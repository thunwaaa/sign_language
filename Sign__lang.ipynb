{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "13_Z7U8hOwmng6irLtRc6t2GfaCswCjGf",
      "authorship_tag": "ABX9TyMu5EMTt1Esg9OgBjAf3ZNu",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunwaaa/sign_language/blob/main/Sign__lang.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ติดตั้งไลบรารีที่จำเป็น"
      ],
      "metadata": {
        "id": "SebiYIhhfa0E"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z5iwm7WkfLwC"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow opencv-python mediapipe pandas matplotlib scikit-learn"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Then download an off-the-shelf model bundle. Check out the MediaPipe documentation for more information about this model bundle."
      ],
      "metadata": {
        "id": "q8JxaMxvflB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ],
      "metadata": {
        "id": "xyt1VaEhfrDk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# นำเข้าไลบรารีที่จำเป็น"
      ],
      "metadata": {
        "id": "HKC7FgHIffG9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot as plt\n",
        "from tqdm.notebook import tqdm\n",
        "from google.colab import drive\n",
        "from mediapipe.python.solutions import hands as mp_hands\n",
        "from mediapipe.framework.formats import landmark_pb2\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "metadata": {
        "id": "i5bsnxuNfgqU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เชื่อมต่อ Google Drive เพื่อเข้าถึงข้อมูล"
      ],
      "metadata": {
        "id": "_fBFq3oTgkNC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "kRjA745egjib"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "BASE_DIR = '/content/drive/MyDrive/sign'  # เปลี่ยนเป็นพาธที่เก็บข้อมูลของคุณ\n",
        "model_path = '/content/drive/MyDrive/model'  # สำหรับบันทึกโมเดล\n",
        "\n",
        "# สร้างโฟลเดอร์สำหรับบันทึกโมเดลถ้ายังไม่มี\n",
        "if not os.path.exists(model_path):\n",
        "    os.makedirs(model_path)"
      ],
      "metadata": {
        "id": "MwZNDQ7dhQ-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตรวจสอบว่าโฟลเดอร์มีอยู่จริง\n",
        "if os.path.exists(BASE_DIR):\n",
        "    print(f\"พบโฟลเดอร์: {BASE_DIR}\")\n",
        "    # ตรวจสอบจำนวนโฟลเดอร์ย่อย (คำในภาษามือ)\n",
        "    subfolders = [f.name for f in os.scandir(BASE_DIR) if f.is_dir()]\n",
        "    print(f\"จำนวนคำในภาษามือ: {len(subfolders)}\")\n",
        "    print(f\"ตัวอย่างคำ: {subfolders[:5] if len(subfolders) >= 5 else subfolders}\")\n",
        "\n",
        "    # ตรวจสอบจำนวนวิดีโอในโฟลเดอร์แรก\n",
        "    if len(subfolders) > 0:\n",
        "        first_folder = os.path.join(BASE_DIR, subfolders[0])\n",
        "        videos = [f for f in os.listdir(first_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "        print(f\"จำนวนวิดีโอในโฟลเดอร์ '{subfolders[0]}': {len(videos)}\")\n",
        "else:\n",
        "    print(f\"ไม่พบโฟลเดอร์: {BASE_DIR}\")\n",
        "    print(\"โปรดตรวจสอบว่าคุณมีพาธที่ถูกต้องไปยังวิดีโอภาษามือไทยของคุณ\")"
      ],
      "metadata": {
        "id": "m79b37pWoKBL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Visualization utilities"
      ],
      "metadata": {
        "id": "ZYTuOOWtfvJl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_hand_landmarks_from_video(video_path, max_frames=30):\n",
        "    \"\"\"\n",
        "    ฟังก์ชันสำหรับสกัดจุดสำคัญของมือจากวิดีโอ (ปรับปรุงแล้ว)\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames_landmarks = []\n",
        "\n",
        "    # ตั้งค่า MediaPipe Hands ด้วยความเชื่อมั่นที่ต่ำลง\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.3,  # ลดลงจาก 0.5\n",
        "        min_tracking_confidence=0.3) as hands:  # ลดลงจาก 0.5\n",
        "\n",
        "        # อ่านเฟรมทั้งหมดก่อน\n",
        "        all_frames = []\n",
        "        while cap.isOpened():\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "            all_frames.append(image)\n",
        "\n",
        "        # เลือกเฟรมแบบกระจาย\n",
        "        if len(all_frames) > 0:\n",
        "            selected_indices = np.linspace(0, len(all_frames)-1, min(max_frames, len(all_frames)), dtype=int)\n",
        "            selected_frames = [all_frames[i] for i in selected_indices]\n",
        "\n",
        "            # ประมวลผลเฟรมที่เลือก\n",
        "            for image in selected_frames:\n",
        "                if len(frames_landmarks) >= max_frames:\n",
        "                    break\n",
        "\n",
        "                # แปลงภาพจาก BGR เป็น RGB\n",
        "                image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "                # ประมวลผลภาพเพื่อรู้จำมือ\n",
        "                results = hands.process(image_rgb)\n",
        "\n",
        "                # เก็บจุดสำคัญของมือ\n",
        "                frame_landmarks = []\n",
        "                if results.multi_hand_landmarks:\n",
        "                    # ใช้มือแรกที่พบ\n",
        "                    hand_landmarks = results.multi_hand_landmarks[0]\n",
        "\n",
        "                    # สกัดพิกัด x, y, z ของจุดสำคัญทั้ง 21 จุด\n",
        "                    for landmark in hand_landmarks.landmark:\n",
        "                        frame_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "                else:\n",
        "                    # ถ้าไม่พบมือ ใส่ 0 สำหรับทุกพิกัด\n",
        "                    frame_landmarks = [0.0] * (21 * 3)  # 21 จุด x 3 พิกัด\n",
        "\n",
        "                frames_landmarks.append(frame_landmarks)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    # ตรวจสอบว่าพบมือในวิดีโออย่างน้อย 1 เฟรมหรือไม่\n",
        "    success = any(sum(landmarks) != 0 for landmarks in frames_landmarks)\n",
        "\n",
        "    # ถ้าจำนวนเฟรมน้อยกว่า max_frames ให้เพิ่มเฟรมที่มีค่า 0 จนครบ\n",
        "    while len(frames_landmarks) < max_frames:\n",
        "        frames_landmarks.append([0.0] * (21 * 3))\n",
        "\n",
        "    return np.array(frames_landmarks), success\n",
        "\n",
        "    # ตรวจสอบวิดีโอใหม่\n",
        "    word_folder = \"ชื่อโฟลเดอร์ที่คุณเพิ่มวิดีโอ\"  # เช่น \"1.สวัสดี\"\n",
        "    video_file = \"ชื่อไฟล์วิดีโอที่เพิ่ม\"  # เช่น \"สวัสดี_เพิ่ม.mp4\"\n",
        "    video_path = os.path.join(BASE_DIR, word_folder, video_file)\n",
        "\n",
        "    if os.path.exists(video_path):\n",
        "        print(f\"กำลังตรวจสอบวิดีโอ: {video_path}\")\n",
        "        landmarks_sequence, success = extract_hand_landmarks_from_video(video_path)\n",
        "        print(f\"การตรวจจับมือสำเร็จ: {success}\")\n",
        "        if success:\n",
        "            print(f\"รูปร่างของข้อมูล: {landmarks_sequence.shape}\")\n",
        "    else:\n",
        "        print(f\"ไม่พบไฟล์: {video_path}\")"
      ],
      "metadata": {
        "id": "5kT1p_D6f4DQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดสอบฟังก์ชันสกัดจุดสำคัญกับวิดีโอตัวอย่าง"
      ],
      "metadata": {
        "id": "qzmzy5wqoULU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "if os.path.exists(BASE_DIR) and len(subfolders) > 0:\n",
        "    # ค้นหาวิดีโอตัวอย่าง\n",
        "    sample_folder = os.path.join(BASE_DIR, subfolders[0])\n",
        "    sample_videos = [f for f in os.listdir(sample_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "    if sample_videos:\n",
        "        sample_video_path = os.path.join(sample_folder, sample_videos[0])\n",
        "        print(f\"กำลังสกัดจุดสำคัญจากวิดีโอตัวอย่าง: {sample_video_path}\")\n",
        "\n",
        "        # สกัดจุดสำคัญ\n",
        "        landmarks_sequence, success = extract_hand_landmarks_from_video(sample_video_path)\n",
        "\n",
        "        print(f\"การสกัดจุดสำคัญสำเร็จ: {success}\")\n",
        "        print(f\"รูปร่างของลำดับจุดสำคัญ: {landmarks_sequence.shape}\")\n",
        "        print(f\"จำนวนเฟรม: {landmarks_sequence.shape[0]}\")\n",
        "        print(f\"จำนวนจุด (21 จุด x 3 พิกัด): {landmarks_sequence.shape[1]}\")\n",
        "\n",
        "        # แสดงตัวอย่างข้อมูลจากเฟรมแรก\n",
        "        print(\"\\nตัวอย่างข้อมูลจากเฟรมแรก (5 ค่าแรก):\")\n",
        "        print(landmarks_sequence[0][:15])  # แสดง 5 จุดแรก (x, y, z)\n",
        "    else:\n",
        "        print(f\"ไม่พบวิดีโอในโฟลเดอร์ {subfolders[0]}\")"
      ],
      "metadata": {
        "id": "oPTQdKxSoTqk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ฟังก์ชันสำหรับสร้างชุดข้อมูลจากโฟลเดอร์\n",
        "\n"
      ],
      "metadata": {
        "id": "FFyNK1hljkjd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_dataset_from_folders(base_dir, max_videos_per_folder=None):\n",
        "    \"\"\"\n",
        "    สร้างชุดข้อมูลจากโฟลเดอร์ที่มีวิดีโอภาษามือไทย\n",
        "\n",
        "    Args:\n",
        "        base_dir: โฟลเดอร์หลักที่มีโฟลเดอร์ย่อยสำหรับแต่ละคำในภาษามือ\n",
        "        max_videos_per_folder: จำนวนวิดีโอสูงสุดที่จะใช้จากแต่ละโฟลเดอร์ (ถ้าเป็น None จะใช้ทั้งหมด)\n",
        "\n",
        "    Returns:\n",
        "        X: ข้อมูลจุดสำคัญของมือ\n",
        "        y: ป้ายกำกับ (คำในภาษามือ)\n",
        "    \"\"\"\n",
        "    X = []\n",
        "    y = []\n",
        "\n",
        "    # วนลูปผ่านโฟลเดอร์ย่อยทั้งหมด\n",
        "    for word_folder in tqdm(os.listdir(base_dir)):\n",
        "        word_path = os.path.join(base_dir, word_folder)\n",
        "\n",
        "        # ข้ามไฟล์ที่ไม่ใช่โฟลเดอร์\n",
        "        if not os.path.isdir(word_path):\n",
        "            continue\n",
        "\n",
        "        # รวบรวมวิดีโอทั้งหมดในโฟลเดอร์\n",
        "        videos = [f for f in os.listdir(word_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "        # จำกัดจำนวนวิดีโอต่อโฟลเดอร์ถ้ากำหนด\n",
        "        if max_videos_per_folder is not None:\n",
        "            videos = videos[:max_videos_per_folder]\n",
        "\n",
        "        # วนลูปผ่านไฟล์วิดีโอที่เลือก\n",
        "        for video_file in videos:\n",
        "            video_path = os.path.join(word_path, video_file)\n",
        "\n",
        "            try:\n",
        "                # สกัดจุดสำคัญของมือจากวิดีโอ\n",
        "                landmarks_sequence, success = extract_hand_landmarks_from_video(video_path)\n",
        "\n",
        "                # เพิ่มข้อมูลเข้าชุดข้อมูลเฉพาะเมื่อพบมือในวิดีโอ\n",
        "                if success:\n",
        "                    X.append(landmarks_sequence)\n",
        "                    y.append(word_folder)\n",
        "                else:\n",
        "                    print(f\"ไม่พบมือในวิดีโอ: {video_path}\")\n",
        "            except Exception as e:\n",
        "                print(f\"เกิดข้อผิดพลาดในการประมวลผล {video_path}: {e}\")\n",
        "\n",
        "    return np.array(X), np.array(y)\n"
      ],
      "metadata": {
        "id": "DqJGnJrUjnia"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การสร้างและฝึกฝนโมเดล"
      ],
      "metadata": {
        "id": "97CF2xhvjtdQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### สร้างชุดข้อมูลขนาดเล็กสำหรับทดสอบ"
      ],
      "metadata": {
        "id": "EQ5JaIrIohvt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# สร้างชุดข้อมูลขนาดเล็กสำหรับทดสอบก่อน (ใช้เพียง 2 วิดีโอต่อโฟลเดอร์)\n",
        "print(\"กำลังสร้างชุดข้อมูลขนาดเล็กสำหรับทดสอบ...\")\n",
        "max_folders_for_test = 5  # จำกัดเพียง 5 โฟลเดอร์แรก\n",
        "max_videos_per_folder_for_test = 2  # จำกัดเพียง 2 วิดีโอต่อโฟลเดอร์\n",
        "\n",
        "# สร้างโฟลเดอร์ย่อยชั่วคราวสำหรับทดสอบ\n",
        "test_folders = subfolders[:max_folders_for_test] if len(subfolders) >= max_folders_for_test else subfolders\n",
        "\n",
        "# แสดงโฟลเดอร์ที่จะใช้ในการทดสอบ\n",
        "print(f\"กำลังใช้ {len(test_folders)} โฟลเดอร์สำหรับการทดสอบ: {test_folders}\")\n",
        "\n",
        "# สร้างชุดข้อมูลขนาดเล็ก\n",
        "X_test, y_test = create_dataset_from_folders(BASE_DIR, max_videos_per_folder=max_videos_per_folder_for_test)\n",
        "\n",
        "print(f\"ชุดข้อมูลทดสอบมี {len(X_test)} ตัวอย่าง\")\n",
        "print(f\"รูปร่างของข้อมูล X: {X_test.shape}\")\n",
        "print(f\"รูปร่างของข้อมูล y: {y_test.shape}\")\n",
        "print(f\"คำในภาษามือที่พบในชุดข้อมูลทดสอบ: {np.unique(y_test)}\")"
      ],
      "metadata": {
        "id": "5VCD5Te9okup"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def debug_class_distribution(X, y):\n",
        "    \"\"\"\n",
        "    ตรวจสอบการกระจายของข้อมูลตามคลาส (คำในภาษามือ)\n",
        "    และแสดงคำที่มีความเสี่ยงจะถูกตัดออกเนื่องจากมีตัวอย่างน้อยเกินไป\n",
        "\n",
        "    Args:\n",
        "        X: ข้อมูลจุดสำคัญของมือ\n",
        "        y: ป้ายกำกับ (คำในภาษามือ)\n",
        "    \"\"\"\n",
        "    # คำนวณจำนวนตัวอย่างต่อคลาส\n",
        "    unique_classes, counts = np.unique(y, return_counts=True)\n",
        "\n",
        "    # สร้าง DataFrame เพื่อแสดงผลให้อ่านง่าย\n",
        "    import pandas as pd\n",
        "    class_distribution = pd.DataFrame({\n",
        "        'คำ': unique_classes,\n",
        "        'จำนวนตัวอย่าง': counts\n",
        "    })\n",
        "\n",
        "    # เรียงลำดับตามจำนวนตัวอย่าง (น้อยไปมาก)\n",
        "    class_distribution = class_distribution.sort_values('จำนวนตัวอย่าง')\n",
        "\n",
        "    # คำที่มีตัวอย่างน้อยกว่า 2 (จะถูกตัดออก)\n",
        "    at_risk_classes = class_distribution[class_distribution['จำนวนตัวอย่าง'] < 2]\n",
        "\n",
        "    # แสดงผลการวิเคราะห์\n",
        "    print(f\"จำนวนคำทั้งหมด: {len(unique_classes)}\")\n",
        "    print(f\"คำที่เสี่ยงจะถูกตัดออก (มีตัวอย่างน้อยกว่า 2): {len(at_risk_classes)}\")\n",
        "\n",
        "    if len(at_risk_classes) > 0:\n",
        "        print(\"\\nรายการคำที่เสี่ยงจะถูกตัดออก:\")\n",
        "        print(at_risk_classes)\n",
        "\n",
        "    # แสดงการกระจายของข้อมูลทั้งหมด\n",
        "    print(\"\\nการกระจายของข้อมูลทั้งหมด (เรียงจากน้อยไปมาก):\")\n",
        "    print(class_distribution)\n",
        "\n",
        "    # วิเคราะห์จำนวนตัวอย่างเพิ่มเติม\n",
        "    print(f\"\\nค่าเฉลี่ยจำนวนตัวอย่างต่อคำ: {counts.mean():.2f}\")\n",
        "    print(f\"ค่ามัธยฐานจำนวนตัวอย่างต่อคำ: {np.median(counts)}\")\n",
        "    print(f\"จำนวนตัวอย่างน้อยที่สุด: {counts.min()}\")\n",
        "    print(f\"จำนวนตัวอย่างมากที่สุด: {counts.max()}\")\n",
        "\n",
        "    # คำที่มีจำนวนตัวอย่างน้อย (1-2 ตัวอย่าง)\n",
        "    low_sample_classes = class_distribution[class_distribution['จำนวนตัวอย่าง'] <= 2]\n",
        "    if len(low_sample_classes) > 0:\n",
        "        print(f\"\\nคำที่มีตัวอย่างน้อย (1-2 ตัวอย่าง): {len(low_sample_classes)} คำ\")\n",
        "        print(low_sample_classes)\n",
        "\n",
        "    # พล็อตกราฟแสดงการกระจายของจำนวนตัวอย่าง\n",
        "    import matplotlib.pyplot as plt\n",
        "    plt.figure(figsize=(12, 6))\n",
        "    plt.bar(range(len(counts)), sorted(counts))\n",
        "    plt.xlabel('คำ (เรียงตามจำนวนตัวอย่าง)')\n",
        "    plt.ylabel('จำนวนตัวอย่าง')\n",
        "    plt.title('การกระจายของจำนวนตัวอย่างต่อคำ')\n",
        "    plt.axhline(y=2, color='r', linestyle='--', label='ขีดแบ่งขั้นต่ำ (2 ตัวอย่าง)')\n",
        "    plt.legend()\n",
        "    plt.show()\n",
        "\n",
        "    return at_risk_classes['คำ'].tolist()\n",
        "\n",
        "# ใช้ฟังก์ชันเพื่อตรวจสอบคำที่จะถูกตัดออก\n",
        "at_risk_words = debug_class_distribution(X_test, y_test)\n",
        "\n",
        "print(\"\\nสรุป: คำที่ต้องเพิ่มตัวอย่างเพื่อไม่ให้ถูกตัดออก:\")\n",
        "for word in at_risk_words:\n",
        "    print(f\"- {word}\")"
      ],
      "metadata": {
        "id": "mMq5Pa_atWGd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ตรวจสอบว่ามีไฟล์วิดีโอใดบ้างที่ไม่สามารถตรวจจับมือได้"
      ],
      "metadata": {
        "id": "75mN7whPtw2H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def check_video_detection_by_class(base_dir):\n",
        "    \"\"\"\n",
        "    ตรวจสอบการตรวจจับมือในวิดีโอตามคลาส (คำในภาษามือ)\n",
        "\n",
        "    Args:\n",
        "        base_dir: โฟลเดอร์หลักที่มีโฟลเดอร์ย่อยสำหรับแต่ละคำในภาษามือ\n",
        "    \"\"\"\n",
        "    results = {}\n",
        "\n",
        "    # วนลูปผ่านโฟลเดอร์ย่อยทั้งหมด\n",
        "    for word_folder in os.listdir(base_dir):\n",
        "        word_path = os.path.join(base_dir, word_folder)\n",
        "\n",
        "        # ข้ามไฟล์ที่ไม่ใช่โฟลเดอร์\n",
        "        if not os.path.isdir(word_path):\n",
        "            continue\n",
        "\n",
        "        # รวบรวมวิดีโอทั้งหมดในโฟลเดอร์\n",
        "        videos = [f for f in os.listdir(word_path) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "        success_count = 0\n",
        "        fail_count = 0\n",
        "\n",
        "        for video_file in videos:\n",
        "            video_path = os.path.join(word_path, video_file)\n",
        "\n",
        "            try:\n",
        "                # สกัดจุดสำคัญของมือจากวิดีโอ\n",
        "                _, success = extract_hand_landmarks_from_video(video_path)\n",
        "\n",
        "                if success:\n",
        "                    success_count += 1\n",
        "                else:\n",
        "                    fail_count += 1\n",
        "                    print(f\"ไม่พบมือในวิดีโอ: {video_path}\")\n",
        "            except Exception as e:\n",
        "                fail_count += 1\n",
        "                print(f\"เกิดข้อผิดพลาดในการประมวลผล {video_path}: {e}\")\n",
        "\n",
        "        # เก็บผลลัพธ์\n",
        "        results[word_folder] = {\n",
        "            'total_videos': len(videos),\n",
        "            'success': success_count,\n",
        "            'fail': fail_count,\n",
        "            'success_rate': success_count / len(videos) if len(videos) > 0 else 0\n",
        "        }\n",
        "\n",
        "    # แสดงผลลัพธ์\n",
        "    import pandas as pd\n",
        "    results_df = pd.DataFrame.from_dict(results, orient='index')\n",
        "    results_df = results_df.sort_values('success_rate')\n",
        "\n",
        "    print(\"\\nผลการตรวจสอบการตรวจจับมือในวิดีโอตามคำในภาษามือ:\")\n",
        "    print(results_df)\n",
        "\n",
        "    # แสดงคำที่มีปัญหามากที่สุด\n",
        "    problem_classes = results_df[results_df['success'] == 0]\n",
        "    if len(problem_classes) > 0:\n",
        "        print(\"\\nคำที่มีปัญหามากที่สุด (ไม่สามารถตรวจจับมือได้เลย):\")\n",
        "        print(problem_classes)\n",
        "\n",
        "    return results_df\n",
        "\n",
        "# ใช้ฟังก์ชันเพื่อตรวจสอบการตรวจจับมือในวิดีโอตามคำในภาษามือ\n",
        "# โค้ดนี้อาจใช้เวลานานในการรัน ขึ้นอยู่กับจำนวนวิดีโอทั้งหมด\n",
        "video_detection_results = check_video_detection_by_class(BASE_DIR)"
      ],
      "metadata": {
        "id": "rUT7iQkXtvqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### เตรียมข้อมูลสำหรับการฝึกฝนโมเดล"
      ],
      "metadata": {
        "id": "kcjfZbEVj0Hq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data(X, y):\n",
        "    \"\"\"\n",
        "    เตรียมข้อมูลสำหรับการฝึกฝนโมเดล\n",
        "\n",
        "    Args:\n",
        "        X: ข้อมูลจุดสำคัญของมือ\n",
        "        y: ป้ายกำกับ (คำในภาษามือ)\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_val, X_test: ข้อมูลฝึกฝน, ตรวจสอบ, และทดสอบ\n",
        "        y_train, y_val, y_test: ป้ายกำกับสำหรับแต่ละชุด\n",
        "        num_classes: จำนวนคลาสทั้งหมด\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "    \"\"\"\n",
        "    # แปลงป้ายกำกับเป็นตัวเลข\n",
        "    label_encoder = LabelEncoder()\n",
        "    y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "    # แบ่งข้อมูลเป็นชุดฝึกฝน, ตรวจสอบ, และทดสอบ\n",
        "    X_train_val, X_test, y_train_val, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
        "    X_train, X_val, y_train, y_val = train_test_split(X_train_val, y_train_val, test_size=0.25, random_state=42, stratify=y_train_val)\n",
        "\n",
        "    # แปลงป้ายกำกับเป็นเวกเตอร์ one-hot\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "    y_train = to_categorical(y_train, num_classes)\n",
        "    y_val = to_categorical(y_val, num_classes)\n",
        "    y_test = to_categorical(y_test, num_classes)\n",
        "\n",
        "    print(f\"รูปร่างของข้อมูลฝึกฝน: {X_train.shape}\")\n",
        "    print(f\"รูปร่างของข้อมูลตรวจสอบ: {X_val.shape}\")\n",
        "    print(f\"รูปร่างของข้อมูลทดสอบ: {X_test.shape}\")\n",
        "    print(f\"จำนวนคลาส: {num_classes}\")\n",
        "    print(f\"คลาสของคำในภาษามือ: {label_encoder.classes_}\")\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, num_classes, label_encoder\n",
        "\n",
        "# เตรียมข้อมูลจากชุดข้อมูลทดสอบ\n",
        "X_train, X_val, X_test, y_train, y_val, y_test, num_classes, label_encoder = prepare_data(X_test, y_test)"
      ],
      "metadata": {
        "id": "_6frUThfozLI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### สร้างโมเดล LSTM สำหรับการรู้จำภาษามือ"
      ],
      "metadata": {
        "id": "XZwUy2Sdj9gh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    สร้างโมเดลสำหรับการรู้จำภาษามือไทย\n",
        "\n",
        "    Args:\n",
        "        input_shape: รูปร่างของข้อมูลอินพุต\n",
        "        num_classes: จำนวนคลาสทั้งหมด\n",
        "\n",
        "    Returns:\n",
        "        model: โมเดล Keras\n",
        "    \"\"\"\n",
        "    model = Sequential([\n",
        "        LSTM(64, return_sequences=True, activation='relu', input_shape=input_shape),\n",
        "        Dropout(0.3),\n",
        "        LSTM(32, return_sequences=False, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.3),\n",
        "        Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    model.compile(\n",
        "        optimizer='adam',\n",
        "        loss='categorical_crossentropy',\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    print(model.summary())\n",
        "    return model\n",
        "\n",
        "# สร้างโมเดล\n",
        "input_shape = (X_train.shape[1], X_train.shape[2])  # (frames, features)\n",
        "model = create_model(input_shape, num_classes)"
      ],
      "metadata": {
        "id": "SjBfpaArkAZS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ฝึกฝนโมเดล"
      ],
      "metadata": {
        "id": "SoAgh7V2kCOD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, X_train, y_train, X_val, y_val, epochs=50):\n",
        "    \"\"\"\n",
        "    ฝึกฝนโมเดลการรู้จำภาษามือไทย\n",
        "\n",
        "    Args:\n",
        "        model: โมเดลที่สร้างขึ้น\n",
        "        X_train, y_train: ข้อมูลฝึกฝนและป้ายกำกับ\n",
        "        X_val, y_val: ข้อมูลตรวจสอบและป้ายกำกับ\n",
        "        epochs: จำนวนรอบในการฝึกฝน\n",
        "\n",
        "    Returns:\n",
        "        history: ประวัติการฝึกฝน\n",
        "    \"\"\"\n",
        "    # กำหนด callbacks\n",
        "    callbacks = [\n",
        "        EarlyStopping(patience=10, restore_best_weights=True),\n",
        "        ReduceLROnPlateau(factor=0.1, patience=5),\n",
        "        ModelCheckpoint('thai_sign_language_model.h5', save_best_only=True)\n",
        "    ]\n",
        "\n",
        "    # ฝึกฝนโมเดล\n",
        "    history = model.fit(\n",
        "        X_train, y_train,\n",
        "        validation_data=(X_val, y_val),\n",
        "        epochs=epochs,\n",
        "        batch_size=16,\n",
        "        callbacks=callbacks\n",
        "    )\n",
        "\n",
        "    return history\n",
        "\n",
        "# ฝึกฝนโมเดล - ใช้เพียง 10 epochs สำหรับการทดสอบ\n",
        "history = train_model(model, X_train, y_train, X_val, y_val, epochs=10)"
      ],
      "metadata": {
        "id": "SYnL9Xs2kDMW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### แสดงประวัติการฝึกฝน"
      ],
      "metadata": {
        "id": "t7qpJGP2kNNs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def plot_training_history(history):\n",
        "    \"\"\"\n",
        "    แสดงกราฟประวัติการฝึกฝน\n",
        "\n",
        "    Args:\n",
        "        history: ประวัติการฝึกฝนจาก model.fit()\n",
        "    \"\"\"\n",
        "    plt.figure(figsize=(12, 4))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('ความแม่นยำของโมเดล')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('การสูญเสียของโมเดล')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()\n",
        "\n",
        "# แสดงกราฟประวัติการฝึกฝน\n",
        "plot_training_history(history)"
      ],
      "metadata": {
        "id": "vJZ-FsbykQB2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#การทดสอบและประเมินผลโมเดล"
      ],
      "metadata": {
        "id": "CabcLMvhkSHX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ประเมินผลโมเดลบนชุดข้อมูลทดสอบ"
      ],
      "metadata": {
        "id": "3g2p4-tbkUG5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_model(model, X_test, y_test, label_encoder):\n",
        "    \"\"\"\n",
        "    ประเมินผลโมเดลบนชุดข้อมูลทดสอบ\n",
        "\n",
        "    Args:\n",
        "        model: โมเดลที่ฝึกฝนแล้ว\n",
        "        X_test, y_test: ข้อมูลทดสอบและป้ายกำกับ\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "    \"\"\"\n",
        "    # คำนวณความแม่นยำบนชุดข้อมูลทดสอบ\n",
        "    test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "    print(f\"ความแม่นยำบนชุดข้อมูลทดสอบ: {test_accuracy:.4f}\")\n",
        "\n",
        "    # ทำนายบนชุดข้อมูลทดสอบ\n",
        "    y_pred = model.predict(X_test)\n",
        "    y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "    y_true_classes = np.argmax(y_test, axis=1)\n",
        "\n",
        "    # แปลงกลับเป็นป้ายกำกับเดิม\n",
        "    y_pred_labels = label_encoder.inverse_transform(y_pred_classes)\n",
        "    y_true_labels = label_encoder.inverse_transform(y_true_classes)\n",
        "\n",
        "    # แสดงตัวอย่างการทำนาย\n",
        "    print(\"\\nตัวอย่างการทำนาย:\")\n",
        "    for i in range(min(len(y_pred_labels), 5)):\n",
        "        print(f\"ตัวอย่างที่ {i+1}: คำทำนาย = {y_pred_labels[i]}, คำจริง = {y_true_labels[i]}\")\n",
        "\n",
        "# ประเมินผลโมเดล\n",
        "evaluate_model(model, X_test, y_test, label_encoder)"
      ],
      "metadata": {
        "id": "OEysrodpkXa7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### บันทึกโมเดลและตัวแปลงป้ายกำกับ"
      ],
      "metadata": {
        "id": "zOtVLs87pEcu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model.save('thai_sign_language_model_test.h5')\n",
        "np.save('label_encoder_classes_test.npy', label_encoder.classes_)\n",
        "\n",
        "print(\"บันทึกโมเดลและตัวแปลงป้ายกำกับเรียบร้อยแล้ว\")"
      ],
      "metadata": {
        "id": "vrAgL3dfpGUR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ฟังก์ชันสำหรับการใช้โมเดลกับกล้องเรียลไทม์"
      ],
      "metadata": {
        "id": "VEn0M4XykYi0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_landmarks(image, results):\n",
        "    \"\"\"\n",
        "    วาดจุดสำคัญของมือบนภาพ\n",
        "\n",
        "    Args:\n",
        "        image: ภาพที่จะวาด\n",
        "        results: ผลลัพธ์จาก MediaPipe Hands\n",
        "\n",
        "    Returns:\n",
        "        image: ภาพที่วาดจุดสำคัญแล้ว\n",
        "    \"\"\"\n",
        "    # วาดจุดสำคัญของมือ\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "    if results.multi_hand_landmarks:\n",
        "        for hand_landmarks in results.multi_hand_landmarks:\n",
        "            mp_drawing.draw_landmarks(\n",
        "                image,\n",
        "                hand_landmarks,\n",
        "                mp_hands.HAND_CONNECTIONS,\n",
        "                mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "                mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "    return image\n",
        "\n",
        "def realtime_sign_recognition(model, label_encoder):\n",
        "    \"\"\"\n",
        "    การรู้จำภาษามือแบบเรียลไทม์จากกล้อง\n",
        "\n",
        "    Args:\n",
        "        model: โมเดลที่ฝึกฝนแล้ว\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    # ตั้งค่า MediaPipe Hands\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as hands:\n",
        "\n",
        "        # เก็บลำดับของจุดสำคัญ\n",
        "        sequence = []\n",
        "        predictions = []\n",
        "        threshold = 0.5\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                print(\"ไม่สามารถเปิดกล้องได้\")\n",
        "                break\n",
        "\n",
        "            # ตั้งค่าภาพเพื่อการแสดงผล\n",
        "            image = cv2.flip(image, 1)  # กลับด้านซ้าย-ขวา\n",
        "            display_image = image.copy()\n",
        "\n",
        "            # แปลงภาพสำหรับ MediaPipe\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            results = hands.process(image_rgb)\n",
        "\n",
        "            # วาดจุดสำคัญบนภาพ\n",
        "            display_image = visualize_landmarks(display_image, results)\n",
        "\n",
        "            # สกัดจุดสำคัญของมือ\n",
        "            frame_landmarks = []\n",
        "            if results.multi_hand_landmarks:\n",
        "                # ใช้มือแรกที่พบ\n",
        "                hand_landmarks = results.multi_hand_landmarks[0]\n",
        "\n",
        "                # สกัดพิกัด x, y, z\n",
        "                for landmark in hand_landmarks.landmark:\n",
        "                    frame_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "            else:\n",
        "                # ถ้าไม่พบมือ ใส่ 0\n",
        "                frame_landmarks = [0.0] * (21 * 3)\n",
        "\n",
        "            # เพิ่มเฟรมเข้าลำดับ\n",
        "            sequence.append(frame_landmarks)\n",
        "            sequence = sequence[-30:]  # เก็บแค่ 30 เฟรมล่าสุด\n",
        "\n",
        "            # ทำนายเมื่อมีเฟรมครบ 30 เฟรม\n",
        "            if len(sequence) == 30:\n",
        "                # เตรียมข้อมูลสำหรับทำนาย\n",
        "                X = np.expand_dims(np.array(sequence), axis=0)\n",
        "\n",
        "                # ทำนาย\n",
        "                prediction = model.predict(X)[0]\n",
        "                predicted_class = np.argmax(prediction)\n",
        "                confidence = prediction[predicted_class]\n",
        "\n",
        "                # เพิ่มการทำนายเข้าในรายการถ้าความเชื่อมั่นสูงกว่าขีดแบ่ง\n",
        "                if confidence > threshold:\n",
        "                    predicted_word = label_encoder.inverse_transform([predicted_class])[0]\n",
        "                    predictions.append(predicted_word)\n",
        "\n",
        "                    # แสดงคำที่ปรากฏบ่อยที่สุดใน 5 การทำนายล่าสุด\n",
        "                    if len(predictions) > 0:\n",
        "                        # นับความถี่\n",
        "                        from collections import Counter\n",
        "                        counter = Counter(predictions[-5:])\n",
        "                        most_common = counter.most_common(1)[0][0]\n",
        "\n",
        "                        # แสดงผลคำที่ทำนาย\n",
        "                        cv2.putText(display_image, f\"{most_common} ({confidence:.2f})\",\n",
        "                                    (10, 30), cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # แสดงภาพ\n",
        "            cv2.imshow('Thai Sign Language Recognition', display_image)\n",
        "\n",
        "            # กด 'q' เพื่อออก\n",
        "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()"
      ],
      "metadata": {
        "id": "mnM_SFu2kcRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ทดสอบการทำนายด้วยวิดีโอตัวอย่าง"
      ],
      "metadata": {
        "id": "Z0qOx8TxppI4"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def predict_from_sample_video(model, label_encoder, video_path):\n",
        "    \"\"\"\n",
        "    ทดสอบการทำนายจากวิดีโอตัวอย่าง\n",
        "\n",
        "    Args:\n",
        "        model: โมเดลที่ฝึกฝนแล้ว\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "        video_path: พาธของไฟล์วิดีโอ\n",
        "    \"\"\"\n",
        "    # สกัดจุดสำคัญของมือจากวิดีโอ\n",
        "    landmarks_sequence, success = extract_hand_landmarks_from_video(video_path)\n",
        "\n",
        "    if not success:\n",
        "        print(\"ไม่พบมือในวิดีโอ\")\n",
        "        return\n",
        "\n",
        "    # เพิ่มมิติแรกเพื่อให้สอดคล้องกับรูปแบบอินพุตของโมเดล\n",
        "    X = np.expand_dims(landmarks_sequence, axis=0)\n",
        "\n",
        "    # ทำนาย\n",
        "    prediction = model.predict(X)[0]\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    confidence = prediction[predicted_class]\n",
        "\n",
        "    # แปลงกลับเป็นคำ\n",
        "    predicted_word = label_encoder.inverse_transform([predicted_class])[0]\n",
        "\n",
        "    print(f\"คำที่ทำนาย: {predicted_word}\")\n",
        "    print(f\"ความเชื่อมั่น: {confidence:.4f}\")\n",
        "\n",
        "    # แสดงผลความเชื่อมั่นสำหรับทุกคลาส\n",
        "    print(\"\\nความเชื่อมั่นสำหรับทุกคลาส:\")\n",
        "    for i, conf in enumerate(prediction):\n",
        "        word = label_encoder.inverse_transform([i])[0]\n",
        "        print(f\"{word}: {conf:.4f}\")\n",
        "\n",
        "# ถ้ามีวิดีโอตัวอย่าง ให้ทดสอบการทำนาย\n",
        "if os.path.exists(BASE_DIR) and len(subfolders) > 0:\n",
        "    # ค้นหาวิดีโอตัวอย่าง\n",
        "    sample_folder = os.path.join(BASE_DIR, subfolders[0])\n",
        "    sample_videos = [f for f in os.listdir(sample_folder) if f.endswith(('.mp4', '.avi', '.mov'))]\n",
        "\n",
        "    if sample_videos:\n",
        "        sample_video_path = os.path.join(sample_folder, sample_videos[0])\n",
        "        print(f\"กำลังทดสอบการทำนายจากวิดีโอตัวอย่าง: {sample_video_path}\")\n",
        "        predict_from_sample_video(model, label_encoder, sample_video_path)"
      ],
      "metadata": {
        "id": "a971JMrvpq-x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## เตรียมฟังก์ชันสำหรับการฝึกฝนเต็มรูปแบบ"
      ],
      "metadata": {
        "id": "e-PMqv5zpu_r"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_full_dataset(base_dir, max_videos_per_folder=None, max_folders=None):\n",
        "    \"\"\"\n",
        "    สร้างชุดข้อมูลเต็มรูปแบบจากโฟลเดอร์ทั้งหมด\n",
        "\n",
        "    Args:\n",
        "        base_dir: โฟลเดอร์หลัก\n",
        "        max_videos_per_folder: จำนวนวิดีโอสูงสุดต่อโฟลเดอร์ (None คือใช้ทั้งหมด)\n",
        "        max_folders: จำนวนโฟลเดอร์สูงสุดที่จะใช้ (None คือใช้ทั้งหมด)\n",
        "\n",
        "    Returns:\n",
        "        X, y: ข้อมูลและป้ายกำกับ\n",
        "    \"\"\"\n",
        "    # รวบรวมโฟลเดอร์ทั้งหมด\n",
        "    all_folders = [f for f in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, f))]\n",
        "\n",
        "    # จำกัดจำนวนโฟลเดอร์ถ้ากำหนด\n",
        "    if max_folders is not None:\n",
        "        all_folders = all_folders[:max_folders]\n",
        "\n",
        "    # จำลองโฟลเดอร์ย่อยด้วยโฟลเดอร์ที่เลือก\n",
        "    base_dir_temp = base_dir\n",
        "\n",
        "    # สร้างชุดข้อมูล\n",
        "    print(f\"กำลังสร้างชุดข้อมูลจาก {len(all_folders)} โฟลเดอร์...\")\n",
        "    X, y = create_dataset_from_folders(base_dir_temp, max_videos_per_folder)\n",
        "\n",
        "    return X, y\n",
        "\n",
        "def full_training_pipeline(base_dir, max_videos_per_folder=None, max_folders=None, epochs=50):\n",
        "    \"\"\"\n",
        "    กระบวนการฝึกฝนเต็มรูปแบบ\n",
        "\n",
        "    Args:\n",
        "        base_dir: โฟลเดอร์หลัก\n",
        "        max_videos_per_folder: จำนวนวิดีโอสูงสุดต่อโฟลเดอร์\n",
        "        max_folders: จำนวนโฟลเดอร์สูงสุดที่จะใช้\n",
        "        epochs: จำนวนรอบในการฝึกฝน\n",
        "\n",
        "    Returns:\n",
        "        model: โมเดลที่ฝึกฝนแล้ว\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "    \"\"\"\n",
        "    # 1. สร้างชุดข้อมูล\n",
        "    X, y = create_full_dataset(base_dir, max_videos_per_folder, max_folders)\n",
        "\n",
        "    # 2. เตรียมข้อมูล\n",
        "    X_train, X_val, X_test, y_train, y_val, y_test, num_classes, label_encoder = prepare_data(X, y)\n",
        "\n",
        "    # 3. สร้างและฝึกฝนโมเดล\n",
        "    input_shape = (X_train.shape[1], X_train.shape[2])\n",
        "    model = create_model(input_shape, num_classes)\n",
        "    history = train_model(model, X_train, y_train, X_val, y_val, epochs)\n",
        "\n",
        "    # 4. แสดงประวัติการฝึกฝน\n",
        "    plot_training_history(history)\n",
        "\n",
        "    # 5. ประเมินผลโมเดล\n",
        "    evaluate_model(model, X_test, y_test, label_encoder)\n",
        "\n",
        "    # 6. บันทึกโมเดลและตัวแปลงป้ายกำกับ\n",
        "    model.save('thai_sign_language_model_full.h5')\n",
        "    np.save('label_encoder_classes_full.npy', label_encoder.classes_)\n",
        "\n",
        "    print(\"บันทึกโมเดลและตัวแปลงป้ายกำกับเรียบร้อยแล้ว\")\n",
        "\n",
        "    return model, label_encoder"
      ],
      "metadata": {
        "id": "1MA5cN6VpxpR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ฝึกฝนโมเดลเต็มรูปแบบ **(รันเมื่อพร้อมเท่านั้น)**"
      ],
      "metadata": {
        "id": "F93f7obDpwxJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# คำเตือน: การรันเซลล์นี้จะใช้เวลานานมาก ขึ้นอยู่กับปริมาณข้อมูลของคุณ\n",
        "\n",
        "# จำกัดจำนวนวิดีโอและโฟลเดอร์เพื่อลดเวลาในการฝึกฝน\n",
        "# ถ้าต้องการใช้ทั้งหมด ให้ตั้งค่าเป็น None\n",
        "max_videos = 3  # จำนวนวิดีโอสูงสุดต่อโฟลเดอร์\n",
        "max_folders = 10  # จำนวนโฟลเดอร์สูงสุด\n",
        "epochs = 30  # จำนวนรอบในการฝึกฝน\n",
        "\n",
        "# ฝึกฝนโมเดลเต็มรูปแบบ\n",
        "full_model, full_label_encoder = full_training_pipeline(BASE_DIR, max_videos, max_folders, epochs)\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "E5CAnnuPp6bq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## โหลดโมเดลที่ฝึกฝนไว้แล้ว"
      ],
      "metadata": {
        "id": "hsCyFsklp-tZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_and_classes(model_path='thai_sign_language_model_test.h5', classes_path='label_encoder_classes_test.npy'):\n",
        "    \"\"\"\n",
        "    โหลดโมเดลและคลาสที่บันทึกไว้\n",
        "\n",
        "    Args:\n",
        "        model_path: พาธของไฟล์โมเดล\n",
        "        classes_path: พาธของไฟล์คลาส\n",
        "\n",
        "    Returns:\n",
        "        model: โมเดลที่โหลด\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "    \"\"\"\n",
        "    # โหลดโมเดล\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # โหลดคลาส\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.classes_ = np.load(classes_path, allow_pickle=True)\n",
        "\n",
        "    print(f\"โหลดโมเดลจาก {model_path} สำเร็จ\")\n",
        "    print(f\"จำนวนคลาส: {len(label_encoder.classes_)}\")\n",
        "    print(f\"คลาสทั้งหมด: {label_encoder.classes_}\")\n",
        "\n",
        "    return model, label_encoder\n",
        "\n",
        "# ตรวจสอบว่าโมเดลถูกสร้างไว้แล้วหรือไม่\n",
        "if os.path.exists('thai_sign_language_model_test.h5'):\n",
        "    # โหลดโมเดลที่ฝึกฝนไว้แล้ว\n",
        "    loaded_model, loaded_label_encoder = load_model_and_classes()"
      ],
      "metadata": {
        "id": "QxY2HdiaqAs4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# การใช้โมเดลกับกล้องเรียลไทม์"
      ],
      "metadata": {
        "id": "YSqMqbfjkeqd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "\"\"\"\n",
        "# คำเตือน: เซลล์นี้จะเปิดกล้องของคุณและใช้โมเดลที่ฝึกฝนแล้วในการรู้จำภาษามือ\n",
        "# รันเฉพาะเมื่อคุณพร้อมที่จะทดสอบกับกล้อง\n",
        "\n",
        "# ใช้โมเดลที่ฝึกฝนไว้แล้ว ทำงานกับกล้อง\n",
        "if 'loaded_model' in locals() and 'loaded_label_encoder' in locals():\n",
        "    print(\"กำลังเริ่มการรู้จำภาษามือแบบเรียลไทม์...\")\n",
        "    print(\"กด 'q' เพื่อออกจากโปรแกรม\")\n",
        "    realtime_sign_recognition(loaded_model, loaded_label_encoder)\n",
        "else:\n",
        "    print(\"โปรดฝึกฝนหรือโหลดโมเดลก่อนใช้งานกับกล้อง\")\n",
        "\"\"\""
      ],
      "metadata": {
        "id": "0UbDP31ekj-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **โค้ดสำหรับการโหลดและใช้โมเดลที่ฝึกฝนไว้แล้ว**"
      ],
      "metadata": {
        "id": "q0Z14yMAkrrL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def load_model_and_recognize():\n",
        "    \"\"\"\n",
        "    โหลดโมเดลที่ฝึกฝนไว้แล้วและใช้ในการรู้จำภาษามือแบบเรียลไทม์\n",
        "    \"\"\"\n",
        "    # โหลดโมเดล\n",
        "    model = tf.keras.models.load_model('thai_sign_language_model.h5')\n",
        "\n",
        "    # โหลดตัวแปลงป้ายกำกับ\n",
        "    label_encoder = LabelEncoder()\n",
        "    label_encoder.classes_ = np.load('label_encoder_classes.npy', allow_pickle=True)\n",
        "\n",
        "    # ใช้โมเดลกับกล้องเรียลไทม์\n",
        "    realtime_sign_recognition(model, label_encoder)\n",
        "\n",
        "# เรียกใช้เมื่อต้องการใช้โมเดลที่ฝึกฝนไว้แล้ว\n",
        "# load_model_and_recognize()"
      ],
      "metadata": {
        "id": "6_tXOeWnkvJI"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}