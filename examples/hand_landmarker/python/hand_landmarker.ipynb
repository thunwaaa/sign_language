{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunwaaa/sign_language/blob/main/examples/hand_landmarker/python/hand_landmarker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Hand Landmarks Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use MediaPipe Tasks Python API to detect hand landmarks from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf>=5.29.1"
      ],
      "metadata": {
        "id": "CyHeT5Wx0LNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "ud9tSu78qK-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy>=2.0.0"
      ],
      "metadata": {
        "id": "wOIHSoTM0-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model bundle. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker#models) for more information about this model bundle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [],
      "source": [
        "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe import solutions\n",
        "\n",
        "# Setup MediaPipe solutions\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Constants\n",
        "MARGIN = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "    hand_landmarks_list = detection_result.multi_hand_landmarks\n",
        "    handedness_list = detection_result.multi_handedness\n",
        "    annotated_image = np.copy(rgb_image)\n",
        "\n",
        "    # Loop through the detected hands to visualize.\n",
        "    for idx in range(len(hand_landmarks_list)):\n",
        "        hand_landmarks = hand_landmarks_list[idx]\n",
        "        handedness = handedness_list[idx]\n",
        "\n",
        "        # Draw the hand landmarks directly using MediaPipe's drawing utilities\n",
        "        mp_drawing.draw_landmarks(\n",
        "            annotated_image,\n",
        "            hand_landmarks,\n",
        "            mp_hands.HAND_CONNECTIONS,\n",
        "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "            mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "        # Get the top left corner of the detected hand's bounding box.\n",
        "        height, width, _ = annotated_image.shape\n",
        "        x_coordinates = [landmark.x for landmark in hand_landmarks.landmark]\n",
        "        y_coordinates = [landmark.y for landmark in hand_landmarks.landmark]\n",
        "        text_x = int(min(x_coordinates) * width)\n",
        "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
        "\n",
        "        # Draw handedness (left or right hand) on the image.\n",
        "        cv2.putText(annotated_image, f\"{handedness.classification[0].label}\",\n",
        "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
        "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
        "\n",
        "    return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "Let's grab a test image that we'll use later. The image is from [Unsplash](https://unsplash.com/photos/mt2fyrdXxzk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "# อัปโหลดวิดีโอหลายๆ ไฟล์\n",
        "uploaded = files.upload()\n",
        "\n",
        "# แสดงรายชื่อไฟล์วิดีโอที่อัปโหลด\n",
        "print(\"ไฟล์วิดีโอที่อัปโหลด:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"- {filename}\")\n",
        "\n",
        "# เก็บพาธของไฟล์วิดีโอทั้งหมด\n",
        "video_paths = list(uploaded.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "Here are the steps to run hand landmark detection using MediaPipe.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/python) to learn more about configuration options that this solution supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# import urllib.request\n",
        "\n",
        "# # MediaPipe initialization\n",
        "# BaseOptions = mp.tasks.BaseOptions\n",
        "# HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "# HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# # Create a hand landmarker instance with the video mode\n",
        "# options = HandLandmarkerOptions(\n",
        "#     base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
        "#     running_mode=VisionRunningMode.VIDEO,\n",
        "#     num_hands=2)\n",
        "\n",
        "# # Open the video file\n",
        "# cap = cv2.VideoCapture(input_video_path)\n",
        "# if not cap.isOpened():\n",
        "#     print(f\"Error: Could not open video file {input_video_path}\")\n",
        "#     exit()\n",
        "\n",
        "# # Get video properties\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# # Create video writer for output\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# with HandLandmarker.create_from_options(options) as landmarker:\n",
        "#     # Initialize timestamp\n",
        "#     timestamp = 0\n",
        "#     frame_count = 0\n",
        "\n",
        "#     while cap.isOpened():\n",
        "#         success, frame = cap.read()\n",
        "#         if not success:\n",
        "#             print(\"End of video or error reading frame.\")\n",
        "#             break\n",
        "\n",
        "#         frame_count += 1\n",
        "#         # Optional: Print progress\n",
        "#         if frame_count % 10 == 0:\n",
        "#             print(f\"Processing frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "#         # Convert to RGB (MediaPipe requirement)\n",
        "#         frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "#         # Process the frame\n",
        "#         results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "#         timestamp += 1\n",
        "\n",
        "#         # Create a black canvas instead of using the original frame\n",
        "#         canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "#         # Draw hand landmarks\n",
        "#         if results.hand_landmarks:\n",
        "#             for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "#                 # Get hand label (LEFT or RIGHT)\n",
        "#                 handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "#                 # Get center of hand for text placement\n",
        "#                 x_values = [landmark.x for landmark in hand_landmarks]\n",
        "#                 y_values = [landmark.y for landmark in hand_landmarks]\n",
        "#                 center_x = int(sum(x_values) / len(x_values) * width)\n",
        "#                 center_y = int(sum(y_values) / len(y_values) * height)\n",
        "\n",
        "#                 # Draw connections with white color\n",
        "#                 for connection in mp.solutions.hands.HAND_CONNECTIONS:\n",
        "#                     start_idx = connection[0]\n",
        "#                     end_idx = connection[1]\n",
        "\n",
        "#                     start_point = (int(hand_landmarks[start_idx].x * width),\n",
        "#                                   int(hand_landmarks[start_idx].y * height))\n",
        "#                     end_point = (int(hand_landmarks[end_idx].x * width),\n",
        "#                                 int(hand_landmarks[end_idx].y * height))\n",
        "\n",
        "#                     cv2.line(canvas, start_point, end_point, (255, 255, 255), 2)  # White lines\n",
        "\n",
        "#                 # Draw landmarks with light blue color\n",
        "#                 for landmark in hand_landmarks:\n",
        "#                     landmark_point = (int(landmark.x * width),\n",
        "#                                      int(landmark.y * height))\n",
        "#                     cv2.circle(canvas, landmark_point, 5, (255, 200, 0), -1)  # Light blue dots\n",
        "\n",
        "#                 # Display hand label\n",
        "#                 color = (255, 100, 100) if handedness == \"LEFT\" else (100, 100, 255)  # Different colors for left/right\n",
        "#                 text_position = (center_x, center_y - 30)\n",
        "#                 cv2.putText(canvas, handedness, text_position,\n",
        "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "#         # Write the canvas to output video\n",
        "#         out.write(canvas)\n",
        "\n",
        "#         # Optional: Display the frame (comment out for faster processing)\n",
        "#         # cv2.imshow('Processing Video', canvas)\n",
        "#         # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         #     break\n",
        "\n",
        "# # Release resources\n",
        "# cap.release()\n",
        "# out.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# print(f\"Processing complete. Output saved to {output_video_path}\")\n",
        "\n",
        "# files.download(output_video_path)"
      ],
      "metadata": {
        "id": "0HLgVzd8A3qT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import mediapipe as mp\n",
        "from google.colab import files\n",
        "\n",
        "def process_video_to_json(input_video_path, gesture_label):\n",
        "    \"\"\"\n",
        "    Process a video and extract hand landmarks to a JSON file\n",
        "\n",
        "    Args:\n",
        "        input_video_path: Path to the input video file\n",
        "        gesture_label: Label for the gesture being performed in the video\n",
        "    \"\"\"\n",
        "    # MediaPipe initialization\n",
        "    BaseOptions = mp.tasks.BaseOptions\n",
        "    HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "    HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "    # Create output JSON path\n",
        "    output_json_path = os.path.splitext(input_video_path)[0] + \"_landmarks.json\"\n",
        "\n",
        "    # Create a hand landmarker instance with the video mode\n",
        "    options = HandLandmarkerOptions(\n",
        "        base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
        "        running_mode=VisionRunningMode.VIDEO,\n",
        "        num_hands=2)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {input_video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Initialize data structure for JSON\n",
        "    video_landmarks = {\n",
        "        'video_id': os.path.splitext(os.path.basename(input_video_path))[0],\n",
        "        'gesture_label': gesture_label,\n",
        "        'fps': fps,\n",
        "        'total_frames': total_frames,\n",
        "        'frames': []\n",
        "    }\n",
        "\n",
        "    with HandLandmarker.create_from_options(options) as landmarker:\n",
        "        # Initialize timestamp\n",
        "        timestamp = 0\n",
        "        frame_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            # Optional: Print progress\n",
        "            if frame_count % 10 == 0:\n",
        "                print(f\"Processing {input_video_path} - frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "            # Convert to RGB (MediaPipe requirement)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "            # Process the frame\n",
        "            results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "\n",
        "            # Calculate timestamp in seconds\n",
        "            timestamp_seconds = frame_count / fps\n",
        "\n",
        "            # Frame landmark data\n",
        "            frame_data = {\n",
        "                'frame_number': frame_count,\n",
        "                'timestamp': timestamp_seconds,\n",
        "                'hands': []\n",
        "            }\n",
        "\n",
        "            # Write hand landmarks to JSON\n",
        "            if results.hand_landmarks:\n",
        "                for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "                    # Get hand label (LEFT or RIGHT)\n",
        "                    handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "                    # Prepare hand landmarks\n",
        "                    hand_data = {\n",
        "                        'hand_type': handedness,\n",
        "                        'landmarks': []\n",
        "                    }\n",
        "\n",
        "                    # Process each landmark\n",
        "                    for landmark_idx, landmark in enumerate(hand_landmarks):\n",
        "                        hand_data['landmarks'].append({\n",
        "                            'landmark_id': landmark_idx,\n",
        "                            'x': landmark.x,\n",
        "                            'y': landmark.y,\n",
        "                            'z': landmark.z\n",
        "                        })\n",
        "\n",
        "                    frame_data['hands'].append(hand_data)\n",
        "\n",
        "            # Add frame data if landmarks were detected\n",
        "            if frame_data['hands']:\n",
        "                video_landmarks['frames'].append(frame_data)\n",
        "\n",
        "            timestamp += 1\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(video_landmarks, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Processing complete. Landmarks saved to {output_json_path}\")\n",
        "    return output_json_path\n",
        "\n",
        "# อัปโหลดวิดีโอหลายๆ ไฟล์\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ให้ผู้ใช้ระบุท่าทางสำหรับทุกวิดีโอ\n",
        "gesture_label = input(\"กรุณาระบุชื่อท่าทาง (เช่น hello, thank_you, เป็นต้น): \")\n",
        "\n",
        "# เก็บ JSON paths\n",
        "json_paths = []\n",
        "\n",
        "# ประมวลผลวิดีโอแต่ละไฟล์\n",
        "for video_path in uploaded.keys():\n",
        "    json_path = process_video_to_json(video_path, gesture_label)\n",
        "    if json_path:\n",
        "        json_paths.append(json_path)\n",
        "\n",
        "# ดาวน์โหลด JSON ทุกไฟล์\n",
        "for json_path in json_paths:\n",
        "    files.download(json_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "n4QL0iI0tHqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "รวบรวมข้อมูลจากทุกไฟล์ JSONในโฟลเดอร์เพื่อเพิ่มความหลากหลายและความครอบคลุมของข้อมูล"
      ],
      "metadata": {
        "id": "RzxvsUVWtQtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE6_sPCXaX3g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "def preprocess_sign_language_data(data_directory):\n",
        "    \"\"\"\n",
        "    Preprocess sign language data from JSON files\n",
        "\n",
        "    Args:\n",
        "        data_directory: Path to directory containing JSON files\n",
        "\n",
        "    Returns:\n",
        "        X: Processed feature data\n",
        "        y: Corresponding labels\n",
        "    \"\"\"\n",
        "    # เก็บข้อมูลทั้งหมด\n",
        "    all_landmarks = []\n",
        "    all_labels = []\n",
        "\n",
        "    # เพิ่มการตรวจสอบก่อนเริ่มทำงาน\n",
        "    if not os.path.exists(data_directory):\n",
        "        print(f\"Error: Directory {data_directory} does not exist!\")\n",
        "        return [], [], None # Return empty lists and None instead of None, None, None\n",
        "\n",
        "   # วนลูปผ่านไฟล์ JSON โดยตรง\n",
        "    for json_file in os.listdir(data_directory):\n",
        "        if json_file.endswith('.json'):\n",
        "            file_path = os.path.join(data_directory, json_file)\n",
        "\n",
        "            try:\n",
        "                # โหลดข้อมูล JSON\n",
        "                with open(file_path, 'r') as f:\n",
        "                    video_data = json.load(f)\n",
        "\n",
        "                # สกัดคุณลักษณะ\n",
        "                processed_landmarks = process_video_landmarks(video_data)\n",
        "\n",
        "                # เพิ่มข้อมูล\n",
        "                all_landmarks.append(processed_landmarks)\n",
        "                # ใช้ชื่อไฟล์เป็นฉลาก\n",
        "                all_labels.append(json_file.split('_')[0])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    # ถ้าไม่พบไฟล์ JSON เลย\n",
        "    if not all_landmarks:\n",
        "        print(f\"No JSON files found in directory {data_directory}\")\n",
        "        return [], [], None # Return empty lists and None instead of None, None, None\n",
        "\n",
        "    # แปลง list เป็น numpy array\n",
        "    X = np.array(all_landmarks)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(all_labels)\n",
        "\n",
        "    # พิมพ์ข้อมูลดีบัก\n",
        "    print(f\"Processed {len(X)} samples\")\n",
        "    print(f\"Labels: {label_encoder.classes_}\")\n",
        "\n",
        "    return X, y, label_encoder\n",
        "\n",
        "def process_video_landmarks(video_data):\n",
        "    \"\"\"\n",
        "    แปลงข้อมูลแลนด์มาร์คจาก JSON เป็นชุดข้อมูลที่เหมาะสำหรับโมเดล\n",
        "\n",
        "    Args:\n",
        "        video_data: ข้อมูล JSON ของวิดีโอ\n",
        "\n",
        "    Returns:\n",
        "        processed_landmarks: อาร์เรย์ของแลนด์มาร์ค\n",
        "    \"\"\"\n",
        "    # เลือกเฟรมที่มีการตรวจจับมือ\n",
        "    hand_frames = [frame for frame in video_data['frames'] if frame['hands']]\n",
        "\n",
        "    # เลือกเฟรมทั้งหมด (หรือจำกัดจำนวนเฟรม)\n",
        "    selected_frames = hand_frames[:30]  # จำกัดที่ 30 เฟรม\n",
        "\n",
        "    # เตรียมอาร์เรย์เก็บแลนด์มาร์ค\n",
        "    landmarks_sequence = []\n",
        "\n",
        "    for frame in selected_frames:\n",
        "        # สำหรับแต่ละมือในเฟรม\n",
        "        frame_landmarks = []\n",
        "        for hand in frame['hands']:\n",
        "            # สกัด x, y, z ของแต่ละจุด\n",
        "            hand_landmarks = [\n",
        "                [landmark['x'], landmark['y'], landmark['z']]\n",
        "                for landmark in hand['landmarks']\n",
        "            ]\n",
        "            frame_landmarks.extend(hand_landmarks)\n",
        "\n",
        "        # padding หากมีจุดไม่ครบ\n",
        "        while len(frame_landmarks) < 42:  # 21 จุด * 2 มือ\n",
        "            frame_landmarks.append([0, 0, 0])\n",
        "\n",
        "        landmarks_sequence.append(frame_landmarks[:42])\n",
        "\n",
        "    # padding sequence ให้มีความยาวคงที่\n",
        "    while len(landmarks_sequence) < 30:\n",
        "        landmarks_sequence.append([[0, 0, 0]] * 42)\n",
        "\n",
        "    # เพิ่มในฟังก์ชัน process_video_landmarks เพื่อดีบัก\n",
        "    print(\"Video data keys:\", video_data.keys())\n",
        "    print(\"Number of frames:\", len(video_data['frames']))\n",
        "    print(\"First frame hands:\", video_data['frames'][0]['hands'])\n",
        "\n",
        "    return np.array(landmarks_sequence)\n",
        "\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "data_directory = '/content/hi'  # ตรวจสอบให้แน่ใจว่าพาธนี้ถูกต้อง\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(data_directory):\n",
        "    print(f\"Error: Directory '{data_directory}' does not exist. Please create it and add your JSON files.\")\n",
        "else:\n",
        "    # Check if the directory contains any JSON files\n",
        "    json_files = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
        "    if not json_files:\n",
        "        print(f\"Error: Directory '{data_directory}' does not contain any JSON files. Please add your JSON files.\")\n",
        "    else:\n",
        "        X, y, label_encoder = preprocess_sign_language_data(data_directory)\n",
        "\n",
        "        if len(X) > 0 and len(y) > 0 and label_encoder is not None:\n",
        "\n",
        "          # เพิ่มบรรทัดนี้ก่อนการแบ่งข้อมูล\n",
        "            print(\"X shape:\", X.shape)\n",
        "            print(\"y shape:\", y.shape)\n",
        "            print(\"X data type:\", X.dtype)\n",
        "            print(\"First sample landmarks:\\n\", X[0])\n",
        "            print(\"Labels:\", y)\n",
        "            # แบ่งข้อมูล\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "            print(\"Shape of training data:\", X_train.shape)\n",
        "            print(\"Unique labels:\", label_encoder.classes_)\n",
        "        else:\n",
        "            print(\"No data to process. Check your JSON files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "Y8K_zntKDLri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เพิ่มความหลากหลายของข้อมูล สร้างข้อมูลเทียม เพิ่มความทนทานของโมเดล"
      ],
      "metadata": {
        "id": "pWzZTi7LDU0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class SignLanguageDataAugmentation:\n",
        "    def __init__(self, original_data):\n",
        "        \"\"\"\n",
        "        เตรียมการเพิ่มความหลากหลายของข้อมูลภาษามือ\n",
        "\n",
        "        Args:\n",
        "            original_data: ข้อมูลแลนด์มาร์คเดิม\n",
        "        \"\"\"\n",
        "        self.original_data = original_data\n",
        "\n",
        "    def add_noise(self, data, noise_level=0.02):\n",
        "        \"\"\"\n",
        "        เพิ่มความคลาดเคลื่อนเล็กน้อยในข้อมูล\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            noise_level: ระดับความคลาดเคลื่อน\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่เพิ่มความคลาดเคลื่อน\n",
        "        \"\"\"\n",
        "        noise = np.random.normal(\n",
        "            loc=0,\n",
        "            scale=noise_level,\n",
        "            size=data.shape\n",
        "        )\n",
        "        return data + noise\n",
        "\n",
        "    def time_warping(self, data, max_warp=5):\n",
        "        \"\"\"\n",
        "        ยืดหรือบีบเวลาของลำดับการเคลื่อนไหว\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            max_warp: จำนวนเฟรมสูงสุดที่จะยืดหรือบีบ\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกดัดแปลงเวลา\n",
        "        \"\"\"\n",
        "        # สุ่มเลือกจุดที่จะยืดหรือบีบ\n",
        "        warp_point = random.randint(0, len(data) - max_warp - 1)\n",
        "\n",
        "        # สร้างข้อมูลใหม่\n",
        "        warped_data = np.copy(data)\n",
        "\n",
        "        # ซ้ำหรือลบเฟรมบางส่วน\n",
        "        insert_point = random.randint(0, max_warp)\n",
        "        warped_data = np.insert(\n",
        "            warped_data,\n",
        "            warp_point + insert_point,\n",
        "            warped_data[warp_point:warp_point+max_warp],\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        # ตัดให้มีความยาวคงเดิม\n",
        "        return warped_data[:len(data)]\n",
        "\n",
        "    def hand_rotation(self, data):\n",
        "        \"\"\"\n",
        "        หมุนตำแหน่งมือ\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกหมุน\n",
        "        \"\"\"\n",
        "        # สุ่มมุมหมุน\n",
        "        angle = np.random.uniform(-30, 30)\n",
        "\n",
        "        # แปลงเป็นเรเดียน\n",
        "        angle_rad = np.deg2rad(angle)\n",
        "\n",
        "        # เมทริกซ์หมุน\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "            [np.sin(angle_rad), np.cos(angle_rad)]\n",
        "        ])\n",
        "\n",
        "        # คัดลอกข้อมูล\n",
        "        rotated_data = np.copy(data)\n",
        "\n",
        "        # หมุนพิกัด x, y\n",
        "        for i in range(len(rotated_data)):\n",
        "            for j in range(0, len(rotated_data[i]), 3):\n",
        "                rotated_data[i][j:j+2] = np.dot(\n",
        "                    rotation_matrix,\n",
        "                    rotated_data[i][j:j+2]\n",
        "                )\n",
        "\n",
        "        return rotated_data\n",
        "\n",
        "    def generate_augmented_data(self, num_augmentations=5):\n",
        "        \"\"\"\n",
        "        สร้างชุดข้อมูลเพิ่มเติม\n",
        "\n",
        "        Args:\n",
        "            num_augmentations: จำนวนข้อมูลที่ต้องการสร้าง\n",
        "\n",
        "        Returns:\n",
        "            ชุดข้อมูลที่ถูกเพิ่มความหลากหลาย\n",
        "        \"\"\"\n",
        "        augmented_data = []\n",
        "\n",
        "        for _ in range(num_augmentations):\n",
        "            # สุ่มเลือกข้อมูลต้นฉบับ\n",
        "            base_data = random.choice(self.original_data)\n",
        "\n",
        "            # เพิ่มความหลากหลาย\n",
        "            augmented_sample = self.add_noise(base_data)\n",
        "            augmented_sample = self.time_warping(augmented_sample)\n",
        "            augmented_sample = self.hand_rotation(augmented_sample)\n",
        "\n",
        "            augmented_data.append(augmented_sample)\n",
        "\n",
        "        return augmented_data\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "# สมมติ X คือชุดข้อมูลเดิม\n",
        "augmentor = SignLanguageDataAugmentation(X)\n",
        "augmented_X = augmentor.generate_augmented_data()\n",
        "\n",
        "# รวมข้อมูล\n",
        "X_augmented = np.concatenate([X, augmented_X])\n",
        "y_augmented = np.concatenate([y, y[:len(augmented_X)]])"
      ],
      "metadata": {
        "id": "NePB3X4-Da4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "2NxeR7VwDr47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สกัดคุณลักษณะพิเศษ\n",
        "คำนวณความเร็ว ความเร่ง\n",
        "วิเคราะห์คุณสมบัติทางสถิติ\n",
        "\n"
      ],
      "metadata": {
        "id": "gVAMip17DvxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "class SignLanguageFeatureExtractor:\n",
        "    def __init__(self, landmarks_data):\n",
        "        \"\"\"\n",
        "        สกัดคุณลักษณะพิเศษจากข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Args:\n",
        "            landmarks_data: ข้อมูลแลนด์มาร์คภาษามือ\n",
        "        \"\"\"\n",
        "        self.landmarks_data = landmarks_data\n",
        "\n",
        "    def calculate_hand_velocity(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร็วของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร็วมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        velocities = []\n",
        "        for sequence in self.landmarks_data:\n",
        "            frame_velocities = []\n",
        "            for frame_idx in range(1, len(sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงตำแหน่ง\n",
        "                prev_frame = sequence[frame_idx-1]\n",
        "                curr_frame = sequence[frame_idx]\n",
        "\n",
        "                # คำนวณความเร็ว\n",
        "                frame_velocity = np.linalg.norm(\n",
        "                    curr_frame[:21*3] - prev_frame[:21*3]\n",
        "                )\n",
        "                frame_velocities.append(frame_velocity)\n",
        "\n",
        "            velocities.append(frame_velocities)\n",
        "\n",
        "        return np.array(velocities)\n",
        "\n",
        "    def calculate_hand_acceleration(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร่งของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร่งมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        accelerations = []\n",
        "        velocities = self.calculate_hand_velocity()\n",
        "\n",
        "        for velocity_sequence in velocities:\n",
        "            frame_accelerations = []\n",
        "            for frame_idx in range(1, len(velocity_sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงความเร็ว\n",
        "                acceleration = abs(\n",
        "                    velocity_sequence[frame_idx] -\n",
        "                    velocity_sequence[frame_idx-1]\n",
        "                )\n",
        "                frame_accelerations.append(acceleration)\n",
        "\n",
        "            accelerations.append(frame_accelerations)\n",
        "\n",
        "        return np.array(accelerations)\n",
        "\n",
        "    def calculate_statistical_features(self):\n",
        "        \"\"\"\n",
        "        คำนวณคุณลักษณะทางสถิติ\n",
        "\n",
        "        Returns:\n",
        "            พจนานุกรมของคุณลักษณะทางสถิติ\n",
        "        \"\"\"\n",
        "        features = []\n",
        "\n",
        "        for sequence in self.landmarks_data:\n",
        "            sequence_features = {}\n",
        "\n",
        "            # คำนวณคุณลักษณะสำหรับแต่ละมือ\n",
        "            for hand_start in [0, 21*3]:\n",
        "                hand_landmarks = sequence[:, hand_start:hand_start+21*3]\n",
        "\n",
        "                # สถิติพื้นฐาน\n",
        "                sequence_features.update({\n",
        "                    f'hand_{hand_start//63}_mean': np.mean(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_std': np.std(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_skewness': skew(hand_landmarks.flatten()),\n",
        "                    f'hand_{hand_start//63}_kurtosis': kurtosis(hand_landmarks.flatten())\n",
        "                })\n",
        "\n",
        "            features.append(sequence_features)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def extract_advanced_features(self):\n",
        "        \"\"\"\n",
        "        สกัดคุณลักษณะขั้นสูง\n",
        "\n",
        "        Returns:\n",
        "            เมทริกซ์คุณลักษณะ\n",
        "        \"\"\"\n",
        "        # รวบรวมคุณลักษณะต่างๆ\n",
        "        velocities = self.calculate_hand_velocity()\n",
        "        accelerations = self.calculate_hand_acceleration()\n",
        "        statistical_features = self.calculate_statistical_features()\n",
        "\n",
        "        # แปลงเป็นรูปแบบที่เหมาะสมสำหรับโมเดล\n",
        "        feature_matrix = []\n",
        "        for i in range(len(self.landmarks_data)):\n",
        "            features = np.concatenate([\n",
        "                np.mean(velocities[i]),\n",
        "                np.mean(accelerations[i]),\n",
        "                list(statistical_features[i].values())\n",
        "            ])\n",
        "            feature_matrix.append(features)\n",
        "\n",
        "        return np.array(feature_matrix)\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "feature_extractor = SignLanguageFeatureExtractor(X)\n",
        "X_advanced_features = feature_extractor.extract_advanced_features()"
      ],
      "metadata": {
        "id": "33HFkVbfD2Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SXpVnlrhD_FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดสอบหลายสถาปัตยกรรม\n",
        "LSTM, CNN, Transformer\n",
        "เปรียบเทียบประสิทธิภาพ และ ค้นหาพารามิเตอร์ที่เหมาะสม\n",
        "ใช้ Random Search\n",
        "ปรับแต่งโมเดลให้ดีขึ้น"
      ],
      "metadata": {
        "id": "cE6HGY7gEAKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "class SignLanguageModelSelector:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        เลือกและปรับแต่งโมเดลสำหรับภาษามือ\n",
        "\n",
        "        Args:\n",
        "            X_train: ข้อมูลฝึกอบรม\n",
        "            y_train: ป้ายกำกับการฝึกอบรม\n",
        "            X_test: ข้อมูลทดสอบ\n",
        "            y_test: ป้ายกำกับการทดสอบ\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # โมเดลที่จะทดสอบ\n",
        "        self.models = {\n",
        "            'LSTM': self.create_lstm_model,\n",
        "            'CNN': self.create_cnn_model,\n",
        "            'Transformer': self.create_transformer_model\n",
        "        }\n",
        "\n",
        "    def create_lstm_model(self, units=64, dropout=0.3):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล LSTM\n",
        "\n",
        "        Args:\n",
        "            units: จำนวนหน่วยใน LSTM layer\n",
        "            dropout: อัตราการ dropout\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.LSTM(\n",
        "                units,\n",
        "                input_shape=(30, 42),\n",
        "                return_sequences=True\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(dropout),\n",
        "            tf.keras.layers.LSTM(units//2),\n",
        "            tf.keras.layers.Dense(\n",
        "                len(np.unique(self.y_train)),\n",
        "                activation='softmax'\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_cnn_model(self, filters=64, kernel_size=3):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล CNN\n",
        "\n",
        "        Args:\n",
        "            filters: จำนวน filters\n",
        "            kernel_size: ขนาด kernel\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv1D(\n",
        "                filters,\n",
        "                kernel_size,\n",
        "                input_shape=(30, 42),\n",
        "                activation='relu'\n",
        "            ),\n",
        "            tf.keras.layers.MaxPooling1D(2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(\n",
        "                len(np.unique(self.y_train)),\n",
        "                activation='softmax'\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_transformer_model(self, num_heads=4, ff_dim=32):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล Transformer\n",
        "\n",
        "        Args:\n",
        "            num_heads: จำนวน attention heads\n",
        "            ff_dim: ขนาดของ feed-forward layer\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        inputs = tf.keras.Input(shape=(30, 42))\n",
        "\n",
        "        # Transformer Encoder\n",
        "        x = inputs\n",
        "        for _ in range(2):\n",
        "            x = tf.keras.layers.MultiHeadAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=ff_dim\n",
        "            )(x, x)\n",
        "            x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
        "        outputs = tf.keras.layers.Dense(\n",
        "            len(np.unique(self.y_train)),\n",
        "            activation='softmax'\n",
        "        )(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def hyperparameter_tuning(self):\n",
        "        \"\"\"\n",
        "        ปรับแต่งพารามิเตอร์โดยใช้ Random Search\n",
        "\n",
        "        Returns:\n",
        "            โมเดลที่ดีที่สุด\n",
        "        \"\"\"\n",
        "        # เตรียม Keras Classifier\n",
        "        model = KerasClassifier(\n",
        "            build_fn=self.create_lstm_model,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # ช่วงพารามิเตอร์\n",
        "        param_dist = {\n",
        "            'units': [32, 64, 128],\n",
        "            'dropout': uniform(0.2, 0.5),\n",
        "            'batch_size': [16, 32, 64],\n",
        "            'epochs': [50, 100, 200]\n",
        "        }\n",
        "\n",
        "        # Random Search\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=model,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            cv=3,\n",
        "            scoring='accuracy'\n",
        "        )\n",
        "\n",
        "        random_search.fit(\n",
        "            self.X_train,\n",
        "            self.y_train,\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        return random_search.best_estimator_\n",
        "\n",
        "    def compare_models(self):\n",
        "        \"\"\"\n",
        "        เปรียบเทียบประสิทธิภาพโมเดล\n",
        "\n",
        "        Returns:\n",
        "            พจนานุกรมผลลัพธ์\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for name, model_creator in self.models.items():\n",
        "            # สร้างโมเดล\n",
        "            model = model_creator()\n",
        "\n",
        "            # ฝึกอบรม\n",
        "            history = model.fit(\n",
        "                self.X_train, self.y_train,\n",
        "                validation_split=0.2,\n",
        "                epochs=50,\n",
        "                batch_size=32\n",
        "            )\n",
        "\n",
        "            # ประเมินผล\n",
        "            test_loss, test_accuracy = model.evaluate(\n",
        "                self.X_test, self.y_test\n",
        "            )\n",
        "\n",
        "            results[name] = {\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'test_loss': test_loss,\n",
        "                'training_history': history\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "model_selector = SignLanguageModelSelector(\n",
        "    X_train, y_train, X_test, y_test\n",
        ")\n",
        "\n",
        "# เปรียบเทียบโมเดล\n",
        "model_comparison = model_selector.compare_models()\n",
        "\n",
        "# ปรับแต่งพารามิเตอร์\n",
        "best_model = model_selector.hyperparameter_tuning()"
      ],
      "metadata": {
        "id": "HV2v4z-ZEEhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   เทรนโมเดลที่ดีที่สุดให้ละเอียดยิ่งขึ้นด้วยการเทรนหลายรอบ\n",
        "*   เพิ่มประสิทธิภาพด้วยการเพิ่มข้อมูล (Data Augmentation)\n",
        "*  ประเมินและวิเคราะห์ผลลัพธ์อย่างละเอียด\n",
        "*   เตรียมโมเดลสำหรับการนำไปใช้งาน\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L25e08HeUfIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pandas as pd\n",
        "\n",
        "class SignLanguageModelTrainer:\n",
        "    def __init__(self, model_selector, best_model=None, best_model_name=None):\n",
        "        \"\"\"\n",
        "        ฝึกอบรมและปรับปรุงโมเดลภาษามือที่ดีที่สุด\n",
        "\n",
        "        Args:\n",
        "            model_selector: อ็อบเจ็กต์ SignLanguageModelSelector ที่ใช้ก่อนหน้านี้\n",
        "            best_model: โมเดลที่ดีที่สุดจากการปรับแต่งพารามิเตอร์ (หากมี)\n",
        "            best_model_name: ชื่อสถาปัตยกรรมที่ดีที่สุด (LSTM, CNN, Transformer)\n",
        "        \"\"\"\n",
        "        self.model_selector = model_selector\n",
        "        self.X_train = model_selector.X_train\n",
        "        self.y_train = model_selector.y_train\n",
        "        self.X_test = model_selector.X_test\n",
        "        self.y_test = model_selector.y_test\n",
        "        self.best_model = best_model\n",
        "        self.best_model_name = best_model_name\n",
        "        self.num_classes = len(np.unique(self.y_train))\n",
        "\n",
        "    def prepare_best_model(self, model_comparison=None):\n",
        "        \"\"\"\n",
        "        เตรียมโมเดลที่ดีที่สุดสำหรับการเทรนอย่างละเอียด\n",
        "\n",
        "        Args:\n",
        "            model_comparison: ผลลัพธ์จาก model_selector.compare_models()\n",
        "\n",
        "        Returns:\n",
        "            โมเดลที่ดีที่สุดพร้อมค่าพารามิเตอร์เริ่มต้น\n",
        "        \"\"\"\n",
        "        if self.best_model is not None:\n",
        "            print(f\"ใช้โมเดลที่กำหนดไว้: {self.best_model_name}\")\n",
        "            return self.best_model\n",
        "\n",
        "        if model_comparison is not None:\n",
        "            # หาโมเดลที่ดีที่สุดจากความแม่นยำ\n",
        "            best_acc = 0\n",
        "            for name, results in model_comparison.items():\n",
        "                if results['test_accuracy'] > best_acc:\n",
        "                    best_acc = results['test_accuracy']\n",
        "                    self.best_model_name = name\n",
        "\n",
        "            print(f\"โมเดลที่ดีที่สุดจากการเปรียบเทียบ: {self.best_model_name} (ความแม่นยำ: {best_acc:.4f})\")\n",
        "\n",
        "            # สร้างโมเดลใหม่ตามสถาปัตยกรรมที่ดีที่สุด\n",
        "            if self.best_model_name == 'LSTM':\n",
        "                self.best_model = self.model_selector.create_lstm_model()\n",
        "            elif self.best_model_name == 'CNN':\n",
        "                self.best_model = self.model_selector.create_cnn_model()\n",
        "            elif self.best_model_name == 'Transformer':\n",
        "                self.best_model = self.model_selector.create_transformer_model()\n",
        "            else:\n",
        "                raise ValueError(\"ไม่พบชื่อโมเดลที่ถูกต้อง\")\n",
        "\n",
        "            return self.best_model\n",
        "\n",
        "        # ถ้าไม่มีข้อมูลเปรียบเทียบโมเดล ให้ใช้ LSTM เป็นค่าเริ่มต้น\n",
        "        print(\"ไม่มีการเปรียบเทียบโมเดล ใช้ LSTM เป็นค่าเริ่มต้น\")\n",
        "        self.best_model_name = 'LSTM'\n",
        "        self.best_model = self.model_selector.create_lstm_model()\n",
        "        return self.best_model\n",
        "\n",
        "    def create_data_augmentation(self):\n",
        "        \"\"\"\n",
        "        สร้างฟังก์ชันสำหรับเพิ่มข้อมูล\n",
        "\n",
        "        Returns:\n",
        "            ฟังก์ชันสำหรับเพิ่มข้อมูล\n",
        "        \"\"\"\n",
        "        def augment_sequence(sequence, label):\n",
        "            # แปลงเป็น tensor\n",
        "            sequence = tf.convert_to_tensor(sequence, dtype=tf.float32)\n",
        "\n",
        "            # เพิ่มสัญญาณรบกวน (Gaussian noise)\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                noise = tf.random.normal(shape=tf.shape(sequence), mean=0.0, stddev=0.05)\n",
        "                sequence = sequence + noise\n",
        "\n",
        "            # สลับเวลา (Time shifting)\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                shift = tf.random.uniform([], minval=-3, maxval=3, dtype=tf.int32)\n",
        "                sequence = tf.roll(sequence, shift, axis=0)\n",
        "\n",
        "            # สเกลแอมพลิจูด (Amplitude scaling)\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                scale = tf.random.uniform([], minval=0.8, maxval=1.2)\n",
        "                sequence = sequence * scale\n",
        "\n",
        "            # หมุนและเอียง (ทำกับข้อมูลที่เป็นตำแหน่ง x, y, z)\n",
        "            # สมมติว่าข้อมูลมี dimension เป็น [timesteps, features]\n",
        "            # และทุกๆ 3 features เป็นตำแหน่ง x, y, z\n",
        "            if tf.random.uniform([]) < 0.5:\n",
        "                angle = tf.random.uniform([], minval=-0.1, maxval=0.1)  # หมุนเล็กน้อย\n",
        "                for i in range(0, sequence.shape[1], 3):\n",
        "                    if i+2 < sequence.shape[1]:  # ตรวจสอบว่ามี 3 channels\n",
        "                        x = sequence[:, i]\n",
        "                        y = sequence[:, i+1]\n",
        "                        # หมุนในระนาบ x-y\n",
        "                        new_x = x * tf.cos(angle) - y * tf.sin(angle)\n",
        "                        new_y = x * tf.sin(angle) + y * tf.cos(angle)\n",
        "                        sequence = tf.tensor_scatter_nd_update(\n",
        "                            sequence,\n",
        "                            [[j, i] for j in range(sequence.shape[0])],\n",
        "                            new_x\n",
        "                        )\n",
        "                        sequence = tf.tensor_scatter_nd_update(\n",
        "                            sequence,\n",
        "                            [[j, i+1] for j in range(sequence.shape[0])],\n",
        "                            new_y\n",
        "                        )\n",
        "\n",
        "            return sequence, label\n",
        "\n",
        "        return augment_sequence\n",
        "\n",
        "    def create_train_dataset(self, batch_size=32, use_augmentation=True):\n",
        "        \"\"\"\n",
        "        สร้าง dataset สำหรับการเทรน\n",
        "\n",
        "        Args:\n",
        "            batch_size: ขนาด batch\n",
        "            use_augmentation: ใช้การเพิ่มข้อมูลหรือไม่\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset สำหรับการเทรน\n",
        "        \"\"\"\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
        "\n",
        "        if use_augmentation:\n",
        "            augment_func = self.create_data_augmentation()\n",
        "            train_dataset = train_dataset.map(augment_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=len(self.X_train))\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        return train_dataset\n",
        "\n",
        "    def create_validation_dataset(self, batch_size=32):\n",
        "        \"\"\"\n",
        "        สร้าง dataset สำหรับการตรวจสอบ\n",
        "\n",
        "        Args:\n",
        "            batch_size: ขนาด batch\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset สำหรับการตรวจสอบ\n",
        "        \"\"\"\n",
        "        # แยก validation set จาก training set\n",
        "        val_split = int(len(self.X_train) * 0.9)\n",
        "        X_val = self.X_train[val_split:]\n",
        "        y_val = self.y_train[val_split:]\n",
        "\n",
        "        val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "        val_dataset = val_dataset.batch(batch_size)\n",
        "        val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        return val_dataset\n",
        "\n",
        "    def train_with_progressive_learning(self, epochs=300, batch_size=32, patience=20):\n",
        "        \"\"\"\n",
        "        ฝึกอบรมโมเดลด้วยการเรียนรู้แบบก้าวหน้า\n",
        "\n",
        "        Args:\n",
        "            epochs: จำนวนรอบการเทรนทั้งหมด\n",
        "            batch_size: ขนาด batch\n",
        "            patience: จำนวนรอบที่รอก่อนที่จะหยุดเมื่อไม่มีการปรับปรุง\n",
        "\n",
        "        Returns:\n",
        "            ประวัติการเทรน\n",
        "        \"\"\"\n",
        "        # เตรียมโมเดล\n",
        "        model = self.prepare_best_model()\n",
        "\n",
        "        # Callbacks\n",
        "        callbacks = [\n",
        "            # บันทึกโมเดลที่ดีที่สุด\n",
        "            ModelCheckpoint(\n",
        "                f'best_{self.best_model_name}_model.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            # ลด learning rate เมื่อไม่มีการปรับปรุง\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=10,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            # หยุดเมื่อไม่มีการปรับปรุง\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=patience,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # สร้าง datasets\n",
        "        train_dataset = self.create_train_dataset(batch_size=batch_size)\n",
        "        val_dataset = self.create_validation_dataset(batch_size=batch_size)\n",
        "\n",
        "        # ฝึกอบรมโมเดล\n",
        "        history = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=epochs,\n",
        "            validation_data=val_dataset,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # บันทึกโมเดลสุดท้าย\n",
        "        model.save(f'final_{self.best_model_name}_model.h5')\n",
        "\n",
        "        self.best_model = model  # อัปเดตโมเดลที่ดีที่สุด\n",
        "\n",
        "        return history\n",
        "\n",
        "    def evaluate_model(self):\n",
        "        \"\"\"\n",
        "        ประเมินโมเดลบนชุดข้อมูลทดสอบ\n",
        "\n",
        "        Returns:\n",
        "            ผลการประเมิน\n",
        "        \"\"\"\n",
        "        if self.best_model is None:\n",
        "            raise ValueError(\"โมเดลยังไม่ได้รับการฝึกอบรม\")\n",
        "\n",
        "        # ประเมินบนชุดข้อมูลทดสอบ\n",
        "        test_loss, test_acc = self.best_model.evaluate(self.X_test, self.y_test)\n",
        "        print(f\"ความแม่นยำบนชุดข้อมูลทดสอบ: {test_acc:.4f}\")\n",
        "\n",
        "        # ทำนายคลาส\n",
        "        y_pred = np.argmax(self.best_model.predict(self.X_test), axis=1)\n",
        "\n",
        "        # สร้าง confusion matrix\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "\n",
        "        # สร้างรายงานการจำแนก\n",
        "        report = classification_report(self.y_test, y_pred, output_dict=True)\n",
        "\n",
        "        return {\n",
        "            'test_accuracy': test_acc,\n",
        "            'test_loss': test_loss,\n",
        "            'confusion_matrix': cm,\n",
        "            'classification_report': report\n",
        "        }\n",
        "\n",
        "    def plot_training_history(self, history):\n",
        "        \"\"\"\n",
        "        วาดกราฟประวัติการเทรน\n",
        "\n",
        "        Args:\n",
        "            history: ประวัติการเทรนจาก model.fit()\n",
        "        \"\"\"\n",
        "        # สร้างกราฟ\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # กราฟค่า accuracy\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='train')\n",
        "        plt.plot(history.history['val_accuracy'], label='validation')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        # กราฟค่า loss\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='train')\n",
        "        plt.plot(history.history['val_loss'], label='validation')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{self.best_model_name}_training_history.png')\n",
        "        plt.show()\n",
        "\n",
        "    def plot_confusion_matrix(self, cm, class_names=None):\n",
        "        \"\"\"\n",
        "        วาดกราฟ confusion matrix\n",
        "\n",
        "        Args:\n",
        "            cm: confusion matrix\n",
        "            class_names: ชื่อคลาส (หากมี)\n",
        "        \"\"\"\n",
        "        if class_names is None:\n",
        "            class_names = [str(i) for i in range(self.num_classes)]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names,\n",
        "                   yticklabels=class_names)\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{self.best_model_name}_confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "    def analyze_errors(self, top_n=5):\n",
        "        \"\"\"\n",
        "        วิเคราะห์ข้อผิดพลาดที่พบบ่อย\n",
        "\n",
        "        Args:\n",
        "            top_n: จำนวนคู่ของความผิดพลาดที่พบบ่อยที่สุดที่จะแสดง\n",
        "        \"\"\"\n",
        "        # ทำนายบนชุดข้อมูลทดสอบ\n",
        "        y_pred = np.argmax(self.best_model.predict(self.X_test), axis=1)\n",
        "\n",
        "        # หาตัวอย่างที่ทำนายผิด\n",
        "        misclassified_indices = np.where(y_pred != self.y_test)[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"ไม่พบข้อผิดพลาดในการทำนาย!\")\n",
        "            return\n",
        "\n",
        "        # สร้างตารางคู่ของ (ป้ายกำกับจริง, ป้ายกำกับที่ทำนาย)\n",
        "        error_pairs = [(self.y_test[i], y_pred[i]) for i in misclassified_indices]\n",
        "\n",
        "        # นับความถี่ของแต่ละคู่\n",
        "        error_counts = {}\n",
        "        for true_label, pred_label in error_pairs:\n",
        "            key = (true_label, pred_label)\n",
        "            if key in error_counts:\n",
        "                error_counts[key] += 1\n",
        "            else:\n",
        "                error_counts[key] = 1\n",
        "\n",
        "        # เรียงลำดับตามความถี่\n",
        "        sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # แสดงคู่ที่พบบ่อยที่สุด\n",
        "        print(f\"คู่ของข้อผิดพลาดที่พบบ่อยที่สุด {min(top_n, len(sorted_errors))} คู่:\")\n",
        "        for (true_label, pred_label), count in sorted_errors[:top_n]:\n",
        "            print(f\"  ป้ายกำกับจริง: {true_label}, ทำนายเป็น: {pred_label}, จำนวน: {count} ครั้ง\")\n",
        "\n",
        "    def export_model_for_deployment(self, model_format='tflite'):\n",
        "        \"\"\"\n",
        "        ส่งออกโมเดลสำหรับการนำไปใช้งาน\n",
        "\n",
        "        Args:\n",
        "            model_format: รูปแบบของโมเดลที่จะส่งออก ('tflite' หรือ 'saved_model')\n",
        "\n",
        "        Returns:\n",
        "            พาธไปยังโมเดลที่ส่งออก\n",
        "        \"\"\"\n",
        "        if self.best_model is None:\n",
        "            raise ValueError(\"โมเดลยังไม่ได้รับการฝึกอบรม\")\n",
        "\n",
        "        if model_format == 'tflite':\n",
        "            # แปลงเป็น TFLite\n",
        "            converter = tf.lite.TFLiteConverter.from_keras_model(self.best_model)\n",
        "            tflite_model = converter.convert()\n",
        "\n",
        "            # บันทึกไฟล์\n",
        "            model_path = f'{self.best_model_name}_model.tflite'\n",
        "            with open(model_path, 'wb') as f:\n",
        "                f.write(tflite_model)\n",
        "\n",
        "            print(f\"ส่งออกโมเดล TFLite แล้วที่: {model_path}\")\n",
        "            return model_path\n",
        "\n",
        "        elif model_format == 'saved_model':\n",
        "            # บันทึกในรูปแบบ SavedModel\n",
        "            model_path = f'{self.best_model_name}_saved_model'\n",
        "            tf.saved_model.save(self.best_model, model_path)\n",
        "\n",
        "            print(f\"ส่งออกโมเดล SavedModel แล้วที่: {model_path}\")\n",
        "            return model_path\n",
        "\n",
        "        else:\n",
        "            raise ValueError(\"รูปแบบโมเดลไม่ถูกต้อง ต้องเป็น 'tflite' หรือ 'saved_model'\")\n",
        "\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "def main():\n",
        "    # สมมติว่าเรามีอ็อบเจ็กต์ SignLanguageModelSelector ที่สร้างไว้แล้ว\n",
        "    # และได้ทำการเปรียบเทียบโมเดลแล้ว\n",
        "    # model_selector = SignLanguageModelSelector(X_train, y_train, X_test, y_test)\n",
        "    # model_comparison = model_selector.compare_models()\n",
        "\n",
        "    # ในกรณีที่ต้องการทดสอบโดยไม่มี model_selector จริง\n",
        "    class DummyModelSelector:\n",
        "        def __init__(self):\n",
        "            # สร้างข้อมูลสมมติ\n",
        "            self.X_train = np.random.random((1000, 30, 42))\n",
        "            self.y_train = np.random.randint(0, 10, 1000)\n",
        "            self.X_test = np.random.random((200, 30, 42))\n",
        "            self.y_test = np.random.randint(0, 10, 200)\n",
        "\n",
        "        def create_lstm_model(self):\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.LSTM(64, input_shape=(30, 42), return_sequences=True),\n",
        "                tf.keras.layers.Dropout(0.3),\n",
        "                tf.keras.layers.LSTM(32),\n",
        "                tf.keras.layers.Dense(10, activation='softmax')\n",
        "            ])\n",
        "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            return model\n",
        "\n",
        "        def create_cnn_model(self):\n",
        "            model = tf.keras.Sequential([\n",
        "                tf.keras.layers.Conv1D(64, 3, input_shape=(30, 42), activation='relu'),\n",
        "                tf.keras.layers.MaxPooling1D(2),\n",
        "                tf.keras.layers.Flatten(),\n",
        "                tf.keras.layers.Dense(10, activation='softmax')\n",
        "            ])\n",
        "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            return model\n",
        "\n",
        "        def create_transformer_model(self):\n",
        "            inputs = tf.keras.Input(shape=(30, 42))\n",
        "            x = inputs\n",
        "            for _ in range(2):\n",
        "                x = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "                x = tf.keras.layers.LayerNormalization()(x)\n",
        "            x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "            x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "            outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "            model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "            model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "            return model\n",
        "\n",
        "    # สร้างอ็อบเจ็กต์ trainer\n",
        "    model_selector = DummyModelSelector()\n",
        "    trainer = SignLanguageModelTrainer(model_selector, best_model_name='LSTM')\n",
        "\n",
        "    # เทรนโมเดล\n",
        "    history = trainer.train_with_progressive_learning(epochs=50, batch_size=32)\n",
        "\n",
        "    # วาดกราฟประวัติการเทรน\n",
        "    trainer.plot_training_history(history)\n",
        "\n",
        "    # ประเมินโมเดล\n",
        "    eval_results = trainer.evaluate_model()\n",
        "\n",
        "    # วาดกราฟ confusion matrix\n",
        "    trainer.plot_confusion_matrix(eval_results['confusion_matrix'])\n",
        "\n",
        "    # วิเคราะห์ข้อผิดพลาด\n",
        "    trainer.analyze_errors()\n",
        "\n",
        "    # ส่งออกโมเดลสำหรับการนำไปใช้งาน\n",
        "    trainer.export_model_for_deployment()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "XQWxk5IMUaaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "FCo8wBR4U19p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "\n",
        "class SignLanguageTranslator:\n",
        "    def __init__(self, model_path):\n",
        "        # โหลดโมเดลที่ได้จากการเทรนเพิ่มเติม\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "        # ตั้งค่า MediaPipe Hands สำหรับการตรวจจับมือ\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.hands = self.mp_hands.Hands(\n",
        "            static_image_mode=False,\n",
        "            max_num_hands=1,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5\n",
        "        )\n",
        "\n",
        "        # คำแปลสัญญาณมือ (ตัวอย่าง)\n",
        "        self.sign_labels = [\"สวัสดี\", \"ขอบคุณ\", \"ช่วยเหลือ\", \"หิว\", \"น้ำ\", ...]\n",
        "\n",
        "        # ตัวแปรสำหรับเก็บตำแหน่งมือ\n",
        "        self.sequence = []\n",
        "        self.sequence_length = 30  # ต้องตรงกับ input shape ของโมเดล\n",
        "\n",
        "    def extract_hand_landmarks(self, frame):\n",
        "        # แปลงสีและประมวลผลภาพ\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.hands.process(image)\n",
        "\n",
        "        # เริ่มต้นด้วยค่าว่างเปล่า\n",
        "        landmarks = np.zeros(42)  # 21 landmarks x 2 (x, y)\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]  # เลือกมือแรก\n",
        "\n",
        "            # แปลงตำแหน่งเป็น array ขนาด 42\n",
        "            landmarks_array = []\n",
        "            for landmark in hand_landmarks.landmark:\n",
        "                landmarks_array.extend([landmark.x, landmark.y])\n",
        "\n",
        "            landmarks = np.array(landmarks_array)\n",
        "\n",
        "        return landmarks\n",
        "\n",
        "    def update_sequence(self, landmarks):\n",
        "        # เพิ่มตำแหน่งมือใหม่เข้าไปในลำดับ\n",
        "        self.sequence.append(landmarks)\n",
        "\n",
        "        # คงความยาวของลำดับที่ sequence_length\n",
        "        if len(self.sequence) > self.sequence_length:\n",
        "            self.sequence = self.sequence[-self.sequence_length:]\n",
        "\n",
        "    def predict_sign(self):\n",
        "        # ตรวจสอบว่ามีข้อมูลเพียงพอหรือไม่\n",
        "        if len(self.sequence) < self.sequence_length:\n",
        "            return None\n",
        "\n",
        "        # แปลงลำดับเป็น array รูปแบบที่โมเดลต้องการ\n",
        "        X = np.array([self.sequence])\n",
        "\n",
        "        # ทำนายด้วยโมเดล\n",
        "        prediction = self.model.predict(X)[0]\n",
        "\n",
        "        # หาคลาสที่มีความน่าจะเป็นสูงสุด\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        confidence = prediction[predicted_class]\n",
        "\n",
        "        # แสดงผลเฉพาะเมื่อความมั่นใจสูงพอ\n",
        "        if confidence > 0.7:\n",
        "            return self.sign_labels[predicted_class], confidence\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def run_webcam(self):\n",
        "        cap = cv2.VideoCapture(0)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                continue\n",
        "\n",
        "            # สกัดตำแหน่งมือ\n",
        "            landmarks = self.extract_hand_landmarks(frame)\n",
        "\n",
        "            # อัปเดตลำดับ\n",
        "            self.update_sequence(landmarks)\n",
        "\n",
        "            # ทำนายสัญญาณมือ\n",
        "            result = self.predict_sign()\n",
        "\n",
        "            # แสดงผลการทำนาย\n",
        "            if result:\n",
        "                sign, confidence = result\n",
        "                cv2.putText(frame, f\"{sign} ({confidence:.2f})\", (50, 50),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # แสดงเฟรม\n",
        "            cv2.imshow('Sign Language Translator', frame)\n",
        "\n",
        "            # กดปุ่ม q เพื่อออก\n",
        "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "translator = SignLanguageTranslator('final_LSTM_model.h5')\n",
        "translator.run_webcam()"
      ],
      "metadata": {
        "id": "ZviTVfR5U5yC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h2q27gKz1H20"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}