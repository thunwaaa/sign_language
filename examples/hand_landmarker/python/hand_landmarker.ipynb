{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunwaaa/sign_language/blob/main/examples/hand_landmarker/python/hand_landmarker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Hand Landmarks Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use MediaPipe Tasks Python API to detect hand landmarks from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf>=5.26.1,<6.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CyHeT5Wx0LNv",
        "outputId": "32a9441f-7d6a-4ba6-d7ff-fe52a1657a3d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/bin/bash: line 1: 6.0: No such file or directory\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l",
        "outputId": "749878b5-a5d7-4d5c-d127-41e4a4b7f87d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.11/dist-packages (4.11.0.86)\n",
            "Requirement already satisfied: numpy>=1.21.2 in /usr/local/lib/python3.11/dist-packages (from opencv-python) (1.26.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install opencv-python"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe --upgrade"
      ],
      "metadata": {
        "id": "ud9tSu78qK-N",
        "outputId": "eeaa85c5-8247-4ef9-e12c-6575e2b5c64f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: mediapipe in /usr/local/lib/python3.11/dist-packages (0.10.21)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.4.0)\n",
            "Requirement already satisfied: attrs>=19.1.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.3.0)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (25.2.10)\n",
            "Requirement already satisfied: jax in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.2)\n",
            "Requirement already satisfied: jaxlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.11/dist-packages (from mediapipe) (3.10.0)\n",
            "Requirement already satisfied: numpy<2 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (1.26.0)\n",
            "Requirement already satisfied: opencv-contrib-python in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.11.0.86)\n",
            "Requirement already satisfied: protobuf<5,>=4.25.3 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (4.25.6)\n",
            "Requirement already satisfied: sounddevice>=0.4.4 in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.5.1)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from mediapipe) (0.2.0)\n",
            "Requirement already satisfied: CFFI>=1.0 in /usr/local/lib/python3.11/dist-packages (from sounddevice>=0.4.4->mediapipe) (1.17.1)\n",
            "Requirement already satisfied: ml_dtypes>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (0.4.1)\n",
            "Requirement already satisfied: opt_einsum in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (3.4.0)\n",
            "Requirement already satisfied: scipy>=1.11.1 in /usr/local/lib/python3.11/dist-packages (from jax->mediapipe) (1.14.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (0.12.1)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (4.56.0)\n",
            "Requirement already satisfied: kiwisolver>=1.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (1.4.8)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (24.2)\n",
            "Requirement already satisfied: pillow>=8 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (11.1.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (3.2.1)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.11/dist-packages (from matplotlib->mediapipe) (2.8.2)\n",
            "Requirement already satisfied: pycparser in /usr/local/lib/python3.11/dist-packages (from CFFI>=1.0->sounddevice>=0.4.4->mediapipe) (2.22)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.7->matplotlib->mediapipe) (1.17.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy==1.26.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wOIHSoTM0-f8",
        "outputId": "0d86a22a-3b8f-4d66-fd32-64d0017d0e66"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy==1.26.0 in /usr/local/lib/python3.11/dist-packages (1.26.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model bundle. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker#models) for more information about this model bundle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [],
      "source": [
        "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe import solutions\n",
        "\n",
        "# Setup MediaPipe solutions\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Constants\n",
        "MARGIN = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "    hand_landmarks_list = detection_result.multi_hand_landmarks\n",
        "    handedness_list = detection_result.multi_handedness\n",
        "    annotated_image = np.copy(rgb_image)\n",
        "\n",
        "    # Loop through the detected hands to visualize.\n",
        "    for idx in range(len(hand_landmarks_list)):\n",
        "        hand_landmarks = hand_landmarks_list[idx]\n",
        "        handedness = handedness_list[idx]\n",
        "\n",
        "        # Draw the hand landmarks directly using MediaPipe's drawing utilities\n",
        "        mp_drawing.draw_landmarks(\n",
        "            annotated_image,\n",
        "            hand_landmarks,\n",
        "            mp_hands.HAND_CONNECTIONS,\n",
        "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "            mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "        # Get the top left corner of the detected hand's bounding box.\n",
        "        height, width, _ = annotated_image.shape\n",
        "        x_coordinates = [landmark.x for landmark in hand_landmarks.landmark]\n",
        "        y_coordinates = [landmark.y for landmark in hand_landmarks.landmark]\n",
        "        text_x = int(min(x_coordinates) * width)\n",
        "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
        "\n",
        "        # Draw handedness (left or right hand) on the image.\n",
        "        cv2.putText(annotated_image, f\"{handedness.classification[0].label}\",\n",
        "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
        "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
        "\n",
        "    return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "83PEJNp9yPBU"
      },
      "source": [
        "## Download test image\n",
        "\n",
        "Let's grab a test image that we'll use later. The image is from [Unsplash](https://unsplash.com/photos/mt2fyrdXxzk)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tzXuqyIBlXer",
        "collapsed": true
      },
      "outputs": [],
      "source": [
        "#"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw",
        "cellView": "form"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "# อัปโหลดวิดีโอหลายๆ ไฟล์\n",
        "uploaded = files.upload()\n",
        "\n",
        "# แสดงรายชื่อไฟล์วิดีโอที่อัปโหลด\n",
        "print(\"ไฟล์วิดีโอที่อัปโหลด:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"- {filename}\")\n",
        "\n",
        "# เก็บพาธของไฟล์วิดีโอทั้งหมด\n",
        "video_paths = list(uploaded.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "Here are the steps to run hand landmark detection using MediaPipe.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/python) to learn more about configuration options that this solution supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# import urllib.request\n",
        "\n",
        "# # MediaPipe initialization\n",
        "# BaseOptions = mp.tasks.BaseOptions\n",
        "# HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "# HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# # Create a hand landmarker instance with the video mode\n",
        "# options = HandLandmarkerOptions(\n",
        "#     base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
        "#     running_mode=VisionRunningMode.VIDEO,\n",
        "#     num_hands=2)\n",
        "\n",
        "# # Open the video file\n",
        "# cap = cv2.VideoCapture(input_video_path)\n",
        "# if not cap.isOpened():\n",
        "#     print(f\"Error: Could not open video file {input_video_path}\")\n",
        "#     exit()\n",
        "\n",
        "# # Get video properties\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# # Create video writer for output\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# with HandLandmarker.create_from_options(options) as landmarker:\n",
        "#     # Initialize timestamp\n",
        "#     timestamp = 0\n",
        "#     frame_count = 0\n",
        "\n",
        "#     while cap.isOpened():\n",
        "#         success, frame = cap.read()\n",
        "#         if not success:\n",
        "#             print(\"End of video or error reading frame.\")\n",
        "#             break\n",
        "\n",
        "#         frame_count += 1\n",
        "#         # Optional: Print progress\n",
        "#         if frame_count % 10 == 0:\n",
        "#             print(f\"Processing frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "#         # Convert to RGB (MediaPipe requirement)\n",
        "#         frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "#         # Process the frame\n",
        "#         results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "#         timestamp += 1\n",
        "\n",
        "#         # Create a black canvas instead of using the original frame\n",
        "#         canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "#         # Draw hand landmarks\n",
        "#         if results.hand_landmarks:\n",
        "#             for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "#                 # Get hand label (LEFT or RIGHT)\n",
        "#                 handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "#                 # Get center of hand for text placement\n",
        "#                 x_values = [landmark.x for landmark in hand_landmarks]\n",
        "#                 y_values = [landmark.y for landmark in hand_landmarks]\n",
        "#                 center_x = int(sum(x_values) / len(x_values) * width)\n",
        "#                 center_y = int(sum(y_values) / len(y_values) * height)\n",
        "\n",
        "#                 # Draw connections with white color\n",
        "#                 for connection in mp.solutions.hands.HAND_CONNECTIONS:\n",
        "#                     start_idx = connection[0]\n",
        "#                     end_idx = connection[1]\n",
        "\n",
        "#                     start_point = (int(hand_landmarks[start_idx].x * width),\n",
        "#                                   int(hand_landmarks[start_idx].y * height))\n",
        "#                     end_point = (int(hand_landmarks[end_idx].x * width),\n",
        "#                                 int(hand_landmarks[end_idx].y * height))\n",
        "\n",
        "#                     cv2.line(canvas, start_point, end_point, (255, 255, 255), 2)  # White lines\n",
        "\n",
        "#                 # Draw landmarks with light blue color\n",
        "#                 for landmark in hand_landmarks:\n",
        "#                     landmark_point = (int(landmark.x * width),\n",
        "#                                      int(landmark.y * height))\n",
        "#                     cv2.circle(canvas, landmark_point, 5, (255, 200, 0), -1)  # Light blue dots\n",
        "\n",
        "#                 # Display hand label\n",
        "#                 color = (255, 100, 100) if handedness == \"LEFT\" else (100, 100, 255)  # Different colors for left/right\n",
        "#                 text_position = (center_x, center_y - 30)\n",
        "#                 cv2.putText(canvas, handedness, text_position,\n",
        "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "#         # Write the canvas to output video\n",
        "#         out.write(canvas)\n",
        "\n",
        "#         # Optional: Display the frame (comment out for faster processing)\n",
        "#         # cv2.imshow('Processing Video', canvas)\n",
        "#         # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         #     break\n",
        "\n",
        "# # Release resources\n",
        "# cap.release()\n",
        "# out.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# print(f\"Processing complete. Output saved to {output_video_path}\")\n",
        "\n",
        "# files.download(output_video_path)"
      ],
      "metadata": {
        "id": "0HLgVzd8A3qT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import mediapipe as mp\n",
        "from google.colab import files\n",
        "\n",
        "def process_video_to_json(input_video_path, gesture_label):\n",
        "    \"\"\"\n",
        "    Process a video and extract hand landmarks to a JSON file\n",
        "\n",
        "    Args:\n",
        "        input_video_path: Path to the input video file\n",
        "        gesture_label: Label for the gesture being performed in the video\n",
        "    \"\"\"\n",
        "    # MediaPipe initialization\n",
        "    BaseOptions = mp.tasks.BaseOptions\n",
        "    HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "    HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "    # Create output JSON path\n",
        "    output_json_path = os.path.splitext(input_video_path)[0] + \"_landmarks.json\"\n",
        "\n",
        "    # Create a hand landmarker instance with the video mode\n",
        "    options = HandLandmarkerOptions(\n",
        "        base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
        "        running_mode=VisionRunningMode.VIDEO,\n",
        "        num_hands=2)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {input_video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Initialize data structure for JSON\n",
        "    video_landmarks = {\n",
        "        'video_id': os.path.splitext(os.path.basename(input_video_path))[0],\n",
        "        'gesture_label': gesture_label,\n",
        "        'fps': fps,\n",
        "        'total_frames': total_frames,\n",
        "        'frames': []\n",
        "    }\n",
        "\n",
        "    with HandLandmarker.create_from_options(options) as landmarker:\n",
        "        # Initialize timestamp\n",
        "        timestamp = 0\n",
        "        frame_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            # Optional: Print progress\n",
        "            if frame_count % 10 == 0:\n",
        "                print(f\"Processing {input_video_path} - frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "            # Convert to RGB (MediaPipe requirement)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "            # Process the frame\n",
        "            results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "\n",
        "            # Calculate timestamp in seconds\n",
        "            timestamp_seconds = frame_count / fps\n",
        "\n",
        "            # Frame landmark data\n",
        "            frame_data = {\n",
        "                'frame_number': frame_count,\n",
        "                'timestamp': timestamp_seconds,\n",
        "                'hands': []\n",
        "            }\n",
        "\n",
        "            # Write hand landmarks to JSON\n",
        "            if results.hand_landmarks:\n",
        "                for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "                    # Get hand label (LEFT or RIGHT)\n",
        "                    handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "                    # Prepare hand landmarks\n",
        "                    hand_data = {\n",
        "                        'hand_type': handedness,\n",
        "                        'landmarks': []\n",
        "                    }\n",
        "\n",
        "                    # Process each landmark\n",
        "                    for landmark_idx, landmark in enumerate(hand_landmarks):\n",
        "                        hand_data['landmarks'].append({\n",
        "                            'landmark_id': landmark_idx,\n",
        "                            'x': landmark.x,\n",
        "                            'y': landmark.y,\n",
        "                            'z': landmark.z\n",
        "                        })\n",
        "\n",
        "                    frame_data['hands'].append(hand_data)\n",
        "\n",
        "            # Add frame data if landmarks were detected\n",
        "            if frame_data['hands']:\n",
        "                video_landmarks['frames'].append(frame_data)\n",
        "\n",
        "            timestamp += 1\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(video_landmarks, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"Processing complete. Landmarks saved to {output_json_path}\")\n",
        "    return output_json_path\n",
        "\n",
        "# อัปโหลดวิดีโอหลายๆ ไฟล์\n",
        "uploaded = files.upload()\n",
        "\n",
        "# ให้ผู้ใช้ระบุท่าทางสำหรับทุกวิดีโอ\n",
        "gesture_label = input(\"กรุณาระบุชื่อท่าทาง (เช่น hello, thank_you, เป็นต้น): \")\n",
        "\n",
        "# เก็บ JSON paths\n",
        "json_paths = []\n",
        "\n",
        "# ประมวลผลวิดีโอแต่ละไฟล์\n",
        "for video_path in uploaded.keys():\n",
        "    json_path = process_video_to_json(video_path, gesture_label)\n",
        "    if json_path:\n",
        "        json_paths.append(json_path)\n",
        "\n",
        "# ดาวน์โหลด JSON ทุกไฟล์\n",
        "for json_path in json_paths:\n",
        "    files.download(json_path)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "n4QL0iI0tHqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "รวบรวมข้อมูลจากทุกไฟล์ JSONในโฟลเดอร์เพื่อเพิ่มความหลากหลายและความครอบคลุมของข้อมูล"
      ],
      "metadata": {
        "id": "RzxvsUVWtQtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE6_sPCXaX3g",
        "outputId": "775e1b09-2eb3-4186-a640-5862cac9e125",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 48\n",
            "First frame hands: [{'hand_type': 'Right', 'landmarks': [{'landmark_id': 0, 'x': 0.3443603515625, 'y': 0.8842741250991821, 'z': -1.2120239034629776e-07}, {'landmark_id': 1, 'x': 0.3644331097602844, 'y': 0.8599238991737366, 'z': -0.011832674033939838}, {'landmark_id': 2, 'x': 0.3963460624217987, 'y': 0.8404296040534973, 'z': -0.024631474167108536}, {'landmark_id': 3, 'x': 0.4157256782054901, 'y': 0.817276656627655, 'z': -0.03736870363354683}, {'landmark_id': 4, 'x': 0.4262501895427704, 'y': 0.7945399284362793, 'z': -0.051433876156806946}, {'landmark_id': 5, 'x': 0.3917095363140106, 'y': 0.8760520219802856, 'z': -0.028685227036476135}, {'landmark_id': 6, 'x': 0.39549970626831055, 'y': 0.8848051428794861, 'z': -0.04091654717922211}, {'landmark_id': 7, 'x': 0.3912796974182129, 'y': 0.8867673873901367, 'z': -0.050275832414627075}, {'landmark_id': 8, 'x': 0.3873821794986725, 'y': 0.8901175260543823, 'z': -0.05685688555240631}, {'landmark_id': 9, 'x': 0.37654221057891846, 'y': 0.8978257775306702, 'z': -0.031112365424633026}, {'landmark_id': 10, 'x': 0.378012478351593, 'y': 0.9083337187767029, 'z': -0.03854791074991226}, {'landmark_id': 11, 'x': 0.37466102838516235, 'y': 0.9164374470710754, 'z': -0.04330039769411087}, {'landmark_id': 12, 'x': 0.36829978227615356, 'y': 0.9262263178825378, 'z': -0.049453482031822205}, {'landmark_id': 13, 'x': 0.3617047667503357, 'y': 0.9162315130233765, 'z': -0.03365695849061012}, {'landmark_id': 14, 'x': 0.3638369143009186, 'y': 0.9308955669403076, 'z': -0.04276951029896736}, {'landmark_id': 15, 'x': 0.3610232174396515, 'y': 0.9408990144729614, 'z': -0.045151643455028534}, {'landmark_id': 16, 'x': 0.35710710287094116, 'y': 0.9519602060317993, 'z': -0.04805188253521919}, {'landmark_id': 17, 'x': 0.3480346202850342, 'y': 0.929940938949585, 'z': -0.03702634945511818}, {'landmark_id': 18, 'x': 0.3505946695804596, 'y': 0.9457376003265381, 'z': -0.042815931141376495}, {'landmark_id': 19, 'x': 0.3502313196659088, 'y': 0.9566890001296997, 'z': -0.04101055487990379}, {'landmark_id': 20, 'x': 0.34839701652526855, 'y': 0.9680348634719849, 'z': -0.04078099876642227}]}]\n",
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 71\n",
            "First frame hands: [{'hand_type': 'Left', 'landmarks': [{'landmark_id': 0, 'x': 0.313771516084671, 'y': 0.965537428855896, 'z': 6.655710649283719e-08}, {'landmark_id': 1, 'x': 0.33894914388656616, 'y': 0.9624893665313721, 'z': -0.01324852742254734}, {'landmark_id': 2, 'x': 0.3651532530784607, 'y': 0.9597474932670593, 'z': -0.02734268642961979}, {'landmark_id': 3, 'x': 0.38185915350914, 'y': 0.9462862610816956, 'z': -0.040745045989751816}, {'landmark_id': 4, 'x': 0.3951246738433838, 'y': 0.928407609462738, 'z': -0.05534052103757858}, {'landmark_id': 5, 'x': 0.3457489311695099, 'y': 0.9973787665367126, 'z': -0.02553163468837738}, {'landmark_id': 6, 'x': 0.34966057538986206, 'y': 1.0136758089065552, 'z': -0.03490730747580528}, {'landmark_id': 7, 'x': 0.35407447814941406, 'y': 1.0211808681488037, 'z': -0.0427650548517704}, {'landmark_id': 8, 'x': 0.35813602805137634, 'y': 1.0253467559814453, 'z': -0.04839610680937767}, {'landmark_id': 9, 'x': 0.32744839787483215, 'y': 1.0084896087646484, 'z': -0.02498994581401348}, {'landmark_id': 10, 'x': 0.330170214176178, 'y': 1.0241668224334717, 'z': -0.030123215168714523}, {'landmark_id': 11, 'x': 0.33367758989334106, 'y': 1.0326827764511108, 'z': -0.03432246297597885}, {'landmark_id': 12, 'x': 0.3354494571685791, 'y': 1.0380380153656006, 'z': -0.03895440697669983}, {'landmark_id': 13, 'x': 0.3111916482448578, 'y': 1.0136781930923462, 'z': -0.024743519723415375}, {'landmark_id': 14, 'x': 0.3121773898601532, 'y': 1.0311639308929443, 'z': -0.02734994888305664}, {'landmark_id': 15, 'x': 0.3166219890117645, 'y': 1.0430494546890259, 'z': -0.028940189629793167}, {'landmark_id': 16, 'x': 0.319950670003891, 'y': 1.0535268783569336, 'z': -0.031719405204057693}, {'landmark_id': 17, 'x': 0.2987765669822693, 'y': 1.01531183719635, 'z': -0.025887951254844666}, {'landmark_id': 18, 'x': 0.2969945967197418, 'y': 1.030174732208252, 'z': -0.027802305296063423}, {'landmark_id': 19, 'x': 0.2986973524093628, 'y': 1.0404858589172363, 'z': -0.026696864515542984}, {'landmark_id': 20, 'x': 0.3009161353111267, 'y': 1.0494894981384277, 'z': -0.026672838255763054}]}]\n",
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 71\n",
            "First frame hands: [{'hand_type': 'Left', 'landmarks': [{'landmark_id': 0, 'x': 0.313771516084671, 'y': 0.965537428855896, 'z': 6.655710649283719e-08}, {'landmark_id': 1, 'x': 0.33894914388656616, 'y': 0.9624893665313721, 'z': -0.01324852742254734}, {'landmark_id': 2, 'x': 0.3651532530784607, 'y': 0.9597474932670593, 'z': -0.02734268642961979}, {'landmark_id': 3, 'x': 0.38185915350914, 'y': 0.9462862610816956, 'z': -0.040745045989751816}, {'landmark_id': 4, 'x': 0.3951246738433838, 'y': 0.928407609462738, 'z': -0.05534052103757858}, {'landmark_id': 5, 'x': 0.3457489311695099, 'y': 0.9973787665367126, 'z': -0.02553163468837738}, {'landmark_id': 6, 'x': 0.34966057538986206, 'y': 1.0136758089065552, 'z': -0.03490730747580528}, {'landmark_id': 7, 'x': 0.35407447814941406, 'y': 1.0211808681488037, 'z': -0.0427650548517704}, {'landmark_id': 8, 'x': 0.35813602805137634, 'y': 1.0253467559814453, 'z': -0.04839610680937767}, {'landmark_id': 9, 'x': 0.32744839787483215, 'y': 1.0084896087646484, 'z': -0.02498994581401348}, {'landmark_id': 10, 'x': 0.330170214176178, 'y': 1.0241668224334717, 'z': -0.030123215168714523}, {'landmark_id': 11, 'x': 0.33367758989334106, 'y': 1.0326827764511108, 'z': -0.03432246297597885}, {'landmark_id': 12, 'x': 0.3354494571685791, 'y': 1.0380380153656006, 'z': -0.03895440697669983}, {'landmark_id': 13, 'x': 0.3111916482448578, 'y': 1.0136781930923462, 'z': -0.024743519723415375}, {'landmark_id': 14, 'x': 0.3121773898601532, 'y': 1.0311639308929443, 'z': -0.02734994888305664}, {'landmark_id': 15, 'x': 0.3166219890117645, 'y': 1.0430494546890259, 'z': -0.028940189629793167}, {'landmark_id': 16, 'x': 0.319950670003891, 'y': 1.0535268783569336, 'z': -0.031719405204057693}, {'landmark_id': 17, 'x': 0.2987765669822693, 'y': 1.01531183719635, 'z': -0.025887951254844666}, {'landmark_id': 18, 'x': 0.2969945967197418, 'y': 1.030174732208252, 'z': -0.027802305296063423}, {'landmark_id': 19, 'x': 0.2986973524093628, 'y': 1.0404858589172363, 'z': -0.026696864515542984}, {'landmark_id': 20, 'x': 0.3009161353111267, 'y': 1.0494894981384277, 'z': -0.026672838255763054}]}]\n",
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 71\n",
            "First frame hands: [{'hand_type': 'Left', 'landmarks': [{'landmark_id': 0, 'x': 0.313771516084671, 'y': 0.965537428855896, 'z': 6.655710649283719e-08}, {'landmark_id': 1, 'x': 0.33894914388656616, 'y': 0.9624893665313721, 'z': -0.01324852742254734}, {'landmark_id': 2, 'x': 0.3651532530784607, 'y': 0.9597474932670593, 'z': -0.02734268642961979}, {'landmark_id': 3, 'x': 0.38185915350914, 'y': 0.9462862610816956, 'z': -0.040745045989751816}, {'landmark_id': 4, 'x': 0.3951246738433838, 'y': 0.928407609462738, 'z': -0.05534052103757858}, {'landmark_id': 5, 'x': 0.3457489311695099, 'y': 0.9973787665367126, 'z': -0.02553163468837738}, {'landmark_id': 6, 'x': 0.34966057538986206, 'y': 1.0136758089065552, 'z': -0.03490730747580528}, {'landmark_id': 7, 'x': 0.35407447814941406, 'y': 1.0211808681488037, 'z': -0.0427650548517704}, {'landmark_id': 8, 'x': 0.35813602805137634, 'y': 1.0253467559814453, 'z': -0.04839610680937767}, {'landmark_id': 9, 'x': 0.32744839787483215, 'y': 1.0084896087646484, 'z': -0.02498994581401348}, {'landmark_id': 10, 'x': 0.330170214176178, 'y': 1.0241668224334717, 'z': -0.030123215168714523}, {'landmark_id': 11, 'x': 0.33367758989334106, 'y': 1.0326827764511108, 'z': -0.03432246297597885}, {'landmark_id': 12, 'x': 0.3354494571685791, 'y': 1.0380380153656006, 'z': -0.03895440697669983}, {'landmark_id': 13, 'x': 0.3111916482448578, 'y': 1.0136781930923462, 'z': -0.024743519723415375}, {'landmark_id': 14, 'x': 0.3121773898601532, 'y': 1.0311639308929443, 'z': -0.02734994888305664}, {'landmark_id': 15, 'x': 0.3166219890117645, 'y': 1.0430494546890259, 'z': -0.028940189629793167}, {'landmark_id': 16, 'x': 0.319950670003891, 'y': 1.0535268783569336, 'z': -0.031719405204057693}, {'landmark_id': 17, 'x': 0.2987765669822693, 'y': 1.01531183719635, 'z': -0.025887951254844666}, {'landmark_id': 18, 'x': 0.2969945967197418, 'y': 1.030174732208252, 'z': -0.027802305296063423}, {'landmark_id': 19, 'x': 0.2986973524093628, 'y': 1.0404858589172363, 'z': -0.026696864515542984}, {'landmark_id': 20, 'x': 0.3009161353111267, 'y': 1.0494894981384277, 'z': -0.026672838255763054}]}]\n",
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 71\n",
            "First frame hands: [{'hand_type': 'Left', 'landmarks': [{'landmark_id': 0, 'x': 0.313771516084671, 'y': 0.965537428855896, 'z': 6.655710649283719e-08}, {'landmark_id': 1, 'x': 0.33894914388656616, 'y': 0.9624893665313721, 'z': -0.01324852742254734}, {'landmark_id': 2, 'x': 0.3651532530784607, 'y': 0.9597474932670593, 'z': -0.02734268642961979}, {'landmark_id': 3, 'x': 0.38185915350914, 'y': 0.9462862610816956, 'z': -0.040745045989751816}, {'landmark_id': 4, 'x': 0.3951246738433838, 'y': 0.928407609462738, 'z': -0.05534052103757858}, {'landmark_id': 5, 'x': 0.3457489311695099, 'y': 0.9973787665367126, 'z': -0.02553163468837738}, {'landmark_id': 6, 'x': 0.34966057538986206, 'y': 1.0136758089065552, 'z': -0.03490730747580528}, {'landmark_id': 7, 'x': 0.35407447814941406, 'y': 1.0211808681488037, 'z': -0.0427650548517704}, {'landmark_id': 8, 'x': 0.35813602805137634, 'y': 1.0253467559814453, 'z': -0.04839610680937767}, {'landmark_id': 9, 'x': 0.32744839787483215, 'y': 1.0084896087646484, 'z': -0.02498994581401348}, {'landmark_id': 10, 'x': 0.330170214176178, 'y': 1.0241668224334717, 'z': -0.030123215168714523}, {'landmark_id': 11, 'x': 0.33367758989334106, 'y': 1.0326827764511108, 'z': -0.03432246297597885}, {'landmark_id': 12, 'x': 0.3354494571685791, 'y': 1.0380380153656006, 'z': -0.03895440697669983}, {'landmark_id': 13, 'x': 0.3111916482448578, 'y': 1.0136781930923462, 'z': -0.024743519723415375}, {'landmark_id': 14, 'x': 0.3121773898601532, 'y': 1.0311639308929443, 'z': -0.02734994888305664}, {'landmark_id': 15, 'x': 0.3166219890117645, 'y': 1.0430494546890259, 'z': -0.028940189629793167}, {'landmark_id': 16, 'x': 0.319950670003891, 'y': 1.0535268783569336, 'z': -0.031719405204057693}, {'landmark_id': 17, 'x': 0.2987765669822693, 'y': 1.01531183719635, 'z': -0.025887951254844666}, {'landmark_id': 18, 'x': 0.2969945967197418, 'y': 1.030174732208252, 'z': -0.027802305296063423}, {'landmark_id': 19, 'x': 0.2986973524093628, 'y': 1.0404858589172363, 'z': -0.026696864515542984}, {'landmark_id': 20, 'x': 0.3009161353111267, 'y': 1.0494894981384277, 'z': -0.026672838255763054}]}]\n",
            "Video data keys: dict_keys(['video_id', 'gesture_label', 'fps', 'total_frames', 'frames'])\n",
            "Number of frames: 71\n",
            "First frame hands: [{'hand_type': 'Left', 'landmarks': [{'landmark_id': 0, 'x': 0.313771516084671, 'y': 0.965537428855896, 'z': 6.655710649283719e-08}, {'landmark_id': 1, 'x': 0.33894914388656616, 'y': 0.9624893665313721, 'z': -0.01324852742254734}, {'landmark_id': 2, 'x': 0.3651532530784607, 'y': 0.9597474932670593, 'z': -0.02734268642961979}, {'landmark_id': 3, 'x': 0.38185915350914, 'y': 0.9462862610816956, 'z': -0.040745045989751816}, {'landmark_id': 4, 'x': 0.3951246738433838, 'y': 0.928407609462738, 'z': -0.05534052103757858}, {'landmark_id': 5, 'x': 0.3457489311695099, 'y': 0.9973787665367126, 'z': -0.02553163468837738}, {'landmark_id': 6, 'x': 0.34966057538986206, 'y': 1.0136758089065552, 'z': -0.03490730747580528}, {'landmark_id': 7, 'x': 0.35407447814941406, 'y': 1.0211808681488037, 'z': -0.0427650548517704}, {'landmark_id': 8, 'x': 0.35813602805137634, 'y': 1.0253467559814453, 'z': -0.04839610680937767}, {'landmark_id': 9, 'x': 0.32744839787483215, 'y': 1.0084896087646484, 'z': -0.02498994581401348}, {'landmark_id': 10, 'x': 0.330170214176178, 'y': 1.0241668224334717, 'z': -0.030123215168714523}, {'landmark_id': 11, 'x': 0.33367758989334106, 'y': 1.0326827764511108, 'z': -0.03432246297597885}, {'landmark_id': 12, 'x': 0.3354494571685791, 'y': 1.0380380153656006, 'z': -0.03895440697669983}, {'landmark_id': 13, 'x': 0.3111916482448578, 'y': 1.0136781930923462, 'z': -0.024743519723415375}, {'landmark_id': 14, 'x': 0.3121773898601532, 'y': 1.0311639308929443, 'z': -0.02734994888305664}, {'landmark_id': 15, 'x': 0.3166219890117645, 'y': 1.0430494546890259, 'z': -0.028940189629793167}, {'landmark_id': 16, 'x': 0.319950670003891, 'y': 1.0535268783569336, 'z': -0.031719405204057693}, {'landmark_id': 17, 'x': 0.2987765669822693, 'y': 1.01531183719635, 'z': -0.025887951254844666}, {'landmark_id': 18, 'x': 0.2969945967197418, 'y': 1.030174732208252, 'z': -0.027802305296063423}, {'landmark_id': 19, 'x': 0.2986973524093628, 'y': 1.0404858589172363, 'z': -0.026696864515542984}, {'landmark_id': 20, 'x': 0.3009161353111267, 'y': 1.0494894981384277, 'z': -0.026672838255763054}]}]\n",
            "Processed 6 samples\n",
            "Labels: ['1' '2' '3' '4' '5' '6']\n",
            "X shape: (6, 30, 42, 3)\n",
            "y shape: (6,)\n",
            "X data type: float64\n",
            "First sample landmarks:\n",
            " [[[ 3.44360352e-01  8.84274125e-01 -1.21202390e-07]\n",
            "  [ 3.64433110e-01  8.59923899e-01 -1.18326740e-02]\n",
            "  [ 3.96346062e-01  8.40429604e-01 -2.46314742e-02]\n",
            "  ...\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 7.29501367e-01  8.63729835e-01  1.12840510e-07]\n",
            "  [ 6.90021217e-01  8.46877098e-01 -1.17434524e-02]\n",
            "  [ 6.52324378e-01  8.21962655e-01 -1.73570961e-02]\n",
            "  ...\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " [[ 3.83579999e-01  8.00637722e-01 -1.82753766e-07]\n",
            "  [ 3.86588991e-01  7.51460016e-01 -1.59670447e-03]\n",
            "  [ 4.05757695e-01  7.06058204e-01 -2.82378448e-03]\n",
            "  ...\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]\n",
            "  [ 0.00000000e+00  0.00000000e+00  0.00000000e+00]]\n",
            "\n",
            " ...\n",
            "\n",
            " [[ 2.55094498e-01  6.40974641e-01  2.95267114e-07]\n",
            "  [ 2.95845807e-01  6.04234457e-01 -2.00469792e-02]\n",
            "  [ 3.18398595e-01  5.64660788e-01 -2.78833471e-02]\n",
            "  ...\n",
            "  [ 9.10462499e-01  5.23058534e-01 -5.44627868e-02]\n",
            "  [ 9.20367599e-01  4.95648563e-01 -6.18618689e-02]\n",
            "  [ 9.27102983e-01  4.71317589e-01 -6.71759248e-02]]\n",
            "\n",
            " [[ 2.60009855e-01  6.40743792e-01  2.59795769e-07]\n",
            "  [ 2.99506515e-01  6.05670393e-01 -1.79596972e-02]\n",
            "  [ 3.20508569e-01  5.64368427e-01 -2.51179654e-02]\n",
            "  ...\n",
            "  [ 9.06240582e-01  5.20821214e-01 -5.05960733e-02]\n",
            "  [ 9.15365696e-01  4.94664669e-01 -5.75650260e-02]\n",
            "  [ 9.22449350e-01  4.71186817e-01 -6.27173781e-02]]\n",
            "\n",
            " [[ 2.60789365e-01  6.42462552e-01  2.64734950e-07]\n",
            "  [ 3.01472038e-01  6.05071306e-01 -1.61170084e-02]\n",
            "  [ 3.23409796e-01  5.64894855e-01 -2.21730992e-02]\n",
            "  ...\n",
            "  [ 9.02085423e-01  5.23621559e-01 -5.11308126e-02]\n",
            "  [ 9.10061419e-01  4.98639643e-01 -5.87712787e-02]\n",
            "  [ 9.15895164e-01  4.75986898e-01 -6.49307817e-02]]]\n",
            "Labels: [5 1 4 2 0 3]\n",
            "Shape of training data: (4, 30, 42, 3)\n",
            "Unique labels: ['1' '2' '3' '4' '5' '6']\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "\n",
        "def preprocess_sign_language_data(data_directory):\n",
        "    \"\"\"\n",
        "    Preprocess sign language data from JSON files\n",
        "\n",
        "    Args:\n",
        "        data_directory: Path to directory containing JSON files\n",
        "\n",
        "    Returns:\n",
        "        X: Processed feature data\n",
        "        y: Corresponding labels\n",
        "    \"\"\"\n",
        "    # เก็บข้อมูลทั้งหมด\n",
        "    all_landmarks = []\n",
        "    all_labels = []\n",
        "\n",
        "    # เพิ่มการตรวจสอบก่อนเริ่มทำงาน\n",
        "    if not os.path.exists(data_directory):\n",
        "        print(f\"Error: Directory {data_directory} does not exist!\")\n",
        "        return [], [], None # Return empty lists and None instead of None, None, None\n",
        "\n",
        "   # วนลูปผ่านไฟล์ JSON โดยตรง\n",
        "    for json_file in os.listdir(data_directory):\n",
        "        if json_file.endswith('.json'):\n",
        "            file_path = os.path.join(data_directory, json_file)\n",
        "\n",
        "            try:\n",
        "                # โหลดข้อมูล JSON\n",
        "                with open(file_path, 'r') as f:\n",
        "                    video_data = json.load(f)\n",
        "\n",
        "                # สกัดคุณลักษณะ\n",
        "                processed_landmarks = process_video_landmarks(video_data)\n",
        "\n",
        "                # เพิ่มข้อมูล\n",
        "                all_landmarks.append(processed_landmarks)\n",
        "                # ใช้ชื่อไฟล์เป็นฉลาก\n",
        "                all_labels.append(json_file.split('_')[0])\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    # ถ้าไม่พบไฟล์ JSON เลย\n",
        "    if not all_landmarks:\n",
        "        print(f\"No JSON files found in directory {data_directory}\")\n",
        "        return [], [], None # Return empty lists and None instead of None, None, None\n",
        "\n",
        "    # แปลง list เป็น numpy array\n",
        "    X = np.array(all_landmarks)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(all_labels)\n",
        "\n",
        "    # พิมพ์ข้อมูลดีบัก\n",
        "    print(f\"Processed {len(X)} samples\")\n",
        "    print(f\"Labels: {label_encoder.classes_}\")\n",
        "\n",
        "    return X, y, label_encoder\n",
        "\n",
        "def process_video_landmarks(video_data):\n",
        "    \"\"\"\n",
        "    แปลงข้อมูลแลนด์มาร์คจาก JSON เป็นชุดข้อมูลที่เหมาะสำหรับโมเดล\n",
        "\n",
        "    Args:\n",
        "        video_data: ข้อมูล JSON ของวิดีโอ\n",
        "\n",
        "    Returns:\n",
        "        processed_landmarks: อาร์เรย์ของแลนด์มาร์ค\n",
        "    \"\"\"\n",
        "    # เลือกเฟรมที่มีการตรวจจับมือ\n",
        "    hand_frames = [frame for frame in video_data['frames'] if frame['hands']]\n",
        "\n",
        "    # เลือกเฟรมทั้งหมด (หรือจำกัดจำนวนเฟรม)\n",
        "    selected_frames = hand_frames[:30]  # จำกัดที่ 30 เฟรม\n",
        "\n",
        "    # เตรียมอาร์เรย์เก็บแลนด์มาร์ค\n",
        "    landmarks_sequence = []\n",
        "\n",
        "    for frame in selected_frames:\n",
        "        # สำหรับแต่ละมือในเฟรม\n",
        "        frame_landmarks = []\n",
        "        for hand in frame['hands']:\n",
        "            # สกัด x, y, z ของแต่ละจุด\n",
        "            hand_landmarks = [\n",
        "                [landmark['x'], landmark['y'], landmark['z']]\n",
        "                for landmark in hand['landmarks']\n",
        "            ]\n",
        "            frame_landmarks.extend(hand_landmarks)\n",
        "\n",
        "        # padding หากมีจุดไม่ครบ\n",
        "        while len(frame_landmarks) < 42:  # 21 จุด * 2 มือ\n",
        "            frame_landmarks.append([0, 0, 0])\n",
        "\n",
        "        landmarks_sequence.append(frame_landmarks[:42])\n",
        "\n",
        "    # padding sequence ให้มีความยาวคงที่\n",
        "    while len(landmarks_sequence) < 30:\n",
        "        landmarks_sequence.append([[0, 0, 0]] * 42)\n",
        "\n",
        "    # เพิ่มในฟังก์ชัน process_video_landmarks เพื่อดีบัก\n",
        "    print(\"Video data keys:\", video_data.keys())\n",
        "    print(\"Number of frames:\", len(video_data['frames']))\n",
        "    print(\"First frame hands:\", video_data['frames'][0]['hands'])\n",
        "\n",
        "    return np.array(landmarks_sequence)\n",
        "\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "data_directory = '/content/hi'  # ตรวจสอบให้แน่ใจว่าพาธนี้ถูกต้อง\n",
        "# Check if the directory exists\n",
        "if not os.path.exists(data_directory):\n",
        "    print(f\"Error: Directory '{data_directory}' does not exist. Please create it and add your JSON files.\")\n",
        "else:\n",
        "    # Check if the directory contains any JSON files\n",
        "    json_files = [f for f in os.listdir(data_directory) if f.endswith('.json')]\n",
        "    if not json_files:\n",
        "        print(f\"Error: Directory '{data_directory}' does not contain any JSON files. Please add your JSON files.\")\n",
        "    else:\n",
        "        X, y, label_encoder = preprocess_sign_language_data(data_directory)\n",
        "\n",
        "        if len(X) > 0 and len(y) > 0 and label_encoder is not None:\n",
        "\n",
        "          # เพิ่มบรรทัดนี้ก่อนการแบ่งข้อมูล\n",
        "            print(\"X shape:\", X.shape)\n",
        "            print(\"y shape:\", y.shape)\n",
        "            print(\"X data type:\", X.dtype)\n",
        "            print(\"First sample landmarks:\\n\", X[0])\n",
        "            print(\"Labels:\", y)\n",
        "            # แบ่งข้อมูล\n",
        "            X_train, X_test, y_train, y_test = train_test_split(\n",
        "                X, y, test_size=0.2, random_state=42\n",
        "            )\n",
        "\n",
        "            print(\"Shape of training data:\", X_train.shape)\n",
        "            print(\"Unique labels:\", label_encoder.classes_)\n",
        "        else:\n",
        "            print(\"No data to process. Check your JSON files.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "Y8K_zntKDLri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เพิ่มความหลากหลายของข้อมูล สร้างข้อมูลเทียม เพิ่มความทนทานของโมเดล"
      ],
      "metadata": {
        "id": "pWzZTi7LDU0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class SignLanguageDataAugmentation:\n",
        "    def __init__(self, original_data):\n",
        "        \"\"\"\n",
        "        เตรียมการเพิ่มความหลากหลายของข้อมูลภาษามือ\n",
        "\n",
        "        Args:\n",
        "            original_data: ข้อมูลแลนด์มาร์คเดิม\n",
        "        \"\"\"\n",
        "        self.original_data = original_data\n",
        "\n",
        "    def add_noise(self, data, noise_level=0.02):\n",
        "        \"\"\"\n",
        "        เพิ่มความคลาดเคลื่อนเล็กน้อยในข้อมูล\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            noise_level: ระดับความคลาดเคลื่อน\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่เพิ่มความคลาดเคลื่อน\n",
        "        \"\"\"\n",
        "        noise = np.random.normal(\n",
        "            loc=0,\n",
        "            scale=noise_level,\n",
        "            size=data.shape\n",
        "        )\n",
        "        return data + noise\n",
        "\n",
        "    def time_warping(self, data, max_warp=5):\n",
        "        \"\"\"\n",
        "        ยืดหรือบีบเวลาของลำดับการเคลื่อนไหว\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            max_warp: จำนวนเฟรมสูงสุดที่จะยืดหรือบีบ\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกดัดแปลงเวลา\n",
        "        \"\"\"\n",
        "        # สุ่มเลือกจุดที่จะยืดหรือบีบ\n",
        "        warp_point = random.randint(0, len(data) - max_warp - 1)\n",
        "\n",
        "        # สร้างข้อมูลใหม่\n",
        "        warped_data = np.copy(data)\n",
        "\n",
        "        # ซ้ำหรือลบเฟรมบางส่วน\n",
        "        insert_point = random.randint(0, max_warp)\n",
        "        warped_data = np.insert(\n",
        "            warped_data,\n",
        "            warp_point + insert_point,\n",
        "            warped_data[warp_point:warp_point+max_warp],\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        # ตัดให้มีความยาวคงเดิม\n",
        "        return warped_data[:len(data)]\n",
        "\n",
        "    def hand_rotation(self, data):\n",
        "        \"\"\"\n",
        "        หมุนตำแหน่งมือ\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกหมุน\n",
        "        \"\"\"\n",
        "        # สุ่มมุมหมุน\n",
        "        angle = np.random.uniform(-30, 30)\n",
        "\n",
        "        # แปลงเป็นเรเดียน\n",
        "        angle_rad = np.deg2rad(angle)\n",
        "\n",
        "        # เมทริกซ์หมุน\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "            [np.sin(angle_rad), np.cos(angle_rad)]\n",
        "        ])\n",
        "\n",
        "        # คัดลอกข้อมูล\n",
        "        rotated_data = np.copy(data)\n",
        "\n",
        "        # หมุนพิกัด x, y\n",
        "        for i in range(len(rotated_data)):\n",
        "            for j in range(0, len(rotated_data[i]), 3):\n",
        "                rotated_data[i][j:j+2] = np.dot(\n",
        "                    rotation_matrix,\n",
        "                    rotated_data[i][j:j+2]\n",
        "                )\n",
        "\n",
        "        return rotated_data\n",
        "\n",
        "    def generate_augmented_data(self, num_augmentations=5):\n",
        "        \"\"\"\n",
        "        สร้างชุดข้อมูลเพิ่มเติม\n",
        "\n",
        "        Args:\n",
        "            num_augmentations: จำนวนข้อมูลที่ต้องการสร้าง\n",
        "\n",
        "        Returns:\n",
        "            ชุดข้อมูลที่ถูกเพิ่มความหลากหลาย\n",
        "        \"\"\"\n",
        "        augmented_data = []\n",
        "\n",
        "        for _ in range(num_augmentations):\n",
        "            # สุ่มเลือกข้อมูลต้นฉบับ\n",
        "            base_data = random.choice(self.original_data)\n",
        "\n",
        "            # เพิ่มความหลากหลาย\n",
        "            augmented_sample = self.add_noise(base_data)\n",
        "            augmented_sample = self.time_warping(augmented_sample)\n",
        "            augmented_sample = self.hand_rotation(augmented_sample)\n",
        "\n",
        "            augmented_data.append(augmented_sample)\n",
        "\n",
        "        return augmented_data\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "# สมมติ X คือชุดข้อมูลเดิม\n",
        "augmentor = SignLanguageDataAugmentation(X)\n",
        "augmented_X = augmentor.generate_augmented_data()\n",
        "\n",
        "# รวมข้อมูล\n",
        "X_augmented = np.concatenate([X, augmented_X])\n",
        "y_augmented = np.concatenate([y, y[:len(augmented_X)]])"
      ],
      "metadata": {
        "id": "NePB3X4-Da4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "2NxeR7VwDr47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สกัดคุณลักษณะพิเศษ\n",
        "คำนวณความเร็ว ความเร่ง\n",
        "วิเคราะห์คุณสมบัติทางสถิติ\n",
        "\n"
      ],
      "metadata": {
        "id": "gVAMip17DvxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "class SignLanguageFeatureExtractor:\n",
        "    def __init__(self, landmarks_data):\n",
        "        \"\"\"\n",
        "        สกัดคุณลักษณะพิเศษจากข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Args:\n",
        "            landmarks_data: ข้อมูลแลนด์มาร์คภาษามือ\n",
        "        \"\"\"\n",
        "        self.landmarks_data = landmarks_data\n",
        "\n",
        "    def calculate_hand_velocity(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร็วของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร็วมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        velocities = []\n",
        "        for sequence in self.landmarks_data:\n",
        "            frame_velocities = []\n",
        "            for frame_idx in range(1, len(sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงตำแหน่ง\n",
        "                prev_frame = sequence[frame_idx-1]\n",
        "                curr_frame = sequence[frame_idx]\n",
        "\n",
        "                # คำนวณความเร็ว\n",
        "                frame_velocity = np.linalg.norm(\n",
        "                    curr_frame[:21*3] - prev_frame[:21*3]\n",
        "                )\n",
        "                frame_velocities.append(frame_velocity)\n",
        "\n",
        "            velocities.append(frame_velocities)\n",
        "\n",
        "        return np.array(velocities)\n",
        "\n",
        "    def calculate_hand_acceleration(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร่งของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร่งมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        accelerations = []\n",
        "        velocities = self.calculate_hand_velocity()\n",
        "\n",
        "        for velocity_sequence in velocities:\n",
        "            frame_accelerations = []\n",
        "            for frame_idx in range(1, len(velocity_sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงความเร็ว\n",
        "                acceleration = abs(\n",
        "                    velocity_sequence[frame_idx] -\n",
        "                    velocity_sequence[frame_idx-1]\n",
        "                )\n",
        "                frame_accelerations.append(acceleration)\n",
        "\n",
        "            accelerations.append(frame_accelerations)\n",
        "\n",
        "        return np.array(accelerations)\n",
        "\n",
        "    def calculate_statistical_features(self):\n",
        "        \"\"\"\n",
        "        คำนวณคุณลักษณะทางสถิติ\n",
        "\n",
        "        Returns:\n",
        "            พจนานุกรมของคุณลักษณะทางสถิติ\n",
        "        \"\"\"\n",
        "        features = []\n",
        "\n",
        "        for sequence in self.landmarks_data:\n",
        "            sequence_features = {}\n",
        "\n",
        "            # คำนวณคุณลักษณะสำหรับแต่ละมือ\n",
        "            for hand_start in [0, 21*3]:\n",
        "                hand_landmarks = sequence[:, hand_start:hand_start+21*3]\n",
        "\n",
        "                # สถิติพื้นฐาน\n",
        "                sequence_features.update({\n",
        "                    f'hand_{hand_start//63}_mean': np.mean(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_std': np.std(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_skewness': skew(hand_landmarks.flatten()),\n",
        "                    f'hand_{hand_start//63}_kurtosis': kurtosis(hand_landmarks.flatten())\n",
        "                })\n",
        "\n",
        "            features.append(sequence_features)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def extract_advanced_features(self):\n",
        "        \"\"\"\n",
        "        สกัดคุณลักษณะขั้นสูง\n",
        "\n",
        "        Returns:\n",
        "            เมทริกซ์คุณลักษณะ\n",
        "        \"\"\"\n",
        "        # รวบรวมคุณลักษณะต่างๆ\n",
        "        velocities = self.calculate_hand_velocity()\n",
        "        accelerations = self.calculate_hand_acceleration()\n",
        "        statistical_features = self.calculate_statistical_features()\n",
        "\n",
        "        # แปลงเป็นรูปแบบที่เหมาะสมสำหรับโมเดล\n",
        "        feature_matrix = []\n",
        "        for i in range(len(self.landmarks_data)):\n",
        "            features = np.concatenate([\n",
        "                np.mean(velocities[i]),\n",
        "                np.mean(accelerations[i]),\n",
        "                list(statistical_features[i].values())\n",
        "            ])\n",
        "            feature_matrix.append(features)\n",
        "\n",
        "        return np.array(feature_matrix)\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "feature_extractor = SignLanguageFeatureExtractor(X)\n",
        "X_advanced_features = feature_extractor.extract_advanced_features()"
      ],
      "metadata": {
        "id": "33HFkVbfD2Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SXpVnlrhD_FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดสอบหลายสถาปัตยกรรม\n",
        "LSTM, CNN, Transformer\n",
        "เปรียบเทียบประสิทธิภาพ และ ค้นหาพารามิเตอร์ที่เหมาะสม\n",
        "ใช้ Random Search\n",
        "ปรับแต่งโมเดลให้ดีขึ้น"
      ],
      "metadata": {
        "id": "cE6HGY7gEAKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "class SignLanguageModelSelector:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        เลือกและปรับแต่งโมเดลสำหรับภาษามือ\n",
        "\n",
        "        Args:\n",
        "            X_train: ข้อมูลฝึกอบรม\n",
        "            y_train: ป้ายกำกับการฝึกอบรม\n",
        "            X_test: ข้อมูลทดสอบ\n",
        "            y_test: ป้ายกำกับการทดสอบ\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # โมเดลที่จะทดสอบ\n",
        "        self.models = {\n",
        "            'LSTM': self.create_lstm_model,\n",
        "            'CNN': self.create_cnn_model,\n",
        "            'Transformer': self.create_transformer_model\n",
        "        }\n",
        "\n",
        "    def create_lstm_model(self, units=64, dropout=0.3):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล LSTM\n",
        "\n",
        "        Args:\n",
        "            units: จำนวนหน่วยใน LSTM layer\n",
        "            dropout: อัตราการ dropout\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.LSTM(\n",
        "                units,\n",
        "                input_shape=(30, 42),\n",
        "                return_sequences=True\n",
        "            ),\n",
        "            tf.keras.layers.Dropout(dropout),\n",
        "            tf.keras.layers.LSTM(units//2),\n",
        "            tf.keras.layers.Dense(\n",
        "                len(np.unique(self.y_train)),\n",
        "                activation='softmax'\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_cnn_model(self, filters=64, kernel_size=3):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล CNN\n",
        "\n",
        "        Args:\n",
        "            filters: จำนวน filters\n",
        "            kernel_size: ขนาด kernel\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        model = tf.keras.Sequential([\n",
        "            tf.keras.layers.Conv1D(\n",
        "                filters,\n",
        "                kernel_size,\n",
        "                input_shape=(30, 42),\n",
        "                activation='relu'\n",
        "            ),\n",
        "            tf.keras.layers.MaxPooling1D(2),\n",
        "            tf.keras.layers.Flatten(),\n",
        "            tf.keras.layers.Dense(\n",
        "                len(np.unique(self.y_train)),\n",
        "                activation='softmax'\n",
        "            )\n",
        "        ])\n",
        "\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def create_transformer_model(self, num_heads=4, ff_dim=32):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล Transformer\n",
        "\n",
        "        Args:\n",
        "            num_heads: จำนวน attention heads\n",
        "            ff_dim: ขนาดของ feed-forward layer\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        inputs = tf.keras.Input(shape=(30, 42))\n",
        "\n",
        "        # Transformer Encoder\n",
        "        x = inputs\n",
        "        for _ in range(2):\n",
        "            x = tf.keras.layers.MultiHeadAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=ff_dim\n",
        "            )(x, x)\n",
        "            x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
        "        outputs = tf.keras.layers.Dense(\n",
        "            len(np.unique(self.y_train)),\n",
        "            activation='softmax'\n",
        "        )(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def hyperparameter_tuning(self):\n",
        "        \"\"\"\n",
        "        ปรับแต่งพารามิเตอร์โดยใช้ Random Search\n",
        "\n",
        "        Returns:\n",
        "            โมเดลที่ดีที่สุด\n",
        "        \"\"\"\n",
        "        # เตรียม Keras Classifier\n",
        "        model = KerasClassifier(\n",
        "            build_fn=self.create_lstm_model,\n",
        "            verbose=0\n",
        "        )\n",
        "\n",
        "        # ช่วงพารามิเตอร์\n",
        "        param_dist = {\n",
        "            'units': [32, 64, 128],\n",
        "            'dropout': uniform(0.2, 0.5),\n",
        "            'batch_size': [16, 32, 64],\n",
        "            'epochs': [50, 100, 200]\n",
        "        }\n",
        "\n",
        "        # Random Search\n",
        "        random_search = RandomizedSearchCV(\n",
        "            estimator=model,\n",
        "            param_distributions=param_dist,\n",
        "            n_iter=10,\n",
        "            cv=3,\n",
        "            scoring='accuracy'\n",
        "        )\n",
        "\n",
        "        random_search.fit(\n",
        "            self.X_train,\n",
        "            self.y_train,\n",
        "            validation_split=0.2\n",
        "        )\n",
        "\n",
        "        return random_search.best_estimator_\n",
        "\n",
        "    def compare_models(self):\n",
        "        \"\"\"\n",
        "        เปรียบเทียบประสิทธิภาพโมเดล\n",
        "\n",
        "        Returns:\n",
        "            พจนานุกรมผลลัพธ์\n",
        "        \"\"\"\n",
        "        results = {}\n",
        "\n",
        "        for name, model_creator in self.models.items():\n",
        "            # สร้างโมเดล\n",
        "            model = model_creator()\n",
        "\n",
        "            # ฝึกอบรม\n",
        "            history = model.fit(\n",
        "                self.X_train, self.y_train,\n",
        "                validation_split=0.2,\n",
        "                epochs=50,\n",
        "                batch_size=32\n",
        "            )\n",
        "\n",
        "            # ประเมินผล\n",
        "            test_loss, test_accuracy = model.evaluate(\n",
        "                self.X_test, self.y_test\n",
        "            )\n",
        "\n",
        "            results[name] = {\n",
        "                'test_accuracy': test_accuracy,\n",
        "                'test_loss': test_loss,\n",
        "                'training_history': history\n",
        "            }\n",
        "\n",
        "        return results\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "model_selector = SignLanguageModelSelector(\n",
        "    X_train, y_train, X_test, y_test\n",
        ")\n",
        "\n",
        "# เปรียบเทียบโมเดล\n",
        "model_comparison = model_selector.compare_models()\n",
        "\n",
        "# ปรับแต่งพารามิเตอร์\n",
        "best_model = model_selector.hyperparameter_tuning()"
      ],
      "metadata": {
        "id": "HV2v4z-ZEEhE"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h2q27gKz1H20"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}