{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunwaaa/sign_language/blob/main/examples/hand_landmarker/python/hand_landmarker.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "h2q27gKz1H20"
      },
      "source": [
        "##### Copyright 2023 The MediaPipe Authors. All Rights Reserved."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TUfAcER1oUS6"
      },
      "outputs": [],
      "source": [
        "#@title Licensed under the Apache License, Version 2.0 (the \"License\");\n",
        "# you may not use this file except in compliance with the License.\n",
        "# You may obtain a copy of the License at\n",
        "#\n",
        "# https://www.apache.org/licenses/LICENSE-2.0\n",
        "#\n",
        "# Unless required by applicable law or agreed to in writing, software\n",
        "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
        "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
        "# See the License for the specific language governing permissions and\n",
        "# limitations under the License."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L_cQX8dWu4Dv"
      },
      "source": [
        "# Hand Landmarks Detection with MediaPipe Tasks\n",
        "\n",
        "This notebook shows you how to use MediaPipe Tasks Python API to detect hand landmarks from images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O6PN9FvIx614"
      },
      "source": [
        "## Preparation\n",
        "\n",
        "Let's start with installing MediaPipe."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install protobuf>=5.29.1"
      ],
      "metadata": {
        "id": "CyHeT5Wx0LNv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gxbHBsF-8Y_l"
      },
      "outputs": [],
      "source": [
        "!pip install opencv-python tqdm numpy mediapipe"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install mediapipe"
      ],
      "metadata": {
        "id": "ud9tSu78qK-N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install numpy"
      ],
      "metadata": {
        "id": "wOIHSoTM0-f8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a49D7h4TVmru"
      },
      "source": [
        "Then download an off-the-shelf model bundle. Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker#models) for more information about this model bundle."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OMjuVQiDYJKF"
      },
      "outputs": [],
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YYKAJ5nDU8-I"
      },
      "source": [
        "## Visualization utilities"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "s3E6NFV-00Qt"
      },
      "outputs": [],
      "source": [
        "#@markdown We implemented some functions to visualize the hand landmark detection results. <br/> Run the following cell to activate the functions.\n",
        "\n",
        "import cv2\n",
        "import numpy as np\n",
        "import mediapipe as mp\n",
        "from mediapipe import solutions\n",
        "\n",
        "# Setup MediaPipe solutions\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_drawing = mp.solutions.drawing_utils\n",
        "mp_drawing_styles = mp.solutions.drawing_styles\n",
        "\n",
        "# Constants\n",
        "MARGIN = 10  # pixels\n",
        "FONT_SIZE = 1\n",
        "FONT_THICKNESS = 1\n",
        "HANDEDNESS_TEXT_COLOR = (88, 205, 54)  # vibrant green\n",
        "\n",
        "def draw_landmarks_on_image(rgb_image, detection_result):\n",
        "    hand_landmarks_list = detection_result.multi_hand_landmarks\n",
        "    handedness_list = detection_result.multi_handedness\n",
        "    annotated_image = np.copy(rgb_image)\n",
        "\n",
        "    # Loop through the detected hands to visualize.\n",
        "    for idx in range(len(hand_landmarks_list)):\n",
        "        hand_landmarks = hand_landmarks_list[idx]\n",
        "        handedness = handedness_list[idx]\n",
        "\n",
        "        # Draw the hand landmarks directly using MediaPipe's drawing utilities\n",
        "        mp_drawing.draw_landmarks(\n",
        "            annotated_image,\n",
        "            hand_landmarks,\n",
        "            mp_hands.HAND_CONNECTIONS,\n",
        "            mp_drawing_styles.get_default_hand_landmarks_style(),\n",
        "            mp_drawing_styles.get_default_hand_connections_style())\n",
        "\n",
        "        # Get the top left corner of the detected hand's bounding box.\n",
        "        height, width, _ = annotated_image.shape\n",
        "        x_coordinates = [landmark.x for landmark in hand_landmarks.landmark]\n",
        "        y_coordinates = [landmark.y for landmark in hand_landmarks.landmark]\n",
        "        text_x = int(min(x_coordinates) * width)\n",
        "        text_y = int(min(y_coordinates) * height) - MARGIN\n",
        "\n",
        "        # Draw handedness (left or right hand) on the image.\n",
        "        cv2.putText(annotated_image, f\"{handedness.classification[0].label}\",\n",
        "                    (text_x, text_y), cv2.FONT_HERSHEY_DUPLEX,\n",
        "                    FONT_SIZE, HANDEDNESS_TEXT_COLOR, FONT_THICKNESS, cv2.LINE_AA)\n",
        "\n",
        "    return annotated_image"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-skLwMBmMN_"
      },
      "source": [
        "Optionally, you can upload your own image. If you want to do so, uncomment and run the cell below."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "etBjSdwImQPw"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import numpy as np\n",
        "import time\n",
        "import os\n",
        "\n",
        "from google.colab import files\n",
        "# อัปโหลดวิดีโอหลายๆ ไฟล์\n",
        "uploaded = files.upload()\n",
        "\n",
        "# แสดงรายชื่อไฟล์วิดีโอที่อัปโหลด\n",
        "print(\"ไฟล์วิดีโอที่อัปโหลด:\")\n",
        "for filename in uploaded.keys():\n",
        "    print(f\"- {filename}\")\n",
        "\n",
        "# เก็บพาธของไฟล์วิดีโอทั้งหมด\n",
        "video_paths = list(uploaded.keys())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Iy4r2_ePylIa"
      },
      "source": [
        "## Running inference and visualizing the results\n",
        "\n",
        "Here are the steps to run hand landmark detection using MediaPipe.\n",
        "\n",
        "Check out the [MediaPipe documentation](https://developers.google.com/mediapipe/solutions/vision/hand_landmarker/python) to learn more about configuration options that this solution supports.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# @title\n",
        "# import urllib.request\n",
        "\n",
        "# # MediaPipe initialization\n",
        "# BaseOptions = mp.tasks.BaseOptions\n",
        "# HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "# HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "# VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "# # Create a hand landmarker instance with the video mode\n",
        "# options = HandLandmarkerOptions(\n",
        "#     base_options=BaseOptions(model_asset_path='hand_landmarker.task'),\n",
        "#     running_mode=VisionRunningMode.VIDEO,\n",
        "#     num_hands=2)\n",
        "\n",
        "# # Open the video file\n",
        "# cap = cv2.VideoCapture(input_video_path)\n",
        "# if not cap.isOpened():\n",
        "#     print(f\"Error: Could not open video file {input_video_path}\")\n",
        "#     exit()\n",
        "\n",
        "# # Get video properties\n",
        "# width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "# height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "# fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "# total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "# # Create video writer for output\n",
        "# fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "# out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "# with HandLandmarker.create_from_options(options) as landmarker:\n",
        "#     # Initialize timestamp\n",
        "#     timestamp = 0\n",
        "#     frame_count = 0\n",
        "\n",
        "#     while cap.isOpened():\n",
        "#         success, frame = cap.read()\n",
        "#         if not success:\n",
        "#             print(\"End of video or error reading frame.\")\n",
        "#             break\n",
        "\n",
        "#         frame_count += 1\n",
        "#         # Optional: Print progress\n",
        "#         if frame_count % 10 == 0:\n",
        "#             print(f\"Processing frame {frame_count}/{total_frames} ({frame_count/total_frames*100:.1f}%)\")\n",
        "\n",
        "#         # Convert to RGB (MediaPipe requirement)\n",
        "#         frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "#         mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "#         # Process the frame\n",
        "#         results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "#         timestamp += 1\n",
        "\n",
        "#         # Create a black canvas instead of using the original frame\n",
        "#         canvas = np.zeros((height, width, 3), dtype=np.uint8)\n",
        "\n",
        "#         # Draw hand landmarks\n",
        "#         if results.hand_landmarks:\n",
        "#             for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "#                 # Get hand label (LEFT or RIGHT)\n",
        "#                 handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "#                 # Get center of hand for text placement\n",
        "#                 x_values = [landmark.x for landmark in hand_landmarks]\n",
        "#                 y_values = [landmark.y for landmark in hand_landmarks]\n",
        "#                 center_x = int(sum(x_values) / len(x_values) * width)\n",
        "#                 center_y = int(sum(y_values) / len(y_values) * height)\n",
        "\n",
        "#                 # Draw connections with white color\n",
        "#                 for connection in mp.solutions.hands.HAND_CONNECTIONS:\n",
        "#                     start_idx = connection[0]\n",
        "#                     end_idx = connection[1]\n",
        "\n",
        "#                     start_point = (int(hand_landmarks[start_idx].x * width),\n",
        "#                                   int(hand_landmarks[start_idx].y * height))\n",
        "#                     end_point = (int(hand_landmarks[end_idx].x * width),\n",
        "#                                 int(hand_landmarks[end_idx].y * height))\n",
        "\n",
        "#                     cv2.line(canvas, start_point, end_point, (255, 255, 255), 2)  # White lines\n",
        "\n",
        "#                 # Draw landmarks with light blue color\n",
        "#                 for landmark in hand_landmarks:\n",
        "#                     landmark_point = (int(landmark.x * width),\n",
        "#                                      int(landmark.y * height))\n",
        "#                     cv2.circle(canvas, landmark_point, 5, (255, 200, 0), -1)  # Light blue dots\n",
        "\n",
        "#                 # Display hand label\n",
        "#                 color = (255, 100, 100) if handedness == \"LEFT\" else (100, 100, 255)  # Different colors for left/right\n",
        "#                 text_position = (center_x, center_y - 30)\n",
        "#                 cv2.putText(canvas, handedness, text_position,\n",
        "#                            cv2.FONT_HERSHEY_SIMPLEX, 1, color, 2)\n",
        "\n",
        "#         # Write the canvas to output video\n",
        "#         out.write(canvas)\n",
        "\n",
        "#         # Optional: Display the frame (comment out for faster processing)\n",
        "#         # cv2.imshow('Processing Video', canvas)\n",
        "#         # if cv2.waitKey(1) & 0xFF == ord('q'):\n",
        "#         #     break\n",
        "\n",
        "# # Release resources\n",
        "# cap.release()\n",
        "# out.release()\n",
        "# cv2.destroyAllWindows()\n",
        "\n",
        "# print(f\"Processing complete. Output saved to {output_video_path}\")\n",
        "\n",
        "# files.download(output_video_path)"
      ],
      "metadata": {
        "id": "0HLgVzd8A3qT",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_JVO3rvPD4RN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import cv2\n",
        "import json\n",
        "import mediapipe as mp\n",
        "from google.colab import drive\n",
        "from tqdm.notebook import tqdm\n",
        "import numpy as np\n",
        "\n",
        "# เชื่อมต่อกับ Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "def process_video_to_json(input_video_path, gesture_label, output_dir=None):\n",
        "    \"\"\"\n",
        "    Process a video and extract hand landmarks to a JSON file\n",
        "\n",
        "    Args:\n",
        "        input_video_path: Path to the input video file\n",
        "        gesture_label: Label for the gesture being performed in the video\n",
        "        output_dir: Directory to save the JSON file (if None, save in the same directory as the video)\n",
        "\n",
        "    Returns:\n",
        "        output_json_path: Path to the saved JSON file\n",
        "    \"\"\"\n",
        "    # MediaPipe initialization\n",
        "    BaseOptions = mp.tasks.BaseOptions\n",
        "    HandLandmarker = mp.tasks.vision.HandLandmarker\n",
        "    HandLandmarkerOptions = mp.tasks.vision.HandLandmarkerOptions\n",
        "    VisionRunningMode = mp.tasks.vision.RunningMode\n",
        "\n",
        "    # Check if model file exists, if not download it\n",
        "    model_path = 'hand_landmarker.task'\n",
        "    if not os.path.exists(model_path):\n",
        "        print(\"กำลังดาวน์โหลดโมเดล HandLandmarker...\")\n",
        "        !wget -q -O hand_landmarker.task https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task\n",
        "        print(\"ดาวน์โหลดเสร็จสิ้น\")\n",
        "\n",
        "    # Create output JSON path\n",
        "    if output_dir is None:\n",
        "        output_json_path = os.path.splitext(input_video_path)[0] + \"_landmarks.json\"\n",
        "    else:\n",
        "        # สร้างโฟลเดอร์ถ้ายังไม่มี\n",
        "        os.makedirs(output_dir, exist_ok=True)\n",
        "        # ใช้ชื่อไฟล์เดิมแต่เปลี่ยนนามสกุลเป็น .json และเก็บในโฟลเดอร์ output_dir\n",
        "        base_filename = os.path.splitext(os.path.basename(input_video_path))[0]\n",
        "        output_json_path = os.path.join(output_dir, f\"{base_filename}_landmarks.json\")\n",
        "\n",
        "    # Create a hand landmarker instance with the video mode\n",
        "    options = HandLandmarkerOptions(\n",
        "        base_options=BaseOptions(model_asset_path=model_path),\n",
        "        running_mode=VisionRunningMode.VIDEO,\n",
        "        num_hands=2)\n",
        "\n",
        "    # Open the video file\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"Error: Could not open video file {input_video_path}\")\n",
        "        return None\n",
        "\n",
        "    # Get video properties\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # Initialize data structure for JSON\n",
        "    video_landmarks = {\n",
        "        'video_id': os.path.splitext(os.path.basename(input_video_path))[0],\n",
        "        'gesture_label': gesture_label,\n",
        "        'fps': fps,\n",
        "        'total_frames': total_frames,\n",
        "        'frames': []\n",
        "    }\n",
        "\n",
        "    with HandLandmarker.create_from_options(options) as landmarker:\n",
        "        # Initialize timestamp\n",
        "        timestamp = 0\n",
        "        frame_count = 0\n",
        "\n",
        "        # ใช้ tqdm สำหรับแสดง progress bar\n",
        "        pbar = tqdm(total=total_frames, desc=f\"กำลังประมวลผล {os.path.basename(input_video_path)}\")\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "            # Convert to RGB (MediaPipe requirement)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "            mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=frame_rgb)\n",
        "\n",
        "            # Process the frame\n",
        "            results = landmarker.detect_for_video(mp_image, timestamp)\n",
        "\n",
        "            # Calculate timestamp in seconds\n",
        "            timestamp_seconds = frame_count / fps\n",
        "\n",
        "            # Frame landmark data\n",
        "            frame_data = {\n",
        "                'frame_number': frame_count,\n",
        "                'timestamp': timestamp_seconds,\n",
        "                'hands': []\n",
        "            }\n",
        "\n",
        "            # Write hand landmarks to JSON\n",
        "            if results.hand_landmarks:\n",
        "                for idx, hand_landmarks in enumerate(results.hand_landmarks):\n",
        "                    # Get hand label (LEFT or RIGHT)\n",
        "                    handedness = results.handedness[idx][0].category_name\n",
        "\n",
        "                    # Prepare hand landmarks\n",
        "                    hand_data = {\n",
        "                        'hand_type': handedness,\n",
        "                        'landmarks': []\n",
        "                    }\n",
        "\n",
        "                    # Process each landmark\n",
        "                    for landmark_idx, landmark in enumerate(hand_landmarks):\n",
        "                        hand_data['landmarks'].append({\n",
        "                            'landmark_id': landmark_idx,\n",
        "                            'x': landmark.x,\n",
        "                            'y': landmark.y,\n",
        "                            'z': landmark.z\n",
        "                        })\n",
        "\n",
        "                    frame_data['hands'].append(hand_data)\n",
        "\n",
        "            # Add frame data if landmarks were detected\n",
        "            if frame_data['hands']:\n",
        "                video_landmarks['frames'].append(frame_data)\n",
        "\n",
        "            timestamp += 1\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "    # Release resources\n",
        "    cap.release()\n",
        "\n",
        "    # Save to JSON\n",
        "    with open(output_json_path, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(video_landmarks, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"การประมวลผลเสร็จสิ้น บันทึกตำแหน่งมือไปยัง {output_json_path}\")\n",
        "    return output_json_path\n",
        "\n",
        "def process_folder_structure(base_dir, output_base_dir):\n",
        "    \"\"\"\n",
        "    Process all videos in a folder structure where each subfolder represents a sign language word\n",
        "\n",
        "    Args:\n",
        "        base_dir: Base directory containing subfolders with videos\n",
        "        output_base_dir: Base directory to save output JSON files\n",
        "    \"\"\"\n",
        "    # ตรวจสอบว่าโฟลเดอร์ฐานข้อมูลมีอยู่จริง\n",
        "    if not os.path.exists(base_dir):\n",
        "        print(f\"ไม่พบโฟลเดอร์ {base_dir}\")\n",
        "        return\n",
        "\n",
        "    # สร้างโฟลเดอร์ output หลัก\n",
        "    os.makedirs(output_base_dir, exist_ok=True)\n",
        "\n",
        "    # หาโฟลเดอร์ย่อยทั้งหมด (แต่ละโฟลเดอร์แทนคำในภาษามือ)\n",
        "    word_folders = [d for d in os.listdir(base_dir) if os.path.isdir(os.path.join(base_dir, d))]\n",
        "\n",
        "    # สร้าง dictionary เพื่อเก็บสถิติ\n",
        "    stats = {\n",
        "        'total_words': len(word_folders),\n",
        "        'total_videos': 0,\n",
        "        'processed_videos': 0,\n",
        "        'failed_videos': 0,\n",
        "        'words_info': {}\n",
        "    }\n",
        "\n",
        "    print(f\"พบทั้งหมด {len(word_folders)} คำในภาษามือ\")\n",
        "\n",
        "    # วนลูปผ่านแต่ละโฟลเดอร์ย่อย (แต่ละคำ)\n",
        "    for word_folder in tqdm(word_folders, desc=\"กำลังประมวลผลคำในภาษามือ\"):\n",
        "        # เตรียมข้อมูลสำหรับคำนี้\n",
        "        word_path = os.path.join(base_dir, word_folder)\n",
        "        word_output_path = os.path.join(output_base_dir, word_folder)\n",
        "\n",
        "        # สร้างโฟลเดอร์ output สำหรับคำนี้\n",
        "        os.makedirs(word_output_path, exist_ok=True)\n",
        "\n",
        "        # หาไฟล์วิดีโอทั้งหมดในโฟลเดอร์นี้\n",
        "        video_files = [f for f in os.listdir(word_path)\n",
        "                      if f.lower().endswith(('.mp4', '.avi', '.mov', '.MP4', '.AVI', '.MOV'))]\n",
        "\n",
        "        # อัปเดตสถิติ\n",
        "        stats['total_videos'] += len(video_files)\n",
        "        stats['words_info'][word_folder] = {\n",
        "            'total_videos': len(video_files),\n",
        "            'processed_videos': 0,\n",
        "            'failed_videos': 0\n",
        "        }\n",
        "\n",
        "        print(f\"\\nกำลังประมวลผลคำ '{word_folder}' - พบ {len(video_files)} วิดีโอ\")\n",
        "\n",
        "        # วนลูปผ่านแต่ละไฟล์วิดีโอในโฟลเดอร์นี้\n",
        "        for video_file in video_files:\n",
        "            video_path = os.path.join(word_path, video_file)\n",
        "\n",
        "            try:\n",
        "                # กำหนดป้ายกำกับจากชื่อโฟลเดอร์\n",
        "                gesture_label = word_folder\n",
        "\n",
        "                # ประมวลผลวิดีโอ\n",
        "                json_path = process_video_to_json(video_path, gesture_label, word_output_path)\n",
        "\n",
        "                if json_path:\n",
        "                    stats['processed_videos'] += 1\n",
        "                    stats['words_info'][word_folder]['processed_videos'] += 1\n",
        "                else:\n",
        "                    stats['failed_videos'] += 1\n",
        "                    stats['words_info'][word_folder]['failed_videos'] += 1\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"เกิดข้อผิดพลาดในการประมวลผล {video_path}: {e}\")\n",
        "                stats['failed_videos'] += 1\n",
        "                stats['words_info'][word_folder]['failed_videos'] += 1\n",
        "\n",
        "    # แสดงสรุปผล\n",
        "    print(\"\\n========== สรุปผลการประมวลผล ==========\")\n",
        "    print(f\"จำนวนคำทั้งหมด: {stats['total_words']}\")\n",
        "    print(f\"จำนวนวิดีโอทั้งหมด: {stats['total_videos']}\")\n",
        "    print(f\"จำนวนวิดีโอที่ประมวลผลสำเร็จ: {stats['processed_videos']}\")\n",
        "    print(f\"จำนวนวิดีโอที่ประมวลผลล้มเหลว: {stats['failed_videos']}\")\n",
        "\n",
        "    # บันทึกสถิติลงใน JSON\n",
        "    stats_path = os.path.join(output_base_dir, \"processing_stats.json\")\n",
        "    with open(stats_path, 'w', encoding='utf-8') as jsonfile:\n",
        "        json.dump(stats, jsonfile, ensure_ascii=False, indent=4)\n",
        "\n",
        "    print(f\"บันทึกสถิติการประมวลผลไปยัง {stats_path}\")\n",
        "\n",
        "# กำหนดพาธของโฟลเดอร์ทั้งหมด\n",
        "BASE_DIR = '/content/drive/MyDrive/sign'  # โฟลเดอร์ที่มีวิดีโอภาษามือไทย\n",
        "OUTPUT_DIR = '/content/drive/MyDrive/thai_sign_language_landmarks/'  # โฟลเดอร์สำหรับเก็บไฟล์ JSON\n",
        "\n",
        "# ประมวลผลทั้งหมด\n",
        "process_folder_structure(BASE_DIR, OUTPUT_DIR)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Processing"
      ],
      "metadata": {
        "id": "n4QL0iI0tHqn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "รวบรวมข้อมูลจากทุกไฟล์ JSONในโฟลเดอร์เพื่อเพิ่มความหลากหลายและความครอบคลุมของข้อมูล"
      ],
      "metadata": {
        "id": "RzxvsUVWtQtV"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SE6_sPCXaX3g"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "import os\n",
        "import json\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "def preprocess_sign_language_data(base_directory):\n",
        "    \"\"\"\n",
        "    Preprocess sign language data from JSON files in a folder structure\n",
        "    where each subfolder represents a sign language word.\n",
        "\n",
        "    Args:\n",
        "        base_directory: Path to directory containing subfolders with JSON files\n",
        "\n",
        "    Returns:\n",
        "        X: Processed feature data\n",
        "        y: Corresponding labels\n",
        "        label_encoder: The label encoder used\n",
        "    \"\"\"\n",
        "    # เก็บข้อมูลทั้งหมด\n",
        "    all_landmarks = []\n",
        "    all_labels = []\n",
        "\n",
        "    # เพิ่มการตรวจสอบก่อนเริ่มทำงาน\n",
        "    if not os.path.exists(base_directory):\n",
        "        print(f\"Error: Directory {base_directory} does not exist!\")\n",
        "        return [], [], None\n",
        "\n",
        "    # หาโฟลเดอร์ย่อยทั้งหมด (แต่ละโฟลเดอร์แทนคำในภาษามือ)\n",
        "    word_folders = [d for d in os.listdir(base_directory) if os.path.isdir(os.path.join(base_directory, d))]\n",
        "\n",
        "    if not word_folders:\n",
        "        print(f\"Error: No subfolders found in {base_directory}\")\n",
        "        return [], [], None\n",
        "\n",
        "    print(f\"Found {len(word_folders)} word folders: {word_folders[:5]}{'...' if len(word_folders) > 5 else ''}\")\n",
        "\n",
        "    # วนลูปผ่านแต่ละโฟลเดอร์ย่อย (แต่ละคำ)\n",
        "    for word_folder in tqdm(word_folders, desc=\"Processing word folders\"):\n",
        "        word_path = os.path.join(base_directory, word_folder)\n",
        "\n",
        "        # หาไฟล์ JSON ทั้งหมดในโฟลเดอร์นี้\n",
        "        json_files = [f for f in os.listdir(word_path) if f.endswith('.json')]\n",
        "\n",
        "        if not json_files:\n",
        "            print(f\"Warning: No JSON files found in {word_path}\")\n",
        "            continue\n",
        "\n",
        "        # วนลูปผ่านแต่ละไฟล์ JSON\n",
        "        for json_file in json_files:\n",
        "            file_path = os.path.join(word_path, json_file)\n",
        "\n",
        "            try:\n",
        "                # โหลดข้อมูล JSON\n",
        "                with open(file_path, 'r') as f:\n",
        "                    video_data = json.load(f)\n",
        "\n",
        "                # ตรวจสอบว่ามีข้อมูลเฟรมหรือไม่\n",
        "                if 'frames' not in video_data or not video_data['frames']:\n",
        "                    print(f\"Warning: No frames data in {file_path}\")\n",
        "                    continue\n",
        "\n",
        "                # สกัดคุณลักษณะ\n",
        "                processed_landmarks = process_video_landmarks(video_data)\n",
        "\n",
        "                # เพิ่มข้อมูล\n",
        "                all_landmarks.append(processed_landmarks)\n",
        "                # ใช้ชื่อโฟลเดอร์เป็นฉลาก\n",
        "                all_labels.append(word_folder)\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {file_path}: {e}\")\n",
        "\n",
        "    # ถ้าไม่พบไฟล์ JSON เลย\n",
        "    if not all_landmarks:\n",
        "        print(f\"No valid JSON files found in directory structure {base_directory}\")\n",
        "        return [], [], None\n",
        "\n",
        "    # แปลง list เป็น numpy array\n",
        "    X = np.array(all_landmarks)\n",
        "\n",
        "    # Encode labels\n",
        "    label_encoder = LabelEncoder()\n",
        "    y = label_encoder.fit_transform(all_labels)\n",
        "\n",
        "    # พิมพ์ข้อมูลดีบัก\n",
        "    print(f\"Processed {len(X)} samples with shape {X.shape}\")\n",
        "    print(f\"Found {len(label_encoder.classes_)} unique classes: {label_encoder.classes_}\")\n",
        "\n",
        "    # คำนวณจำนวนตัวอย่างต่อคลาส\n",
        "    class_counts = pd.Series(all_labels).value_counts()\n",
        "    print(\"\\nSamples per class:\")\n",
        "    for cls, count in class_counts.items():\n",
        "        print(f\"  {cls}: {count}\")\n",
        "\n",
        "    return X, y, label_encoder"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def process_video_landmarks(video_data, max_frames=30, verbose=False):\n",
        "    \"\"\"\n",
        "    แปลงข้อมูลแลนด์มาร์คจาก JSON เป็นชุดข้อมูลที่เหมาะสำหรับโมเดล\n",
        "\n",
        "    Args:\n",
        "        video_data: ข้อมูล JSON ของวิดีโอ\n",
        "        max_frames: จำนวนเฟรมสูงสุดที่จะใช้\n",
        "        verbose: แสดงข้อความดีบัก\n",
        "\n",
        "    Returns:\n",
        "        processed_landmarks: อาร์เรย์ของแลนด์มาร์ค\n",
        "    \"\"\"\n",
        "    # เลือกเฟรมที่มีการตรวจจับมือ\n",
        "    hand_frames = [frame for frame in video_data['frames'] if frame['hands']]\n",
        "\n",
        "    if not hand_frames:\n",
        "        if verbose:\n",
        "            print(f\"Warning: No hand detected in video {video_data.get('video_id', 'unknown')}\")\n",
        "        # สร้างเฟรมว่างๆ\n",
        "        return np.zeros((max_frames, 21 * 2, 3))\n",
        "\n",
        "    # เลือกเฟรมกระจายทั่ววิดีโอ\n",
        "    if len(hand_frames) <= max_frames:\n",
        "        selected_frames = hand_frames\n",
        "    else:\n",
        "        # เลือกเฟรมแบบกระจาย\n",
        "        indices = np.linspace(0, len(hand_frames) - 1, max_frames, dtype=int)\n",
        "        selected_frames = [hand_frames[i] for i in indices]\n",
        "\n",
        "    # เตรียมอาร์เรย์เก็บแลนด์มาร์ค\n",
        "    landmarks_sequence = []\n",
        "\n",
        "    for frame in selected_frames:\n",
        "        # จัดเรียงเพื่อให้มือซ้ายอยู่ก่อนมือขวาเสมอ (ถ้ามีทั้งสองมือ)\n",
        "        left_hand = None\n",
        "        right_hand = None\n",
        "\n",
        "        for hand in frame['hands']:\n",
        "            if hand['hand_type'] == 'LEFT':\n",
        "                left_hand = hand\n",
        "            elif hand['hand_type'] == 'RIGHT':\n",
        "                right_hand = hand\n",
        "\n",
        "        # สกัดแลนด์มาร์คจากมือซ้าย (ถ้ามี)\n",
        "        left_landmarks = []\n",
        "        if left_hand:\n",
        "            left_landmarks = [\n",
        "                [landmark['x'], landmark['y'], landmark['z']]\n",
        "                for landmark in left_hand['landmarks']\n",
        "            ]\n",
        "        else:\n",
        "            left_landmarks = [[0, 0, 0]] * 21  # มือซ้ายไม่มี ใส่ 0\n",
        "\n",
        "        # สกัดแลนด์มาร์คจากมือขวา (ถ้ามี)\n",
        "        right_landmarks = []\n",
        "        if right_hand:\n",
        "            right_landmarks = [\n",
        "                [landmark['x'], landmark['y'], landmark['z']]\n",
        "                for landmark in right_hand['landmarks']\n",
        "            ]\n",
        "        else:\n",
        "            right_landmarks = [[0, 0, 0]] * 21  # มือขวาไม่มี ใส่ 0\n",
        "\n",
        "        # รวมจุดของทั้งสองมือ\n",
        "        frame_landmarks = left_landmarks + right_landmarks\n",
        "\n",
        "        # ตรวจสอบจำนวนจุด ควรมี 21*2 จุด\n",
        "        if len(frame_landmarks) != 42:\n",
        "            if verbose:\n",
        "                print(f\"Warning: Expected 42 landmarks, but got {len(frame_landmarks)}\")\n",
        "            # Padding ให้ครบ 42 จุด\n",
        "            while len(frame_landmarks) < 42:\n",
        "                frame_landmarks.append([0, 0, 0])\n",
        "            # ตัดให้เหลือ 42 จุด\n",
        "            frame_landmarks = frame_landmarks[:42]\n",
        "\n",
        "        landmarks_sequence.append(frame_landmarks)\n",
        "\n",
        "    # Padding sequence ให้มีความยาวคงที่\n",
        "    while len(landmarks_sequence) < max_frames:\n",
        "        landmarks_sequence.append([[0, 0, 0]] * 42)\n",
        "\n",
        "    # ตัดให้เหลือ max_frames\n",
        "    landmarks_sequence = landmarks_sequence[:max_frames]\n",
        "\n",
        "    # ปรับรูปร่างเป็น (max_frames, 42, 3) -> (max_frames, 21*2, 3)\n",
        "    result = np.array(landmarks_sequence).reshape(max_frames, 42, 3)\n",
        "\n",
        "    if verbose:\n",
        "        print(f\"Video: {video_data.get('video_id', 'unknown')}\")\n",
        "        print(f\"Processed landmarks shape: {result.shape}\")\n",
        "\n",
        "    return result"
      ],
      "metadata": {
        "id": "mT6PEJ7YKkmf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_model_data(X, y, label_encoder, test_size=0.2, validation_size=0.25):\n",
        "    \"\"\"\n",
        "    เตรียมข้อมูลสำหรับการฝึกฝนโมเดล\n",
        "\n",
        "    Args:\n",
        "        X: ข้อมูลคุณลักษณะ\n",
        "        y: ป้ายกำกับ\n",
        "        label_encoder: ตัวแปลงป้ายกำกับ\n",
        "        test_size: สัดส่วนข้อมูลทดสอบ\n",
        "        validation_size: สัดส่วนข้อมูลตรวจสอบจากข้อมูลฝึกฝน\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_val, X_test: ข้อมูลฝึกฝน, ตรวจสอบ, และทดสอบ\n",
        "        y_train, y_val, y_test: ป้ายกำกับสำหรับแต่ละชุด\n",
        "        num_classes: จำนวนคลาสทั้งหมด\n",
        "    \"\"\"\n",
        "    # คำนวณจำนวนคลาสทั้งหมด\n",
        "    num_classes = len(label_encoder.classes_)\n",
        "\n",
        "    # ตรวจสอบว่ามีข้อมูลพอที่จะทำ stratified split หรือไม่\n",
        "    expected_test_size = int(len(X) * test_size)\n",
        "\n",
        "    try:\n",
        "        # พยายามแบ่งข้อมูลแบบ stratified\n",
        "        from sklearn.model_selection import train_test_split\n",
        "\n",
        "        # แบ่งข้อมูลเป็นชุดฝึกฝน+ตรวจสอบ และชุดทดสอบ\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42, stratify=y\n",
        "        )\n",
        "\n",
        "        # แบ่งข้อมูลฝึกฝน+ตรวจสอบเป็นชุดฝึกฝนและชุดตรวจสอบ\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=validation_size, random_state=42, stratify=y_train_val\n",
        "        )\n",
        "\n",
        "        print(\"\\nData split using stratified sampling:\")\n",
        "\n",
        "    except ValueError as e:\n",
        "        print(f\"\\nWarning: Cannot perform stratified split: {e}\")\n",
        "        print(\"Using random split instead...\")\n",
        "\n",
        "        # แบ่งข้อมูลแบบสุ่ม (ไม่ stratify)\n",
        "        X_train_val, X_test, y_train_val, y_test = train_test_split(\n",
        "            X, y, test_size=test_size, random_state=42\n",
        "        )\n",
        "\n",
        "        X_train, X_val, y_train, y_val = train_test_split(\n",
        "            X_train_val, y_train_val, test_size=validation_size, random_state=42\n",
        "        )\n",
        "\n",
        "        print(\"\\nData split using random sampling:\")\n",
        "\n",
        "    print(f\"Training set: {X_train.shape} - {y_train.shape}\")\n",
        "    print(f\"Validation set: {X_val.shape} - {y_val.shape}\")\n",
        "    print(f\"Test set: {X_test.shape} - {y_test.shape}\")\n",
        "    print(f\"Number of classes: {num_classes}\")\n",
        "\n",
        "    # ตรวจสอบว่ามีคลาสที่หายไปในชุดข้อมูลใดหรือไม่\n",
        "    train_classes = set(y_train)\n",
        "    val_classes = set(y_val)\n",
        "    test_classes = set(y_test)\n",
        "    all_classes = set(range(num_classes))\n",
        "\n",
        "    missing_train = all_classes - train_classes\n",
        "    missing_val = all_classes - val_classes\n",
        "    missing_test = all_classes - test_classes\n",
        "\n",
        "    if missing_train:\n",
        "        print(f\"Warning: {len(missing_train)} classes missing from training set: {missing_train}\")\n",
        "    if missing_val:\n",
        "        print(f\"Warning: {len(missing_val)} classes missing from validation set: {missing_val}\")\n",
        "    if missing_test:\n",
        "        print(f\"Warning: {len(missing_test)} classes missing from test set: {missing_test}\")\n",
        "\n",
        "    return X_train, X_val, X_test, y_train, y_val, y_test, num_classes\n"
      ],
      "metadata": {
        "id": "E8ius3NaKnGw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ฟังก์ชันสำหรับการแปลงข้อมูลให้เหมาะสมสำหรับโมเดล LSTM\n",
        "def reshape_for_lstm(X_train, X_val, X_test):\n",
        "    \"\"\"\n",
        "    ปรับโครงสร้างข้อมูลให้เหมาะสมสำหรับโมเดล LSTM\n",
        "\n",
        "    Args:\n",
        "        X_train, X_val, X_test: ข้อมูลฝึกฝน, ตรวจสอบ, และทดสอบ\n",
        "\n",
        "    Returns:\n",
        "        X_train, X_val, X_test: ข้อมูลที่ปรับโครงสร้างแล้ว\n",
        "    \"\"\"\n",
        "    # ปรับโครงสร้างจาก (samples, frames, landmarks, 3) เป็น (samples, frames, landmarks*3)\n",
        "    n_train, n_frames, n_landmarks, n_coords = X_train.shape\n",
        "    X_train_reshaped = X_train.reshape(n_train, n_frames, n_landmarks * n_coords)\n",
        "\n",
        "    n_val = X_val.shape[0]\n",
        "    X_val_reshaped = X_val.reshape(n_val, n_frames, n_landmarks * n_coords)\n",
        "\n",
        "    n_test = X_test.shape[0]\n",
        "    X_test_reshaped = X_test.reshape(n_test, n_frames, n_landmarks * n_coords)\n",
        "\n",
        "    print(f\"LSTM input shape: {X_train_reshaped.shape[1:]}\")\n",
        "\n",
        "    return X_train_reshaped, X_val_reshaped, X_test_reshaped"
      ],
      "metadata": {
        "id": "HB6OuuzKKrpE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    # โฟลเดอร์ที่เก็บข้อมูล JSON ที่ประมวลผลแล้ว\n",
        "    data_directory = '/content/drive/MyDrive/thai_sign_language_landmarks/'  # ปรับตามพาธของคุณ\n",
        "\n",
        "    # ตรวจสอบว่าโฟลเดอร์มีอยู่จริง\n",
        "    if not os.path.exists(data_directory):\n",
        "        print(f\"Error: Directory '{data_directory}' does not exist.\")\n",
        "        return\n",
        "\n",
        "    # ประมวลผลข้อมูล\n",
        "    X, y, label_encoder = preprocess_sign_language_data(data_directory)\n",
        "\n",
        "    if len(X) > 0 and len(y) > 0 and label_encoder is not None:\n",
        "        # ตรวจสอบว่ามีข้อมูลเพียงพอสำหรับการแบ่ง\n",
        "        num_classes = len(label_encoder.classes_)\n",
        "        min_samples_needed = num_classes * 5  # ประมาณการขั้นต่ำ\n",
        "\n",
        "        if len(X) < min_samples_needed:\n",
        "            print(f\"\\nWarning: You have {len(X)} samples for {num_classes} classes.\")\n",
        "            print(f\"This may not be enough for effective training. Recommended minimum: {min_samples_needed} samples.\")\n",
        "\n",
        "            # นับจำนวนตัวอย่างต่อคลาส\n",
        "            from collections import Counter\n",
        "            class_counts = Counter(y)\n",
        "            min_count = min(class_counts.values())\n",
        "\n",
        "            print(f\"Minimum samples per class: {min_count}\")\n",
        "\n",
        "            # แสดงคลาสที่มีตัวอย่างน้อย\n",
        "            classes_with_few_samples = [(label_encoder.classes_[class_idx], count)\n",
        "                                      for class_idx, count in class_counts.items()\n",
        "                                      if count < 3]\n",
        "\n",
        "            if classes_with_few_samples:\n",
        "                print(\"\\nClasses with very few samples (less than 3):\")\n",
        "                for cls, count in classes_with_few_samples:\n",
        "                    print(f\"  {cls}: {count} samples\")\n",
        "\n",
        "        # เตรียมข้อมูลสำหรับโมเดล\n",
        "        X_train, X_val, X_test, y_train, y_val, y_test, num_classes = prepare_model_data(X, y, label_encoder)\n",
        "\n",
        "        # ปรับโครงสร้างข้อมูลสำหรับ LSTM\n",
        "        X_train_lstm, X_val_lstm, X_test_lstm = reshape_for_lstm(X_train, X_val, X_test)\n",
        "\n",
        "        # บันทึกข้อมูลที่ประมวลผลแล้ว\n",
        "        output_directory = '/content/drive/MyDrive/thai_sign_language_processed_data/'\n",
        "        os.makedirs(output_directory, exist_ok=True)\n",
        "\n",
        "        np.save(os.path.join(output_directory, 'X_train.npy'), X_train_lstm)\n",
        "        np.save(os.path.join(output_directory, 'X_val.npy'), X_val_lstm)\n",
        "        np.save(os.path.join(output_directory, 'X_test.npy'), X_test_lstm)\n",
        "        np.save(os.path.join(output_directory, 'y_train.npy'), y_train)\n",
        "        np.save(os.path.join(output_directory, 'y_val.npy'), y_val)\n",
        "        np.save(os.path.join(output_directory, 'y_test.npy'), y_test)\n",
        "        np.save(os.path.join(output_directory, 'label_encoder_classes.npy'), label_encoder.classes_)\n",
        "\n",
        "        print(f\"\\nData saved to {output_directory}\")\n",
        "    else:\n",
        "        print(\"No data to process. Check your JSON files.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "Mrp0R56sRkwo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# สร้างโมเดล LSTM"
      ],
      "metadata": {
        "id": "wXtqcuJ8ScCm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "# 1. โหลดข้อมูล\n",
        "data_dir = '/content/drive/MyDrive/thai_sign_language_processed_data/'\n",
        "X_train = np.load(f'{data_dir}X_train.npy')\n",
        "X_val = np.load(f'{data_dir}X_val.npy')\n",
        "X_test = np.load(f'{data_dir}X_test.npy')\n",
        "y_train = np.load(f'{data_dir}y_train.npy')\n",
        "y_val = np.load(f'{data_dir}y_val.npy')\n",
        "y_test = np.load(f'{data_dir}y_test.npy')\n",
        "classes = np.load(f'{data_dir}label_encoder_classes.npy')\n",
        "\n",
        "# แปลง y เป็น one-hot encoding\n",
        "num_classes = len(classes)\n",
        "y_train_onehot = to_categorical(y_train, num_classes)\n",
        "y_val_onehot = to_categorical(y_val, num_classes)\n",
        "y_test_onehot = to_categorical(y_test, num_classes)\n",
        "\n",
        "# แสดงข้อมูล\n",
        "print(f\"X_train shape: {X_train.shape}\")\n",
        "print(f\"X_val shape: {X_val.shape}\")\n",
        "print(f\"X_test shape: {X_test.shape}\")\n",
        "print(f\"y_train shape: {y_train_onehot.shape}\")\n",
        "print(f\"Number of classes: {num_classes}\")\n",
        "print(f\"Classes: {classes}\")\n",
        "\n",
        "# 2. สร้างโมเดล LSTM\n",
        "model = Sequential([\n",
        "    # Input layer\n",
        "    LSTM(128, return_sequences=True, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Second LSTM layer\n",
        "    LSTM(64, return_sequences=False, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Dense layers\n",
        "    Dense(64, activation='relu'),\n",
        "    Dropout(0.4),\n",
        "\n",
        "    # Output layer\n",
        "    Dense(num_classes, activation='softmax')\n",
        "])\n",
        "\n",
        "# คอมไพล์โมเดล\n",
        "model.compile(\n",
        "    optimizer='adam',\n",
        "    loss='categorical_crossentropy',\n",
        "    metrics=['accuracy']\n",
        ")\n",
        "\n",
        "# สรุปโมเดล\n",
        "model.summary()\n",
        "\n",
        "# 3. กำหนด callbacks สำหรับการฝึกฝน\n",
        "callbacks = [\n",
        "    EarlyStopping(patience=15, restore_best_weights=True, verbose=1),\n",
        "    ReduceLROnPlateau(factor=0.1, patience=10, min_lr=1e-6, verbose=1),\n",
        "    ModelCheckpoint('thai_sign_language_model.h5', save_best_only=True, verbose=1)\n",
        "]\n",
        "\n",
        "# 4. ฝึกฝนโมเดล\n",
        "history = model.fit(\n",
        "    X_train, y_train_onehot,\n",
        "    validation_data=(X_val, y_val_onehot),\n",
        "    epochs=100,\n",
        "    batch_size=32,\n",
        "    callbacks=callbacks\n",
        ")\n",
        "\n",
        "# 5. ประเมินประสิทธิภาพของโมเดล\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test_onehot)\n",
        "print(f\"Test accuracy: {test_accuracy:.4f}\")\n",
        "\n",
        "# 6. แสดงกราฟการฝึกฝน\n",
        "plt.figure(figsize=(12, 4))\n",
        "\n",
        "plt.subplot(1, 2, 1)\n",
        "plt.plot(history.history['accuracy'])\n",
        "plt.plot(history.history['val_accuracy'])\n",
        "plt.title('Model Accuracy')\n",
        "plt.ylabel('Accuracy')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='lower right')\n",
        "\n",
        "plt.subplot(1, 2, 2)\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('Model Loss')\n",
        "plt.ylabel('Loss')\n",
        "plt.xlabel('Epoch')\n",
        "plt.legend(['Train', 'Validation'], loc='upper right')\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# 7. ทำนายและวิเคราะห์ผล\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis=1)\n",
        "y_true_classes = np.argmax(y_test_onehot, axis=1)\n",
        "\n",
        "# หาค่าคลาสที่มีในข้อมูลทดสอบ\n",
        "unique_classes = np.unique(y_true_classes)\n",
        "unique_classes_names = [classes[i] for i in unique_classes]\n",
        "\n",
        "# สร้าง classification report ด้วยเฉพาะคลาสที่มีในข้อมูลทดสอบ\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y_true_classes, y_pred_classes, labels=unique_classes, target_names=unique_classes_names))\n",
        "\n",
        "# สร้าง confusion matrix แบบย่อ\n",
        "cm = confusion_matrix(y_true_classes, y_pred_classes)\n",
        "\n",
        "# แสดงคู่คลาสที่มีการทำนายผิดมากที่สุด\n",
        "print(\"\\nTop misclassifications:\")\n",
        "error_pairs = []\n",
        "\n",
        "# ใช้เฉพาะคลาสที่มีในข้อมูลทดสอบ\n",
        "for i in range(len(unique_classes)):\n",
        "    for j in range(len(unique_classes)):\n",
        "        if i != j and cm[i, j] > 0:\n",
        "            true_idx = unique_classes[i]\n",
        "            pred_idx = unique_classes[j]\n",
        "            error_pairs.append((true_idx, pred_idx, cm[i, j]))\n",
        "\n",
        "# เรียงลำดับตามจำนวนการทำนายผิด\n",
        "error_pairs.sort(key=lambda x: x[2], reverse=True)\n",
        "\n",
        "# แสดง 10 คู่แรก (หรือน้อยกว่าถ้ามีไม่ถึง)\n",
        "for true_idx, pred_idx, count in error_pairs[:min(10, len(error_pairs))]:\n",
        "    true_label = classes[true_idx]\n",
        "    pred_label = classes[pred_idx]\n",
        "    print(f\"คำจริง: {true_label}, คำที่ทำนายผิด: {pred_label}, จำนวน: {count}\")\n",
        "\n",
        "# แสดงคลาสที่ไม่มีในข้อมูลทดสอบ\n",
        "missing_classes = set(range(num_classes)) - set(unique_classes)\n",
        "if missing_classes:\n",
        "    print(f\"\\nคำเตือน: {len(missing_classes)} คลาสไม่มีในข้อมูลทดสอบ:\")\n",
        "    for idx in missing_classes:\n",
        "        print(f\"  - {classes[idx]}\")\n",
        "\n",
        "# 8. บันทึกโมเดล\n",
        "model.save('/content/drive/MyDrive/thai_sign_language_model_final.h5')\n",
        "print(\"บันทึกโมเดลแล้วที่ '/content/drive/MyDrive/thai_sign_language_model_final.h5'\")"
      ],
      "metadata": {
        "id": "cNyTjcDTSell"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ทดสอบโมเดลกับวิดีโอที่บันทึกไว้แล้ว"
      ],
      "metadata": {
        "id": "Y8R842uPSnU7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "def predict_from_video(model_path, video_path, classes_path):\n",
        "    \"\"\"\n",
        "    ทำนายภาษามือจากวิดีโอ\n",
        "\n",
        "    Args:\n",
        "        model_path: พาธของโมเดล\n",
        "        video_path: พาธของไฟล์วิดีโอ\n",
        "        classes_path: พาธของไฟล์ classes\n",
        "    \"\"\"\n",
        "    # โหลดโมเดล\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # โหลดคลาส\n",
        "    classes = np.load(classes_path)\n",
        "\n",
        "    # สกัดจุดสำคัญของมือจากวิดีโอ\n",
        "    landmarks_sequence = extract_hand_landmarks_from_video(video_path)\n",
        "\n",
        "    if landmarks_sequence is None:\n",
        "        print(\"ไม่พบมือในวิดีโอ\")\n",
        "        return\n",
        "\n",
        "    # ปรับรูปร่างข้อมูล\n",
        "    X = landmarks_sequence.reshape(1, landmarks_sequence.shape[0], -1)\n",
        "\n",
        "    # ทำนาย\n",
        "    prediction = model.predict(X)[0]\n",
        "    predicted_class = np.argmax(prediction)\n",
        "    confidence = prediction[predicted_class]\n",
        "\n",
        "    # แสดงผล\n",
        "    print(f\"คำที่ทำนาย: {classes[predicted_class]}\")\n",
        "    print(f\"ความเชื่อมั่น: {confidence:.4f}\")\n",
        "\n",
        "    # แสดง top 5 การทำนาย\n",
        "    top_indices = prediction.argsort()[-5:][::-1]\n",
        "    print(\"\\nTop 5 predictions:\")\n",
        "    for i in top_indices:\n",
        "        print(f\"{classes[i]}: {prediction[i]:.4f}\")\n",
        "\n",
        "def extract_hand_landmarks_from_video(video_path, max_frames=30):\n",
        "    \"\"\"\n",
        "    สกัดจุดสำคัญของมือจากวิดีโอ\n",
        "    \"\"\"\n",
        "    mp_hands = mp.solutions.hands\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "\n",
        "    # อ่านเฟรมทั้งหมด\n",
        "    all_frames = []\n",
        "    while cap.isOpened():\n",
        "        success, image = cap.read()\n",
        "        if not success:\n",
        "            break\n",
        "        all_frames.append(image)\n",
        "\n",
        "    cap.release()\n",
        "\n",
        "    if not all_frames:\n",
        "        return None\n",
        "\n",
        "    # เลือกเฟรมกระจาย\n",
        "    if len(all_frames) > max_frames:\n",
        "        indices = np.linspace(0, len(all_frames) - 1, max_frames, dtype=int)\n",
        "        frames = [all_frames[i] for i in indices]\n",
        "    else:\n",
        "        frames = all_frames\n",
        "        while len(frames) < max_frames:\n",
        "            frames.append(frames[-1])  # ทำซ้ำเฟรมสุดท้าย\n",
        "\n",
        "    # ประมวลผลเฟรม\n",
        "    landmarks_sequence = []\n",
        "\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.3) as hands:\n",
        "\n",
        "        for frame in frames:\n",
        "            # แปลงภาพเป็น RGB\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # ประมวลผลภาพ\n",
        "            results = hands.process(frame_rgb)\n",
        "\n",
        "            # จัดเรียงมือซ้าย-ขวา\n",
        "            left_hand = right_hand = None\n",
        "\n",
        "            if results.multi_hand_landmarks:\n",
        "                for idx, handedness in enumerate(results.multi_handedness):\n",
        "                    if handedness.classification[0].label == \"Left\":\n",
        "                        left_hand = results.multi_hand_landmarks[idx]\n",
        "                    else:\n",
        "                        right_hand = results.multi_hand_landmarks[idx]\n",
        "\n",
        "            # สกัดจุดสำคัญจากมือซ้าย (ถ้ามี)\n",
        "            left_landmarks = []\n",
        "            if left_hand:\n",
        "                for landmark in left_hand.landmark:\n",
        "                    left_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "            else:\n",
        "                left_landmarks = [0.0] * 21 * 3\n",
        "\n",
        "            # สกัดจุดสำคัญจากมือขวา (ถ้ามี)\n",
        "            right_landmarks = []\n",
        "            if right_hand:\n",
        "                for landmark in right_hand.landmark:\n",
        "                    right_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "            else:\n",
        "                right_landmarks = [0.0] * 21 * 3\n",
        "\n",
        "            # รวมจุดของทั้งสองมือ\n",
        "            frame_landmarks = left_landmarks + right_landmarks\n",
        "            landmarks_sequence.append(frame_landmarks)\n",
        "\n",
        "    # ตรวจสอบว่าพบมือในวิดีโออย่างน้อยหนึ่งเฟรม\n",
        "    if not any(sum(frame) > 0 for frame in landmarks_sequence):\n",
        "        return None\n",
        "\n",
        "    return np.array(landmarks_sequence)\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "model_path = '/content/drive/MyDrive/thai_sign_language_model_final.h5'\n",
        "classes_path = '/content/drive/MyDrive/thai_sign_language_processed_data/label_encoder_classes.npy'\n",
        "video_path = '/content/drive/MyDrive/sign/16.สบายดี/สบายดี 2.MOV'  # เปลี่ยนเป็นพาธของวิดีโอที่ต้องการทดสอบ\n",
        "\n",
        "predict_from_video(model_path, video_path, classes_path)"
      ],
      "metadata": {
        "id": "UFhLGBp5SpK6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดสอบโมเดลกับกล้องเรียลไทม์"
      ],
      "metadata": {
        "id": "L07o_w3YSrJI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "from collections import deque\n",
        "\n",
        "def realtime_sign_recognition(model_path, classes_path):\n",
        "    \"\"\"\n",
        "    รู้จำภาษามือแบบเรียลไทม์จากกล้อง\n",
        "\n",
        "    Args:\n",
        "        model_path: พาธของโมเดล\n",
        "        classes_path: พาธของไฟล์ classes\n",
        "    \"\"\"\n",
        "    # โหลดโมเดล\n",
        "    model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "    # โหลดคลาส\n",
        "    classes = np.load(classes_path)\n",
        "\n",
        "    # ตั้งค่า MediaPipe\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "\n",
        "    # เปิดกล้อง\n",
        "    cap = cv2.VideoCapture(0)\n",
        "\n",
        "    # ตั้งค่า MediaPipe Hands\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as hands:\n",
        "\n",
        "        # สำหรับเก็บลำดับการทำนาย\n",
        "        predictions_queue = deque(maxlen=10)\n",
        "        landmarks_sequence = deque(maxlen=30)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                print(\"ไม่สามารถเปิดกล้องได้\")\n",
        "                break\n",
        "\n",
        "            # เตรียมภาพสำหรับ MediaPipe\n",
        "            image = cv2.flip(image, 1)  # flip to mirror\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "            results = hands.process(image_rgb)\n",
        "\n",
        "            # จัดเตรียมข้อมูลจุดสำคัญ\n",
        "            left_hand = right_hand = None\n",
        "\n",
        "            if results.multi_hand_landmarks:\n",
        "                # วาดจุดสำคัญบนภาพ\n",
        "                for idx, hand_landmark in enumerate(results.multi_hand_landmarks):\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image,\n",
        "                        hand_landmark,\n",
        "                        mp_hands.HAND_CONNECTIONS)\n",
        "\n",
        "                    # จัดเรียงมือซ้าย-ขวา\n",
        "                    if results.multi_handedness[idx].classification[0].label == \"Left\":\n",
        "                        left_hand = hand_landmark\n",
        "                    else:\n",
        "                        right_hand = hand_landmark\n",
        "\n",
        "            # สกัดจุดสำคัญจากมือซ้าย (ถ้ามี)\n",
        "            left_landmarks = []\n",
        "            if left_hand:\n",
        "                for landmark in left_hand.landmark:\n",
        "                    left_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "            else:\n",
        "                left_landmarks = [0.0] * 21 * 3\n",
        "\n",
        "            # สกัดจุดสำคัญจากมือขวา (ถ้ามี)\n",
        "            right_landmarks = []\n",
        "            if right_hand:\n",
        "                for landmark in right_hand.landmark:\n",
        "                    right_landmarks.extend([landmark.x, landmark.y, landmark.z])\n",
        "            else:\n",
        "                right_landmarks = [0.0] * 21 * 3\n",
        "\n",
        "            # รวมจุดของทั้งสองมือ\n",
        "            frame_landmarks = left_landmarks + right_landmarks\n",
        "\n",
        "            # เพิ่มเฟรมปัจจุบันเข้าไปในลำดับ\n",
        "            landmarks_sequence.append(frame_landmarks)\n",
        "\n",
        "            # ทำนายเมื่อมีข้อมูลเพียงพอ\n",
        "            if len(landmarks_sequence) == 30:\n",
        "                # เตรียมข้อมูลสำหรับโมเดล\n",
        "                X = np.array(list(landmarks_sequence)).reshape(1, 30, -1)\n",
        "\n",
        "                # ทำนาย\n",
        "                prediction = model.predict(X, verbose=0)[0]\n",
        "                predicted_class = np.argmax(prediction)\n",
        "                confidence = prediction[predicted_class]\n",
        "\n",
        "                if confidence > 0.5:  # แสดงผลเฉพาะเมื่อความเชื่อมั่นมากกว่า 0.5\n",
        "                    predictions_queue.append(predicted_class)\n",
        "\n",
        "                    # นับความถี่ของการทำนาย\n",
        "                    from collections import Counter\n",
        "                    most_common = Counter(predictions_queue).most_common(3)\n",
        "\n",
        "                    # แสดงผลการทำนาย 3 อันดับแรก\n",
        "                    y_pos = 30\n",
        "                    for i, (class_idx, count) in enumerate(most_common):\n",
        "                        if i >= 3:  # แสดงแค่ 3 อันดับแรก\n",
        "                            break\n",
        "                        confidence_ratio = count / len(predictions_queue)\n",
        "                        if confidence_ratio >= 0.3:  # แสดงเฉพาะคำที่มีความเชื่อมั่นมากกว่า 30%\n",
        "                            text = f\"{classes[class_idx]} ({confidence_ratio:.2f})\"\n",
        "                            color = (0, 255, 0) if i == 0 else (0, 200, 200)\n",
        "                            cv2.putText(image, text, (10, y_pos), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                                      1, color, 2, cv2.LINE_AA)\n",
        "                            y_pos += 40\n",
        "\n",
        "            # แสดงคำแนะนำ\n",
        "            cv2.putText(image, \"Press 'q' to quit\",\n",
        "                      (10, image.shape[0] - 30), cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                      0.7, (0, 0, 255), 2)\n",
        "\n",
        "            # แสดงภาพ\n",
        "            cv2.imshow('Thai Sign Language Recognition', image)\n",
        "\n",
        "            # กด q เพื่อออก\n",
        "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        # คืนทรัพยากร\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# เรียกใช้ฟังก์ชันรู้จำภาษามือแบบเรียลไทม์\n",
        "model_path = '/content/drive/MyDrive/thai_sign_language_model_final.h5'\n",
        "classes_path = '/content/drive/MyDrive/thai_sign_language_processed_data/label_encoder_classes.npy'\n",
        "\n",
        "realtime_sign_recognition(model_path, classes_path)"
      ],
      "metadata": {
        "id": "kzUg5TEUSsFy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "เรียกใช้ฟังก์ชันสำหรับการรู้จำภาษามือแบบเรียลไทม์"
      ],
      "metadata": {
        "id": "fxWB0nFfSvfn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดโมเดล\n",
        "model = tf.keras.models.load_model('/content/drive/MyDrive/thai_sign_language_model_final.h5')\n",
        "\n",
        "# โหลดคลาส\n",
        "classes = np.load('/content/drive/MyDrive/thai_sign_language_processed_data/label_encoder_classes.npy')\n",
        "\n",
        "# รู้จำภาษามือแบบเรียลไทม์\n",
        "realtime_sign_recognition(model, classes)"
      ],
      "metadata": {
        "id": "j_H3xoJjSxDE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Data Augmentation"
      ],
      "metadata": {
        "id": "Y8K_zntKDLri"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "เพิ่มความหลากหลายของข้อมูล สร้างข้อมูลเทียม เพิ่มความทนทานของโมเดล"
      ],
      "metadata": {
        "id": "pWzZTi7LDU0I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "\n",
        "class SignLanguageDataAugmentation:\n",
        "    def __init__(self, original_data):\n",
        "        \"\"\"\n",
        "        เตรียมการเพิ่มความหลากหลายของข้อมูลภาษามือ\n",
        "\n",
        "        Args:\n",
        "            original_data: ข้อมูลแลนด์มาร์คเดิม\n",
        "        \"\"\"\n",
        "        self.original_data = original_data\n",
        "\n",
        "    def add_noise(self, data, noise_level=0.02):\n",
        "        \"\"\"\n",
        "        เพิ่มความคลาดเคลื่อนเล็กน้อยในข้อมูล\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            noise_level: ระดับความคลาดเคลื่อน\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่เพิ่มความคลาดเคลื่อน\n",
        "        \"\"\"\n",
        "        noise = np.random.normal(\n",
        "            loc=0,\n",
        "            scale=noise_level,\n",
        "            size=data.shape\n",
        "        )\n",
        "        return data + noise\n",
        "\n",
        "    def time_warping(self, data, max_warp=5):\n",
        "        \"\"\"\n",
        "        ยืดหรือบีบเวลาของลำดับการเคลื่อนไหว\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "            max_warp: จำนวนเฟรมสูงสุดที่จะยืดหรือบีบ\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกดัดแปลงเวลา\n",
        "        \"\"\"\n",
        "        # สุ่มเลือกจุดที่จะยืดหรือบีบ\n",
        "        warp_point = random.randint(0, len(data) - max_warp - 1)\n",
        "\n",
        "        # สร้างข้อมูลใหม่\n",
        "        warped_data = np.copy(data)\n",
        "\n",
        "        # ซ้ำหรือลบเฟรมบางส่วน\n",
        "        insert_point = random.randint(0, max_warp)\n",
        "        warped_data = np.insert(\n",
        "            warped_data,\n",
        "            warp_point + insert_point,\n",
        "            warped_data[warp_point:warp_point+max_warp],\n",
        "            axis=0\n",
        "        )\n",
        "\n",
        "        # ตัดให้มีความยาวคงเดิม\n",
        "        return warped_data[:len(data)]\n",
        "\n",
        "    def hand_rotation(self, data):\n",
        "        \"\"\"\n",
        "        หมุนตำแหน่งมือ\n",
        "\n",
        "        Args:\n",
        "            data: ข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Returns:\n",
        "            ข้อมูลที่ถูกหมุน\n",
        "        \"\"\"\n",
        "        # สุ่มมุมหมุน\n",
        "        angle = np.random.uniform(-30, 30)\n",
        "\n",
        "        # แปลงเป็นเรเดียน\n",
        "        angle_rad = np.deg2rad(angle)\n",
        "\n",
        "        # เมทริกซ์หมุน\n",
        "        rotation_matrix = np.array([\n",
        "            [np.cos(angle_rad), -np.sin(angle_rad)],\n",
        "            [np.sin(angle_rad), np.cos(angle_rad)]\n",
        "        ])\n",
        "\n",
        "        # คัดลอกข้อมูล\n",
        "        rotated_data = np.copy(data)\n",
        "\n",
        "        # หมุนพิกัด x, y\n",
        "        for i in range(len(rotated_data)):\n",
        "            for j in range(0, len(rotated_data[i]), 3):\n",
        "                rotated_data[i][j:j+2] = np.dot(\n",
        "                    rotation_matrix,\n",
        "                    rotated_data[i][j:j+2]\n",
        "                )\n",
        "\n",
        "        return rotated_data\n",
        "\n",
        "    def generate_augmented_data(self, num_augmentations=5):\n",
        "        \"\"\"\n",
        "        สร้างชุดข้อมูลเพิ่มเติม\n",
        "\n",
        "        Args:\n",
        "            num_augmentations: จำนวนข้อมูลที่ต้องการสร้าง\n",
        "\n",
        "        Returns:\n",
        "            ชุดข้อมูลที่ถูกเพิ่มความหลากหลาย\n",
        "        \"\"\"\n",
        "        augmented_data = []\n",
        "\n",
        "        for _ in range(num_augmentations):\n",
        "            # สุ่มเลือกข้อมูลต้นฉบับ\n",
        "            base_data = random.choice(self.original_data)\n",
        "\n",
        "            # เพิ่มความหลากหลาย\n",
        "            augmented_sample = self.add_noise(base_data)\n",
        "            augmented_sample = self.time_warping(augmented_sample)\n",
        "            augmented_sample = self.hand_rotation(augmented_sample)\n",
        "\n",
        "            augmented_data.append(augmented_sample)\n",
        "\n",
        "        return augmented_data\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "# สมมติ X คือชุดข้อมูลเดิม\n",
        "augmentor = SignLanguageDataAugmentation(X)\n",
        "augmented_X = augmentor.generate_augmented_data()\n",
        "\n",
        "# รวมข้อมูล\n",
        "X_augmented = np.concatenate([X, augmented_X])\n",
        "y_augmented = np.concatenate([y, y[:len(augmented_X)]])"
      ],
      "metadata": {
        "id": "NePB3X4-Da4L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Feature Engineering"
      ],
      "metadata": {
        "id": "2NxeR7VwDr47"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "สกัดคุณลักษณะพิเศษ\n",
        "คำนวณความเร็ว ความเร่ง\n",
        "วิเคราะห์คุณสมบัติทางสถิติ\n",
        "\n"
      ],
      "metadata": {
        "id": "gVAMip17DvxL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from scipy.stats import skew, kurtosis\n",
        "\n",
        "class SignLanguageFeatureExtractor:\n",
        "    def __init__(self, landmarks_data):\n",
        "        \"\"\"\n",
        "        สกัดคุณลักษณะพิเศษจากข้อมูลแลนด์มาร์ค\n",
        "\n",
        "        Args:\n",
        "            landmarks_data: ข้อมูลแลนด์มาร์คภาษามือ\n",
        "        \"\"\"\n",
        "        self.landmarks_data = landmarks_data\n",
        "\n",
        "    def calculate_hand_velocity(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร็วของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร็วมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        velocities = []\n",
        "        for sequence in self.landmarks_data:\n",
        "            frame_velocities = []\n",
        "            for frame_idx in range(1, len(sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงตำแหน่ง\n",
        "                prev_frame = sequence[frame_idx-1]\n",
        "                curr_frame = sequence[frame_idx]\n",
        "\n",
        "                # คำนวณความเร็ว\n",
        "                frame_velocity = np.linalg.norm(\n",
        "                    curr_frame[:21*3] - prev_frame[:21*3]\n",
        "                )\n",
        "                frame_velocities.append(frame_velocity)\n",
        "\n",
        "            velocities.append(frame_velocities)\n",
        "\n",
        "        return np.array(velocities)\n",
        "\n",
        "    def calculate_hand_acceleration(self):\n",
        "        \"\"\"\n",
        "        คำนวณความเร่งของการเคลื่อนไหวมือ\n",
        "\n",
        "        Returns:\n",
        "            อาร์เรย์ของความเร่งมือในแต่ละเฟรม\n",
        "        \"\"\"\n",
        "        accelerations = []\n",
        "        velocities = self.calculate_hand_velocity()\n",
        "\n",
        "        for velocity_sequence in velocities:\n",
        "            frame_accelerations = []\n",
        "            for frame_idx in range(1, len(velocity_sequence)):\n",
        "                # คำนวณการเปลี่ยนแปลงความเร็ว\n",
        "                acceleration = abs(\n",
        "                    velocity_sequence[frame_idx] -\n",
        "                    velocity_sequence[frame_idx-1]\n",
        "                )\n",
        "                frame_accelerations.append(acceleration)\n",
        "\n",
        "            accelerations.append(frame_accelerations)\n",
        "\n",
        "        return np.array(accelerations)\n",
        "\n",
        "    def calculate_statistical_features(self):\n",
        "        \"\"\"\n",
        "        คำนวณคุณลักษณะทางสถิติ\n",
        "\n",
        "        Returns:\n",
        "            พจนานุกรมของคุณลักษณะทางสถิติ\n",
        "        \"\"\"\n",
        "        features = []\n",
        "\n",
        "        for sequence in self.landmarks_data:\n",
        "            sequence_features = {}\n",
        "\n",
        "            # คำนวณคุณลักษณะสำหรับแต่ละมือ\n",
        "            for hand_start in [0, 21*3]:\n",
        "                hand_landmarks = sequence[:, hand_start:hand_start+21*3]\n",
        "\n",
        "                # สถิติพื้นฐาน\n",
        "                sequence_features.update({\n",
        "                    f'hand_{hand_start//63}_mean': np.mean(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_std': np.std(hand_landmarks),\n",
        "                    f'hand_{hand_start//63}_skewness': skew(hand_landmarks.flatten()),\n",
        "                    f'hand_{hand_start//63}_kurtosis': kurtosis(hand_landmarks.flatten())\n",
        "                })\n",
        "\n",
        "            features.append(sequence_features)\n",
        "\n",
        "        return features\n",
        "\n",
        "    def extract_advanced_features(self):\n",
        "\n",
        "      # รวบรวมคุณลักษณะต่างๆ\n",
        "      velocities = self.calculate_hand_velocity()\n",
        "      accelerations = self.calculate_hand_acceleration()\n",
        "      statistical_features = self.calculate_statistical_features()\n",
        "\n",
        "      # แปลงเป็นรูปแบบที่เหมาะสมสำหรับโมเดล\n",
        "      feature_matrix = []\n",
        "      for i in range(len(self.landmarks_data)):\n",
        "          # แปลงค่าเดี่ยวให้เป็น array ด้วย np.array() หรือใช้ list\n",
        "          velocity_mean = np.mean(velocities[i])  # ค่าเดี่ยว\n",
        "          acceleration_mean = np.mean(accelerations[i])  # ค่าเดี่ยว\n",
        "          stat_features = list(statistical_features[i].values())  # list ของค่า\n",
        "\n",
        "          # รวมคุณลักษณะโดยสร้างเป็น list ก่อน แล้วค่อยแปลงเป็น numpy array\n",
        "          features = np.array([velocity_mean, acceleration_mean] + stat_features)\n",
        "          feature_matrix.append(features)\n",
        "\n",
        "      return np.array(feature_matrix)\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "feature_extractor = SignLanguageFeatureExtractor(X)\n",
        "X_advanced_features = feature_extractor.extract_advanced_features()"
      ],
      "metadata": {
        "id": "33HFkVbfD2Yl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Model Selection & Hyperparameter Tuning"
      ],
      "metadata": {
        "id": "SXpVnlrhD_FX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ทดสอบหลายสถาปัตยกรรม\n",
        "LSTM, CNN, Transformer\n",
        "เปรียบเทียบประสิทธิภาพ และ ค้นหาพารามิเตอร์ที่เหมาะสม\n",
        "ใช้ Random Search\n",
        "ปรับแต่งโมเดลให้ดีขึ้น"
      ],
      "metadata": {
        "id": "cE6HGY7gEAKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install scikeras"
      ],
      "metadata": {
        "id": "KF33_jajvD7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from scikeras.wrappers import KerasClassifier\n",
        "from scipy.stats import uniform, randint\n",
        "\n",
        "class SignLanguageModelSelector:\n",
        "    def __init__(self, X_train, y_train, X_test, y_test):\n",
        "        \"\"\"\n",
        "        เลือกและปรับแต่งโมเดลสำหรับภาษามือ\n",
        "\n",
        "        Args:\n",
        "            X_train: ข้อมูลฝึกอบรม\n",
        "            y_train: ป้ายกำกับการฝึกอบรม\n",
        "            X_test: ข้อมูลทดสอบ\n",
        "            y_test: ป้ายกำกับการทดสอบ\n",
        "        \"\"\"\n",
        "        self.X_train = X_train\n",
        "        self.y_train = y_train\n",
        "        self.X_test = X_test\n",
        "        self.y_test = y_test\n",
        "\n",
        "        # โมเดลที่จะทดสอบ\n",
        "        self.models = {\n",
        "            'LSTM': self.create_lstm_model,\n",
        "            'CNN': self.create_cnn_model,\n",
        "            'Transformer': self.create_transformer_model\n",
        "        }\n",
        "\n",
        "    def create_lstm_model(self, units=64, dropout=0.3):\n",
        "      \"\"\"\n",
        "      สร้างโมเดล LSTM\n",
        "\n",
        "      Args:\n",
        "          units: จำนวนหน่วยใน LSTM layer\n",
        "          dropout: อัตราการ dropout\n",
        "\n",
        "      Returns:\n",
        "          โมเดล Keras\n",
        "      \"\"\"\n",
        "      # รับข้อมูลรูปร่าง (30, 42, 3) - ปรับตามรูปร่างจริงของข้อมูล\n",
        "      model = tf.keras.Sequential([\n",
        "          # เพิ่ม Reshape layer เพื่อแบนมิติสุดท้าย\n",
        "          tf.keras.layers.Reshape((30, 42*3), input_shape=(30, 42, 3)),\n",
        "\n",
        "          tf.keras.layers.LSTM(\n",
        "              units,\n",
        "              return_sequences=True\n",
        "          ),\n",
        "          tf.keras.layers.Dropout(dropout),\n",
        "          tf.keras.layers.LSTM(units//2),\n",
        "          tf.keras.layers.Dense(\n",
        "              len(np.unique(self.y_train)),\n",
        "              activation='softmax'\n",
        "          )\n",
        "      ])\n",
        "\n",
        "      model.compile(\n",
        "          optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy']\n",
        "      )\n",
        "\n",
        "      return model\n",
        "\n",
        "    def create_cnn_model(self, filters=64, kernel_size=3):\n",
        "      \"\"\"\n",
        "      สร้างโมเดล CNN\n",
        "\n",
        "      Args:\n",
        "          filters: จำนวน filters\n",
        "          kernel_size: ขนาด kernel\n",
        "\n",
        "      Returns:\n",
        "          โมเดล Keras\n",
        "      \"\"\"\n",
        "      model = tf.keras.Sequential([\n",
        "          # ใช้ Conv2D แทน Conv1D\n",
        "          tf.keras.layers.Conv2D(\n",
        "              filters,\n",
        "              kernel_size=(kernel_size, kernel_size),  # kernel size ต้องเป็น tuple สำหรับ Conv2D\n",
        "              input_shape=(30, 42, 3),\n",
        "              activation='relu'\n",
        "          ),\n",
        "          tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "          tf.keras.layers.Flatten(),\n",
        "          tf.keras.layers.Dense(\n",
        "              len(np.unique(self.y_train)),\n",
        "              activation='softmax'\n",
        "          )\n",
        "      ])\n",
        "\n",
        "      model.compile(\n",
        "          optimizer='adam',\n",
        "          loss='sparse_categorical_crossentropy',\n",
        "          metrics=['accuracy']\n",
        "      )\n",
        "\n",
        "      return model\n",
        "\n",
        "    def create_transformer_model(self, num_heads=4, ff_dim=32):\n",
        "        \"\"\"\n",
        "        สร้างโมเดล Transformer\n",
        "\n",
        "        Args:\n",
        "            num_heads: จำนวน attention heads\n",
        "            ff_dim: ขนาดของ feed-forward layer\n",
        "\n",
        "        Returns:\n",
        "            โมเดล Keras\n",
        "        \"\"\"\n",
        "        # ปรับรูปร่างของ input\n",
        "        inputs = tf.keras.Input(shape=(30, 42, 3))  # ปรับตามรูปร่างจริงของข้อมูล\n",
        "\n",
        "        # แบนมิติสุดท้าย\n",
        "        x = tf.keras.layers.Reshape((30, 42*3))(inputs)\n",
        "\n",
        "        # Transformer Encoder\n",
        "        for _ in range(2):\n",
        "            x = tf.keras.layers.MultiHeadAttention(\n",
        "                num_heads=num_heads,\n",
        "                key_dim=ff_dim\n",
        "            )(x, x)\n",
        "            x = tf.keras.layers.LayerNormalization()(x)\n",
        "\n",
        "        x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "        x = tf.keras.layers.Dense(ff_dim, activation='relu')(x)\n",
        "        outputs = tf.keras.layers.Dense(\n",
        "            len(np.unique(self.y_train)),\n",
        "            activation='softmax'\n",
        "        )(x)\n",
        "\n",
        "        model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "        model.compile(\n",
        "            optimizer='adam',\n",
        "            loss='sparse_categorical_crossentropy',\n",
        "            metrics=['accuracy']\n",
        "        )\n",
        "\n",
        "        return model\n",
        "\n",
        "    def hyperparameter_tuning(self):\n",
        "      # เตรียม Keras Classifier\n",
        "      model = KerasClassifier(\n",
        "          model=self.create_lstm_model,  # เปลี่ยนจาก build_fn เป็น model\n",
        "          verbose=0\n",
        "      )\n",
        "\n",
        "      # ปรับช่วงพารามิเตอร์\n",
        "      param_dist = {\n",
        "          'model__units': [32, 64, 128],  # เพิ่ม model__ ข้างหน้า\n",
        "          'model__dropout': uniform(0.2, 0.5),\n",
        "          'batch_size': [16, 32, 64],\n",
        "          'epochs': [50, 100, 200]\n",
        "      }\n",
        "\n",
        "      # ตรวจสอบจำนวนข้อมูล\n",
        "      if len(self.X_train) < 10:  # ถ้าข้อมูลน้อยเกินไป\n",
        "          print(\"ข้อมูลมีจำนวนน้อยเกินไปสำหรับ hyperparameter tuning\")\n",
        "          return model  # คืนค่าโมเดลเริ่มต้น\n",
        "\n",
        "      # กำหนด cv ตามขนาดข้อมูล\n",
        "      cv_value = min(3, len(self.X_train) // 2)\n",
        "\n",
        "      # Random Search\n",
        "      random_search = RandomizedSearchCV(\n",
        "          estimator=model,\n",
        "          param_distributions=param_dist,\n",
        "          n_iter=10,\n",
        "          cv=cv_value,\n",
        "          scoring='accuracy'\n",
        "      )\n",
        "\n",
        "      # ตรวจสอบว่ามีพื้นที่พอสำหรับ validation_split หรือไม่\n",
        "      if len(self.X_train) > 5:  # ถ้ามีข้อมูลมากกว่า 5 ตัวอย่าง\n",
        "          random_search.fit(\n",
        "              self.X_train,\n",
        "              self.y_train,\n",
        "              validation_split=0.2\n",
        "          )\n",
        "      else:\n",
        "          random_search.fit(\n",
        "              self.X_train,\n",
        "              self.y_train\n",
        "          )\n",
        "\n",
        "      return random_search.best_estimator_\n",
        "\n",
        "    def compare_models(self):\n",
        "      results = {}\n",
        "\n",
        "      #ตรวจสอบจำนวนข้อมูลฝึกอบรม\n",
        "      if len(self.X_train) < 10:  # หากข้อมูลน้อยกว่า 10 ตัวอย่าง\n",
        "          validation_split = None\n",
        "          validation_data = None\n",
        "      else:\n",
        "          validation_split = 0.2\n",
        "          validation_data = None\n",
        "\n",
        "      for name, model_creator in self.models.items():\n",
        "          # สร้างโมเดล\n",
        "          model = model_creator()\n",
        "\n",
        "          #ฝึกอบรม - ปรับการใช้ validation\n",
        "          if validation_split:\n",
        "              history = model.fit(\n",
        "                  self.X_train, self.y_train,\n",
        "                  validation_split=validation_split,\n",
        "                  epochs=50,\n",
        "                  batch_size=min(32, len(self.X_train))  # ปรับขนาด batch ตามข้อมูล\n",
        "              )\n",
        "          else:\n",
        "              history = model.fit(\n",
        "                  self.X_train, self.y_train,\n",
        "                  epochs=50,\n",
        "                  batch_size=min(32, len(self.X_train))\n",
        "              )\n",
        "\n",
        "          #ประเมินผล\n",
        "          test_loss, test_accuracy = model.evaluate(\n",
        "              self.X_test, self.y_test\n",
        "          )\n",
        "\n",
        "          results[name] = {\n",
        "              'test_accuracy': test_accuracy,\n",
        "              'test_loss': test_loss,\n",
        "              'training_history': history\n",
        "          }\n",
        "\n",
        "      return results\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "model_selector = SignLanguageModelSelector(\n",
        "    X_train, y_train, X_test, y_test\n",
        ")\n",
        "\n",
        "# เปรียบเทียบโมเดล\n",
        "model_comparison = model_selector.compare_models()\n",
        "\n",
        "# ปรับแต่งพารามิเตอร์\n",
        "best_model = model_selector.hyperparameter_tuning()"
      ],
      "metadata": {
        "id": "HV2v4z-ZEEhE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EJ6Ff6LLvJAi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "*   เทรนโมเดลที่ดีที่สุดให้ละเอียดยิ่งขึ้นด้วยการเทรนหลายรอบ\n",
        "*   เพิ่มประสิทธิภาพด้วยการเพิ่มข้อมูล (Data Augmentation)\n",
        "*  ประเมินและวิเคราะห์ผลลัพธ์อย่างละเอียด\n",
        "*   เตรียมโมเดลสำหรับการนำไปใช้งาน\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L25e08HeUfIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "import seaborn as sns\n",
        "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\n",
        "import pandas as pd\n",
        "\n",
        "class SignLanguageModelTrainer:\n",
        "  def __init__(self, model_selector, best_model=None, best_model_name=None):\n",
        "        \"\"\"\n",
        "        ฝึกอบรมและปรับปรุงโมเดลภาษามือที่ดีที่สุด\n",
        "\n",
        "        Args:\n",
        "            model_selector: อ็อบเจ็กต์ SignLanguageModelSelector ที่ใช้ก่อนหน้านี้\n",
        "            best_model: โมเดลที่ดีที่สุดจากการปรับแต่งพารามิเตอร์ (หากมี)\n",
        "            best_model_name: ชื่อสถาปัตยกรรมที่ดีที่สุด (LSTM, CNN, Transformer)\n",
        "        \"\"\"\n",
        "        self.model_selector = model_selector\n",
        "        self.X_train = model_selector.X_train\n",
        "        self.y_train = model_selector.y_train\n",
        "        self.X_test = model_selector.X_test\n",
        "        self.y_test = model_selector.y_test\n",
        "        self.best_model = best_model\n",
        "        self.best_model_name = best_model_name\n",
        "        self.num_classes = len(np.unique(self.y_train))\n",
        "\n",
        "  def prepare_best_model(self, model_comparison=None):\n",
        "        \"\"\"\n",
        "        เตรียมโมเดลที่ดีที่สุดสำหรับการเทรนอย่างละเอียด\n",
        "\n",
        "        Args:\n",
        "            model_comparison: ผลลัพธ์จาก model_selector.compare_models()\n",
        "\n",
        "        Returns:\n",
        "            โมเดลที่ดีที่สุดพร้อมค่าพารามิเตอร์เริ่มต้น\n",
        "        \"\"\"\n",
        "        if self.best_model is not None:\n",
        "            print(f\"ใช้โมเดลที่กำหนดไว้: {self.best_model_name}\")\n",
        "            return self.best_model\n",
        "\n",
        "        if model_comparison is not None:\n",
        "            # หาโมเดลที่ดีที่สุดจากความแม่นยำ\n",
        "            best_acc = 0\n",
        "            for name, results in model_comparison.items():\n",
        "                if results['test_accuracy'] > best_acc:\n",
        "                    best_acc = results['test_accuracy']\n",
        "                    self.best_model_name = name\n",
        "\n",
        "            print(f\"โมเดลที่ดีที่สุดจากการเปรียบเทียบ: {self.best_model_name} (ความแม่นยำ: {best_acc:.4f})\")\n",
        "\n",
        "#สร้างโมเดลใหม่ตามสถาปัตยกรรมที่ดีที่สุด\n",
        "            if self.best_model_name == 'LSTM':\n",
        "                self.best_model = self.model_selector.create_lstm_model()\n",
        "            elif self.best_model_name == 'CNN':\n",
        "                self.best_model = self.model_selector.create_cnn_model()\n",
        "            elif self.best_model_name == 'Transformer':\n",
        "                self.best_model = self.model_selector.create_transformer_model()\n",
        "            else:\n",
        "                raise ValueError(\"ไม่พบชื่อโมเดลที่ถูกต้อง\")\n",
        "\n",
        "            return self.best_model\n",
        "\n",
        "#ถ้าไม่มีข้อมูลเปรียบเทียบโมเดล ให้ใช้ LSTM เป็นค่าเริ่มต้น\n",
        "        print(\"ไม่มีการเปรียบเทียบโมเดล ใช้ LSTM เป็นค่าเริ่มต้น\")\n",
        "        self.best_model_name = 'LSTM'\n",
        "        self.best_model = self.model_selector.create_lstm_model()\n",
        "        return self.best_model\n",
        "\n",
        "  def create_data_augmentation(self):\n",
        "    \"\"\"\n",
        "    สร้างฟังก์ชันสำหรับเพิ่มข้อมูล\n",
        "\n",
        "    Returns:\n",
        "        ฟังก์ชันสำหรับเพิ่มข้อมูล\n",
        "    \"\"\"\n",
        "    def augment_sequence(sequence, label):\n",
        "        # แปลงเป็น tensor โดยไม่ระบุ dtype เพื่อให้ใช้ชนิดเดิมของข้อมูล\n",
        "        # หรือแปลงข้อมูลเป็น float32 ก่อนเรียกฟังก์ชันนี้\n",
        "        sequence = tf.cast(sequence, tf.float32)  # แก้ไขตรงนี้\n",
        "\n",
        "        # เพิ่มสัญญาณรบกวน (Gaussian noise)\n",
        "        if tf.random.uniform([]) < 0.5:\n",
        "            noise = tf.random.normal(shape=tf.shape(sequence), mean=0.0, stddev=0.05)\n",
        "            sequence = sequence + noise\n",
        "\n",
        "        # สลับเวลา (Time shifting)\n",
        "        if tf.random.uniform([]) < 0.5:\n",
        "            shift = tf.random.uniform([], minval=-3, maxval=3, dtype=tf.int32)\n",
        "            sequence = tf.roll(sequence, shift, axis=0)\n",
        "\n",
        "        # สเกลแอมพลิจูด (Amplitude scaling)\n",
        "        if tf.random.uniform([]) < 0.5:\n",
        "            scale = tf.random.uniform([], minval=0.8, maxval=1.2)\n",
        "            sequence = sequence * scale\n",
        "\n",
        "        # หมุนและเอียง (ทำกับข้อมูลที่เป็นตำแหน่ง x, y, z)\n",
        "        # สมมติว่าข้อมูลมี dimension เป็น [timesteps, features, channels]\n",
        "        # ให้ปรับการหมุนให้เข้ากับรูปร่างข้อมูลที่มี 3 มิติ\n",
        "\n",
        "        return sequence, label\n",
        "\n",
        "    return augment_sequence\n",
        "\n",
        "  def create_train_dataset(self, batch_size=32, use_augmentation=True):\n",
        "        \"\"\"\n",
        "        สร้าง dataset สำหรับการเทรน\n",
        "\n",
        "        Args:\n",
        "            batch_size: ขนาด batch\n",
        "            use_augmentation: ใช้การเพิ่มข้อมูลหรือไม่\n",
        "\n",
        "        Returns:\n",
        "            tf.data.Dataset สำหรับการเทรน\n",
        "        \"\"\"\n",
        "        train_dataset = tf.data.Dataset.from_tensor_slices((self.X_train, self.y_train))\n",
        "\n",
        "        if use_augmentation:\n",
        "            augment_func = self.create_data_augmentation()\n",
        "            train_dataset = train_dataset.map(augment_func, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "\n",
        "        train_dataset = train_dataset.shuffle(buffer_size=len(self.X_train))\n",
        "        train_dataset = train_dataset.batch(batch_size)\n",
        "        train_dataset = train_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "        return train_dataset\n",
        "\n",
        "  def create_validation_dataset(self, batch_size=32):\n",
        "        # ตรวจสอบว่ามีข้อมูลเพียงพอสำหรับการแบ่ง\n",
        "      if len(self.X_train) < 10:  # ถ้าข้อมูลน้อยเกินไป\n",
        "          # ใช้ข้อมูลเดียวกันกับชุดข้อมูลทดสอบ\n",
        "          X_val = self.X_test\n",
        "          y_val = self.y_test\n",
        "      else:\n",
        "          # แยก validation set จาก training set\n",
        "          val_split = int(len(self.X_train) * 0.9)\n",
        "          X_val = self.X_train[val_split:]\n",
        "          y_val = self.y_train[val_split:]\n",
        "\n",
        "      val_dataset = tf.data.Dataset.from_tensor_slices((X_val, y_val))\n",
        "      val_dataset = val_dataset.batch(batch_size)\n",
        "      val_dataset = val_dataset.prefetch(tf.data.AUTOTUNE)\n",
        "\n",
        "      return val_dataset\n",
        "\n",
        "  def train_with_progressive_learning(self, epochs=300, batch_size=32, patience=20):\n",
        "        \"\"\"\n",
        "        ฝึกอบรมโมเดลด้วยการเรียนรู้แบบก้าวหน้า\n",
        "\n",
        "        Args:\n",
        "            epochs: จำนวนรอบการเทรนทั้งหมด\n",
        "            batch_size: ขนาด batch\n",
        "            patience: จำนวนรอบที่รอก่อนที่จะหยุดเมื่อไม่มีการปรับปรุง\n",
        "\n",
        "        Returns:\n",
        "            ประวัติการเทรน\n",
        "        \"\"\"\n",
        "        # เตรียมโมเดล\n",
        "        model = self.prepare_best_model()\n",
        "\n",
        "        # Callbacks\n",
        "        callbacks = [\n",
        "            # บันทึกโมเดลที่ดีที่สุด\n",
        "            ModelCheckpoint(\n",
        "                f'best_{self.best_model_name}_model.h5',\n",
        "                monitor='val_accuracy',\n",
        "                save_best_only=True,\n",
        "                mode='max',\n",
        "                verbose=1\n",
        "            ),\n",
        "            # ลด learning rate เมื่อไม่มีการปรับปรุง\n",
        "            ReduceLROnPlateau(\n",
        "                monitor='val_loss',\n",
        "                factor=0.5,\n",
        "                patience=10,\n",
        "                min_lr=1e-6,\n",
        "                verbose=1\n",
        "            ),\n",
        "            # หยุดเมื่อไม่มีการปรับปรุง\n",
        "            EarlyStopping(\n",
        "                monitor='val_loss',\n",
        "                patience=patience,\n",
        "                restore_best_weights=True,\n",
        "                verbose=1\n",
        "            )\n",
        "        ]\n",
        "\n",
        "        # สร้าง datasets\n",
        "        train_dataset = self.create_train_dataset(batch_size=batch_size)\n",
        "        val_dataset = self.create_validation_dataset(batch_size=batch_size)\n",
        "\n",
        "        # ฝึกอบรมโมเดล\n",
        "        history = model.fit(\n",
        "            train_dataset,\n",
        "            epochs=epochs,\n",
        "            validation_data=val_dataset,\n",
        "            callbacks=callbacks,\n",
        "            verbose=1\n",
        "        )\n",
        "\n",
        "        # บันทึกโมเดลสุดท้าย\n",
        "        model.save(f'final_{self.best_model_name}_model.h5')\n",
        "\n",
        "        self.best_model = model  # อัปเดตโมเดลที่ดีที่สุด\n",
        "\n",
        "        return history\n",
        "\n",
        "  def evaluate_model(self):\n",
        "        \"\"\"\n",
        "        ประเมินโมเดลบนชุดข้อมูลทดสอบ\n",
        "\n",
        "        Returns:\n",
        "            ผลการประเมิน\n",
        "        \"\"\"\n",
        "        if self.best_model is None:\n",
        "            raise ValueError(\"โมเดลยังไม่ได้รับการฝึกอบรม\")\n",
        "\n",
        "        # ประเมินบนชุดข้อมูลทดสอบ\n",
        "        test_loss, test_acc = self.best_model.evaluate(self.X_test, self.y_test)\n",
        "        print(f\"ความแม่นยำบนชุดข้อมูลทดสอบ: {test_acc:.4f}\")\n",
        "\n",
        "        # ทำนายคลาส\n",
        "        y_pred = np.argmax(self.best_model.predict(self.X_test), axis=1)\n",
        "\n",
        "        # สร้าง confusion matrix\n",
        "        cm = confusion_matrix(self.y_test, y_pred)\n",
        "\n",
        "        # สร้างรายงานการจำแนก\n",
        "        report = classification_report(self.y_test, y_pred, output_dict=True)\n",
        "\n",
        "        return {\n",
        "            'test_accuracy': test_acc,\n",
        "            'test_loss': test_loss,\n",
        "            'confusion_matrix': cm,\n",
        "            'classification_report': report\n",
        "        }\n",
        "\n",
        "  def plot_training_history(self, history):\n",
        "        \"\"\"\n",
        "        วาดกราฟประวัติการเทรน\n",
        "\n",
        "        Args:\n",
        "            history: ประวัติการเทรนจาก model.fit()\n",
        "        \"\"\"\n",
        "        # สร้างกราฟ\n",
        "        plt.figure(figsize=(12, 5))\n",
        "\n",
        "        # กราฟค่า accuracy\n",
        "        plt.subplot(1, 2, 1)\n",
        "        plt.plot(history.history['accuracy'], label='train')\n",
        "        plt.plot(history.history['val_accuracy'], label='validation')\n",
        "        plt.title('Model Accuracy')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Accuracy')\n",
        "        plt.legend()\n",
        "\n",
        "        # กราฟค่า loss\n",
        "        plt.subplot(1, 2, 2)\n",
        "        plt.plot(history.history['loss'], label='train')\n",
        "        plt.plot(history.history['val_loss'], label='validation')\n",
        "        plt.title('Model Loss')\n",
        "        plt.xlabel('Epoch')\n",
        "        plt.ylabel('Loss')\n",
        "        plt.legend()\n",
        "\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{self.best_model_name}_training_history.png')\n",
        "        plt.show()\n",
        "\n",
        "  def plot_confusion_matrix(self, cm, class_names=None):\n",
        "        \"\"\"\n",
        "        วาดกราฟ confusion matrix\n",
        "\n",
        "        Args:\n",
        "            cm: confusion matrix\n",
        "            class_names: ชื่อคลาส (หากมี)\n",
        "        \"\"\"\n",
        "        if class_names is None:\n",
        "            class_names = [str(i) for i in range(self.num_classes)]\n",
        "\n",
        "        plt.figure(figsize=(10, 8))\n",
        "        sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                   xticklabels=class_names,\n",
        "                   yticklabels=class_names)\n",
        "        plt.xlabel('Predicted Label')\n",
        "        plt.ylabel('True Label')\n",
        "        plt.title('Confusion Matrix')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig(f'{self.best_model_name}_confusion_matrix.png')\n",
        "        plt.show()\n",
        "\n",
        "  def analyze_errors(self, top_n=5):\n",
        "        \"\"\"\n",
        "        วิเคราะห์ข้อผิดพลาดที่พบบ่อย\n",
        "\n",
        "        Args:\n",
        "            top_n: จำนวนคู่ของความผิดพลาดที่พบบ่อยที่สุดที่จะแสดง\n",
        "        \"\"\"\n",
        "        # ทำนายบนชุดข้อมูลทดสอบ\n",
        "        y_pred = np.argmax(self.best_model.predict(self.X_test), axis=1)\n",
        "\n",
        "        # หาตัวอย่างที่ทำนายผิด\n",
        "        misclassified_indices = np.where(y_pred != self.y_test)[0]\n",
        "\n",
        "        if len(misclassified_indices) == 0:\n",
        "            print(\"ไม่พบข้อผิดพลาดในการทำนาย!\")\n",
        "            return\n",
        "\n",
        "        # สร้างตารางคู่ของ (ป้ายกำกับจริง, ป้ายกำกับที่ทำนาย)\n",
        "        error_pairs = [(self.y_test[i], y_pred[i]) for i in misclassified_indices]\n",
        "\n",
        "        # นับความถี่ของแต่ละคู่\n",
        "        error_counts = {}\n",
        "        for true_label, pred_label in error_pairs:\n",
        "            key = (true_label, pred_label)\n",
        "            if key in error_counts:\n",
        "                error_counts[key] += 1\n",
        "            else:\n",
        "                error_counts[key] = 1\n",
        "\n",
        "        # เรียงลำดับตามความถี่\n",
        "        sorted_errors = sorted(error_counts.items(), key=lambda x: x[1], reverse=True)\n",
        "\n",
        "        # แสดงคู่ที่พบบ่อยที่สุด\n",
        "        print(f\"คู่ของข้อผิดพลาดที่พบบ่อยที่สุด {min(top_n, len(sorted_errors))} คู่:\")\n",
        "        for (true_label, pred_label), count in sorted_errors[:top_n]:\n",
        "            print(f\"  ป้ายกำกับจริง: {true_label}, ทำนายเป็น: {pred_label}, จำนวน: {count} ครั้ง\")\n",
        "\n",
        "  def export_model_for_deployment(self, model_format='tflite'):\n",
        "      \"\"\"\n",
        "      ส่งออกโมเดลสำหรับการนำไปใช้งาน\n",
        "\n",
        "      Args:\n",
        "          model_format: รูปแบบของโมเดลที่จะส่งออก ('tflite' หรือ 'saved_model')\n",
        "\n",
        "      Returns:\n",
        "          พาธไปยังโมเดลที่ส่งออก\n",
        "      \"\"\"\n",
        "      if self.best_model is None:\n",
        "          raise ValueError(\"โมเดลยังไม่ได้รับการฝึกอบรม\")\n",
        "\n",
        "      if model_format == 'tflite':\n",
        "          try:\n",
        "              # แปลงเป็น TFLite\n",
        "              converter = tf.lite.TFLiteConverter.from_keras_model(self.best_model)\n",
        "\n",
        "              # ตั้งค่าพิเศษเพื่อเพิ่มความเข้ากันได้\n",
        "              converter.target_spec.supported_ops = [\n",
        "                  tf.lite.OpsSet.TFLITE_BUILTINS,  # ใช้ operator ที่มีมาตรฐานใน TFLite\n",
        "                  tf.lite.OpsSet.SELECT_TF_OPS     # ใช้ operator ของ TensorFlow ถ้าจำเป็น\n",
        "              ]\n",
        "\n",
        "              # ตั้งค่าเพิ่มเติมเพื่อให้ conversion สำเร็จ\n",
        "              converter.allow_custom_ops = True\n",
        "              converter.experimental_new_converter = True\n",
        "\n",
        "              # ลองลดขนาดโมเดล\n",
        "              converter.optimizations = [tf.lite.Optimize.DEFAULT]\n",
        "\n",
        "              # แปลงโมเดล\n",
        "              print(\"กำลังแปลงโมเดลเป็น TFLite...\")\n",
        "              tflite_model = converter.convert()\n",
        "\n",
        "              # บันทึกไฟล์\n",
        "              model_path = f'{self.best_model_name}_model.tflite'\n",
        "              with open(model_path, 'wb') as f:\n",
        "                  f.write(tflite_model)\n",
        "\n",
        "              print(f\"ส่งออกโมเดล TFLite แล้วที่: {model_path}\")\n",
        "              return model_path\n",
        "\n",
        "          except Exception as e:\n",
        "              print(f\"เกิดข้อผิดพลาดในการแปลงเป็น TFLite: {e}\")\n",
        "              print(\"ลองส่งออกในรูปแบบ SavedModel แทน...\")\n",
        "              # ส่งออกในรูปแบบ SavedModel เป็นตัวเลือกสำรอง\n",
        "              return self.export_model_for_deployment(model_format='saved_model')\n",
        "\n",
        "      elif model_format == 'saved_model':\n",
        "          try:\n",
        "              # บันทึกในรูปแบบ SavedModel\n",
        "              model_path = f'{self.best_model_name}_saved_model'\n",
        "              tf.saved_model.save(self.best_model, model_path)\n",
        "\n",
        "              print(f\"ส่งออกโมเดล SavedModel แล้วที่: {model_path}\")\n",
        "              return model_path\n",
        "          except Exception as e:\n",
        "              print(f\"เกิดข้อผิดพลาดในการส่งออกเป็น SavedModel: {e}\")\n",
        "              print(\"ลองส่งออกในรูปแบบ h5 แทน...\")\n",
        "\n",
        "              # ส่งออกในรูปแบบ h5 เป็นตัวเลือกสำรอง\n",
        "              model_path = f'{self.best_model_name}_model.h5'\n",
        "              self.best_model.save(model_path)\n",
        "              print(f\"ส่งออกโมเดลในรูปแบบ h5 แล้วที่: {model_path}\")\n",
        "              return model_path\n",
        "\n",
        "      else:\n",
        "          raise ValueError(\"รูปแบบโมเดลไม่ถูกต้อง ต้องเป็น 'tflite' หรือ 'saved_model'\")\n",
        "# ตัวอย่างการใช้งาน\n",
        "def main():\n",
        "    # สมมติว่าเรามีอ็อบเจ็กต์ SignLanguageModelSelector ที่สร้างไว้แล้ว\n",
        "    # และได้ทำการเปรียบเทียบโมเดลแล้ว\n",
        "    # model_selector = SignLanguageModelSelector(X_train, y_train, X_test, y_test)\n",
        "    # model_comparison = model_selector.compare_models()\n",
        "\n",
        "    # ในกรณีที่ต้องการทดสอบโดยไม่มี model_selector จริง\n",
        "    class DummyModelSelector:\n",
        "\n",
        "      def __init__(self):\n",
        "          # สร้างข้อมูลสมมติที่มีรูปร่าง 4 มิติ\n",
        "          self.X_train = np.random.random((1000, 30, 42, 3))  # เพิ่มมิติสุดท้าย\n",
        "          self.y_train = np.random.randint(0, 10, 1000)\n",
        "          self.X_test = np.random.random((200, 30, 42, 3))    # เพิ่มมิติสุดท้าย\n",
        "          self.y_test = np.random.randint(0, 10, 200)\n",
        "\n",
        "      # แก้ไขโมเดลให้รับข้อมูล 4 มิติ...\n",
        "      def create_lstm_model(self):\n",
        "          model = tf.keras.Sequential([\n",
        "              # เพิ่ม Reshape layer\n",
        "              tf.keras.layers.Reshape((30, 42*3), input_shape=(30, 42, 3)),\n",
        "              tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "              tf.keras.layers.Dropout(0.3),\n",
        "              tf.keras.layers.LSTM(32),\n",
        "              tf.keras.layers.Dense(10, activation='softmax')\n",
        "          ])\n",
        "          model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "          return model\n",
        "\n",
        "      def create_cnn_model(self):\n",
        "          model = tf.keras.Sequential([\n",
        "              # ใช้ Conv2D แทน Conv1D\n",
        "              tf.keras.layers.Conv2D(64, (3, 3), input_shape=(30, 42, 3), activation='relu'),\n",
        "              tf.keras.layers.MaxPooling2D(pool_size=(2, 2)),\n",
        "              tf.keras.layers.Flatten(),\n",
        "              tf.keras.layers.Dense(10, activation='softmax')\n",
        "          ])\n",
        "          model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "          return model\n",
        "\n",
        "      def create_transformermodel(self):\n",
        "          inputs = tf.keras.Input(shape=(30, 42, 3))\n",
        "          # แบนมิติสุดท้าย\n",
        "          x = tf.keras.layers.Reshape((30, 42*3))(inputs)\n",
        "          for _ in range(2):\n",
        "              x = tf.keras.layers.MultiHeadAttention(num_heads=4, key_dim=32)(x, x)\n",
        "              x = tf.keras.layers.LayerNormalization()(x)\n",
        "          x = tf.keras.layers.GlobalAveragePooling1D()(x)\n",
        "          x = tf.keras.layers.Dense(32, activation='relu')(x)\n",
        "          outputs = tf.keras.layers.Dense(10, activation='softmax')(x)\n",
        "          model = tf.keras.Model(inputs=inputs, outputs=outputs)\n",
        "          model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
        "          return model\n",
        "\n",
        "# สร้างอ็อบเจ็กต์ trainer\n",
        "    model_selector = DummyModelSelector()\n",
        "    trainer = SignLanguageModelTrainer(model_selector, best_model_name='LSTM')\n",
        "\n",
        "    # เทรนโมเดล\n",
        "    history = trainer.train_with_progressive_learning(epochs=50, batch_size=32)\n",
        "\n",
        "    # วาดกราฟประวัติการเทรน\n",
        "    trainer.plot_training_history(history)\n",
        "\n",
        "    # ประเมินโมเดล\n",
        "    eval_results = trainer.evaluate_model()\n",
        "\n",
        "    # วาดกราฟ confusion matrix\n",
        "    trainer.plot_confusion_matrix(eval_results['confusion_matrix'])\n",
        "\n",
        "    # วิเคราะห์ข้อผิดพลาด\n",
        "    trainer.analyze_errors()\n",
        "\n",
        "    # ส่งออกโมเดลสำหรับการนำไปใช้งาน\n",
        "    trainer.export_model_for_deployment()\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    main()"
      ],
      "metadata": {
        "id": "XQWxk5IMUaaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test\n"
      ],
      "metadata": {
        "id": "FCo8wBR4U19p"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import mediapipe as mp\n",
        "\n",
        "class SignLanguageTranslator:\n",
        "    def __init__(self, model_path):\n",
        "        # โหลดโมเดลที่ได้จากการเทรนเพิ่มเติม\n",
        "        self.model = tf.keras.models.load_model(model_path)\n",
        "\n",
        "        # ตั้งค่า MediaPipe Hands สำหรับการตรวจจับมือ\n",
        "        self.mp_hands = mp.solutions.hands\n",
        "        self.hands = self.mp_hands.Hands(\n",
        "            static_image_mode=False,\n",
        "            max_num_hands=1,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5\n",
        "        )\n",
        "\n",
        "        # คำแปลสัญญาณมือ (ตัวอย่าง)\n",
        "        self.sign_labels = [\"สวัสดี\", \"ขอบคุณ\", \"ช่วยเหลือ\", \"หิว\", \"น้ำ\", ...]\n",
        "\n",
        "        # ตัวแปรสำหรับเก็บตำแหน่งมือ\n",
        "        self.sequence = []\n",
        "        self.sequence_length = 30  # ต้องตรงกับ input shape ของโมเดล\n",
        "\n",
        "    def extract_hand_landmarks(self, frame):\n",
        "        # แปลงสีและประมวลผลภาพ\n",
        "        image = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "        results = self.hands.process(image)\n",
        "\n",
        "        # เริ่มต้นด้วยค่าว่างเปล่า\n",
        "        landmarks = np.zeros(42)  # 21 landmarks x 2 (x, y)\n",
        "\n",
        "        if results.multi_hand_landmarks:\n",
        "            hand_landmarks = results.multi_hand_landmarks[0]  # เลือกมือแรก\n",
        "\n",
        "            # แปลงตำแหน่งเป็น array ขนาด 42\n",
        "            landmarks_array = []\n",
        "            for landmark in hand_landmarks.landmark:\n",
        "                landmarks_array.extend([landmark.x, landmark.y])\n",
        "\n",
        "            landmarks = np.array(landmarks_array)\n",
        "\n",
        "        return landmarks\n",
        "\n",
        "    def update_sequence(self, landmarks):\n",
        "        # เพิ่มตำแหน่งมือใหม่เข้าไปในลำดับ\n",
        "        self.sequence.append(landmarks)\n",
        "\n",
        "        # คงความยาวของลำดับที่ sequence_length\n",
        "        if len(self.sequence) > self.sequence_length:\n",
        "            self.sequence = self.sequence[-self.sequence_length:]\n",
        "\n",
        "    def predict_sign(self):\n",
        "        # ตรวจสอบว่ามีข้อมูลเพียงพอหรือไม่\n",
        "        if len(self.sequence) < self.sequence_length:\n",
        "            return None\n",
        "\n",
        "        # แปลงลำดับเป็น array รูปแบบที่โมเดลต้องการ\n",
        "        X = np.array([self.sequence])\n",
        "\n",
        "        # ทำนายด้วยโมเดล\n",
        "        prediction = self.model.predict(X)[0]\n",
        "\n",
        "        # หาคลาสที่มีความน่าจะเป็นสูงสุด\n",
        "        predicted_class = np.argmax(prediction)\n",
        "        confidence = prediction[predicted_class]\n",
        "\n",
        "        # แสดงผลเฉพาะเมื่อความมั่นใจสูงพอ\n",
        "        if confidence > 0.7:\n",
        "            return self.sign_labels[predicted_class], confidence\n",
        "        else:\n",
        "            return None\n",
        "\n",
        "    def run_webcam(self):\n",
        "        cap = cv2.VideoCapture(0)\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                continue\n",
        "\n",
        "            # สกัดตำแหน่งมือ\n",
        "            landmarks = self.extract_hand_landmarks(frame)\n",
        "\n",
        "            # อัปเดตลำดับ\n",
        "            self.update_sequence(landmarks)\n",
        "\n",
        "            # ทำนายสัญญาณมือ\n",
        "            result = self.predict_sign()\n",
        "\n",
        "            # แสดงผลการทำนาย\n",
        "            if result:\n",
        "                sign, confidence = result\n",
        "                cv2.putText(frame, f\"{sign} ({confidence:.2f})\", (50, 50),\n",
        "                           cv2.FONT_HERSHEY_SIMPLEX, 1, (0, 255, 0), 2)\n",
        "\n",
        "            # แสดงเฟรม\n",
        "            cv2.imshow('Sign Language Translator', frame)\n",
        "\n",
        "            # กดปุ่ม q เพื่อออก\n",
        "            if cv2.waitKey(5) & 0xFF == ord('q'):\n",
        "                break\n",
        "\n",
        "        cap.release()\n",
        "        cv2.destroyAllWindows()\n",
        "\n",
        "# ตัวอย่างการใช้งาน\n",
        "translator = SignLanguageTranslator('final_LSTM_model.h5')\n",
        "translator.run_webcam()"
      ],
      "metadata": {
        "id": "ZviTVfR5U5yC"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "h2q27gKz1H20"
      ],
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}