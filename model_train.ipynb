{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "mount_file_id": "1vBoM9_m1omVL5E2sjUPaWWUppvUhDdku",
      "authorship_tag": "ABX9TyNF+Tw2Md5bo0if+TqITgzs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/thunwaaa/sign_language/blob/main/model_train.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Install library"
      ],
      "metadata": {
        "id": "7tuKbF8SuCkQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q mediapipe opencv-python matplotlib tqdm open3d pandas"
      ],
      "metadata": {
        "id": "d3SWNSt_4-CZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -q https://storage.googleapis.com/mediapipe-models/hand_landmarker/hand_landmarker/float16/1/hand_landmarker.task"
      ],
      "metadata": {
        "id": "AI1lrjzT24MR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Connect to Google Drive"
      ],
      "metadata": {
        "id": "UZ8PNdzAuNO6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "yFGBzVZI1Y_R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **สร้างโฟลเดอร์สำหรับเก็บผลลัพธ์**"
      ],
      "metadata": {
        "id": "nwP3uXjtuWe6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p '/content/drive/MyDrive/sign_language_3d_project/landmarks'\n",
        "!mkdir -p '/content/drive/MyDrive/sign_language_3d_project/visualizations'\n",
        "!mkdir -p '/content/drive/MyDrive/sign_language_3d_project/models'"
      ],
      "metadata": {
        "id": "ihgPp4p5uTzg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!ls \"/content/drive/MyDrive\" #check drive connect is complete or not?"
      ],
      "metadata": {
        "collapsed": true,
        "id": "9K-SYRMM1eZ6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import cv2\n",
        "import mediapipe as mp\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "from tqdm.notebook import tqdm"
      ],
      "metadata": {
        "id": "nmBsmDjM1-iJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "main_folder = '/content/drive/MyDrive/sign'\n",
        "output_folder = '/content/drive/MyDrive/sign_language_3d_project/landmarks'"
      ],
      "metadata": {
        "id": "-Elyb5Sj1qvO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# สำรวจโครงสร้างโฟลเดอร์\n",
        "sign_words = os.listdir(main_folder)\n",
        "print(f\"พบคำภาษามือทั้งหมด: {len(sign_words)} คำ\")"
      ],
      "metadata": {
        "id": "3t_yZxgE3uyw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ตรวจสอบจำนวนวิดีโอในแต่ละโฟลเดอร์\n",
        "for word in sign_words[:50]:  # แสดงตัวอย่าง 5 คำแรก\n",
        "    word_folder = os.path.join(main_folder, word)\n",
        "    videos = [f for f in os.listdir(word_folder) if f.endswith(('.mp4', '.avi', '.mov', '.MP4', '.MOV'))]\n",
        "    print(f\"คำ '{word}' มีวิดีโอ {len(videos)} คลิป\")"
      ],
      "metadata": {
        "id": "u1s8PyUr3z5X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#settings mediapipe\n",
        "mp_hands = mp.solutions.hands\n",
        "mp_pose = mp.solutions.pose\n",
        "mp_face_mesh = mp.solutions.face_mesh\n",
        "mp_drawing = mp.solutions.drawing_utils"
      ],
      "metadata": {
        "id": "CSuRbD0k2JSt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_landmarks_from_video(video_path, max_frames=30, extract_face=True):\n",
        "    \"\"\"\n",
        "    สกัดจุดสำคัญจากวิดีโอโดยใช้ MediaPipe\n",
        "\n",
        "    Args:\n",
        "        video_path (str): พาธไปยังไฟล์วิดีโอ\n",
        "        max_frames (int): จำนวนเฟรมสูงสุดที่จะสกัด\n",
        "        extract_face (bool): เปิดใช้การสกัดใบหน้าแบบละเอียดหรือไม่\n",
        "\n",
        "    Returns:\n",
        "        list: รายการข้อมูลจุดสำคัญในแต่ละเฟรม\n",
        "    \"\"\"\n",
        "    cap = cv2.VideoCapture(video_path)\n",
        "    frames_landmarks = []\n",
        "\n",
        "    # ตรวจสอบว่าเปิดวิดีโอได้หรือไม่\n",
        "    if not cap.isOpened():\n",
        "        print(f\"ไม่สามารถเปิดวิดีโอ: {video_path}\")\n",
        "        return frames_landmarks\n",
        "\n",
        "    # ดึงข้อมูลวิดีโอ\n",
        "    frame_count = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    duration = frame_count / fps if fps > 0 else 0\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "\n",
        "    print(f\"วิดีโอ: {os.path.basename(video_path)}\")\n",
        "    print(f\"  ความละเอียด: {width}x{height}\")\n",
        "    print(f\"  จำนวนเฟรม: {frame_count}\")\n",
        "    print(f\"  FPS: {fps}\")\n",
        "    print(f\"  ความยาว: {duration:.2f} วินาที\")\n",
        "\n",
        "    # คำนวณความถี่ในการสุ่มเฟรม (เพื่อให้ได้ max_frames เฟรม)\n",
        "    sample_interval = max(1, frame_count // max_frames)\n",
        "\n",
        "    # MediaPipe models\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as hands, \\\n",
        "        mp_pose.Pose(\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5) as pose:\n",
        "\n",
        "        # เพิ่ม Face Mesh ถ้าต้องการ\n",
        "        face_mesh = None\n",
        "        if extract_face:\n",
        "            face_mesh = mp_face_mesh.FaceMesh(\n",
        "                static_image_mode=False,\n",
        "                max_num_faces=1,\n",
        "                min_detection_confidence=0.5,\n",
        "                min_tracking_confidence=0.5)\n",
        "\n",
        "        frame_idx = 0\n",
        "        pbar = tqdm(total=min(frame_count, max_frames), desc=\"กำลังประมวลผลเฟรม\")\n",
        "\n",
        "        while cap.isOpened() and len(frames_landmarks) < max_frames:\n",
        "            success, frame = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            # สุ่มเฟรมตาม sample_interval\n",
        "            if frame_idx % sample_interval != 0:\n",
        "                frame_idx += 1\n",
        "                continue\n",
        "\n",
        "            # แปลงสี BGR เป็น RGB (MediaPipe ต้องการ RGB)\n",
        "            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # ตรวจจับมือและท่าทาง\n",
        "            hand_results = hands.process(frame_rgb)\n",
        "            pose_results = pose.process(frame_rgb)\n",
        "\n",
        "            # ตรวจจับใบหน้า (ถ้าเปิดใช้)\n",
        "            face_results = None\n",
        "            if face_mesh:\n",
        "                face_results = face_mesh.process(frame_rgb)\n",
        "\n",
        "            # สกัดข้อมูลจุดสำคัญ\n",
        "            frame_data = {\n",
        "                'frame_idx': frame_idx,\n",
        "                'timestamp': frame_idx / fps if fps > 0 else 0,\n",
        "                'hands': [],\n",
        "                'pose': None,\n",
        "                'face': None\n",
        "            }\n",
        "\n",
        "            # เก็บข้อมูลมือ\n",
        "            if hand_results.multi_hand_landmarks and hand_results.multi_handedness:\n",
        "                for i, (hand_landmarks, handedness) in enumerate(zip(\n",
        "                    hand_results.multi_hand_landmarks, hand_results.multi_handedness)):\n",
        "\n",
        "                    # ตรวจสอบว่าเป็นมือซ้ายหรือขวา\n",
        "                    hand_type = handedness.classification[0].label\n",
        "                    is_right = (hand_type == \"Right\")\n",
        "\n",
        "                    # เก็บข้อมูลจุดสำคัญ\n",
        "                    hand_data = []\n",
        "                    for landmark in hand_landmarks.landmark:\n",
        "                        hand_data.append([landmark.x, landmark.y, landmark.z])\n",
        "\n",
        "                    # เพิ่มข้อมูลมือ\n",
        "                    frame_data['hands'].append({\n",
        "                        'landmarks': hand_data,\n",
        "                        'is_right': is_right\n",
        "                    })\n",
        "\n",
        "            # เก็บข้อมูลท่าทาง\n",
        "            if pose_results.pose_landmarks:\n",
        "                pose_data = []\n",
        "                for landmark in pose_results.pose_landmarks.landmark:\n",
        "                    pose_data.append([landmark.x, landmark.y, landmark.z])\n",
        "                frame_data['pose'] = pose_data\n",
        "\n",
        "            # เก็บข้อมูลใบหน้า (ถ้ามี)\n",
        "            if face_mesh and face_results.multi_face_landmarks:\n",
        "                face_data = []\n",
        "                for face_landmarks in face_results.multi_face_landmarks:\n",
        "                    for landmark in face_landmarks.landmark:\n",
        "                        face_data.append([landmark.x, landmark.y, landmark.z])\n",
        "                    # เก็บเฉพาะใบหน้าแรก\n",
        "                    break\n",
        "                frame_data['face'] = face_data\n",
        "\n",
        "            # เพิ่มข้อมูลเฟรมนี้\n",
        "            frames_landmarks.append(frame_data)\n",
        "            frame_idx += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "    # ปิดวิดีโอ\n",
        "    cap.release()\n",
        "\n",
        "    if face_mesh:\n",
        "        face_mesh.close()\n",
        "\n",
        "    print(f\"สกัดข้อมูลสำเร็จ: {len(frames_landmarks)} เฟรม\")\n",
        "    return frames_landmarks"
      ],
      "metadata": {
        "id": "nX0fCUpy4IeP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "TCk8PfHM78bT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "cqsaHAAy78bU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดข้อมูลสรุป\n",
        "with open(os.path.join(output_folder, \"summary.json\"), 'r', encoding='utf-8') as f:\n",
        "    summary_data = json.load(f)\n",
        "\n",
        "# แสดงจำนวนวิดีโอในแต่ละคำ\n",
        "for word, count in summary_data.items():\n",
        "    print(f\"คำ '{word}': {count} วิดีโอ\")\n",
        "\n",
        "# โหลดข้อมูลของคำแรกเพื่อวิเคราะห์เพิ่มเติม\n",
        "first_word = list(summary_data.keys())[0]\n",
        "with open(os.path.join(output_folder, f\"{first_word}.json\"), 'r', encoding='utf-8') as f:\n",
        "    first_word_data = json.load(f)\n",
        "\n",
        "# ตรวจสอบจำนวนเฟรมในแต่ละวิดีโอ\n",
        "for i, video_data in enumerate(first_word_data):\n",
        "    print(f\"วิดีโอที่ {i+1}: {video_data['file_name']} - {len(video_data['landmarks'])} เฟรม\")"
      ],
      "metadata": {
        "id": "DYEk9Iz36wnf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "E6RsXiij78bU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ปรับปรุงการแสดงผลเพื่อตรวจสอบการจับจุดสำคัญ"
      ],
      "metadata": {
        "id": "JhA4-4KBFSVh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def visualize_hand_tracking_improved(input_video_path, output_video_path=None, show_face=True):\n",
        "    \"\"\"\n",
        "    สร้างวิดีโอที่แสดงการตรวจจับจุดสำคัญพร้อมหมายเลขจุดกำกับ\n",
        "\n",
        "    Args:\n",
        "        input_video_path: พาธไปยังวิดีโอต้นฉบับ\n",
        "        output_video_path: พาธสำหรับบันทึกวิดีโอผลลัพธ์\n",
        "        show_face: แสดงจุดสำคัญของใบหน้าหรือไม่\n",
        "\n",
        "    Returns:\n",
        "        str: พาธของวิดีโอผลลัพธ์\n",
        "    \"\"\"\n",
        "    # กำหนดพาธสำหรับบันทึกวิดีโอผลลัพธ์\n",
        "    if output_video_path is None:\n",
        "        file_name, file_ext = os.path.splitext(input_video_path)\n",
        "        output_video_path = f\"{file_name}_visualized{file_ext}\"\n",
        "\n",
        "    # MediaPipe\n",
        "    mp_drawing = mp.solutions.drawing_utils\n",
        "    mp_drawing_styles = mp.solutions.drawing_styles\n",
        "    mp_hands = mp.solutions.hands\n",
        "    mp_pose = mp.solutions.pose\n",
        "    mp_face_mesh = mp.solutions.face_mesh\n",
        "\n",
        "    # เปิดวิดีโอต้นฉบับ\n",
        "    cap = cv2.VideoCapture(input_video_path)\n",
        "    if not cap.isOpened():\n",
        "        print(f\"ไม่สามารถเปิดวิดีโอ: {input_video_path}\")\n",
        "        return None\n",
        "\n",
        "    # อ่านข้อมูลวิดีโอ\n",
        "    width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
        "    height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
        "    fps = cap.get(cv2.CAP_PROP_FPS)\n",
        "    total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
        "\n",
        "    # สร้าง VideoWriter สำหรับบันทึกวิดีโอผลลัพธ์\n",
        "    fourcc = cv2.VideoWriter_fourcc(*'mp4v')\n",
        "    out = cv2.VideoWriter(output_video_path, fourcc, fps, (width, height))\n",
        "\n",
        "    # ตัวเลือกการวาด\n",
        "    hand_drawing_spec = mp_drawing.DrawingSpec(color=(0, 255, 0), thickness=2)\n",
        "    hand_connection_spec = mp_drawing.DrawingSpec(color=(255, 0, 0), thickness=2)\n",
        "\n",
        "    # MediaPipe models\n",
        "    with mp_hands.Hands(\n",
        "        static_image_mode=False,\n",
        "        max_num_hands=2,\n",
        "        min_detection_confidence=0.5,\n",
        "        min_tracking_confidence=0.5) as hands, \\\n",
        "        mp_pose.Pose(\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5) as pose, \\\n",
        "        mp_face_mesh.FaceMesh(\n",
        "            static_image_mode=False,\n",
        "            max_num_faces=1,\n",
        "            min_detection_confidence=0.5,\n",
        "            min_tracking_confidence=0.5) as face_mesh:\n",
        "\n",
        "        # วนลูปผ่านทุกเฟรมในวิดีโอ\n",
        "        pbar = tqdm(total=total_frames, desc=\"กำลังประมวลผลวิดีโอ\")\n",
        "        frame_count = 0\n",
        "\n",
        "        while cap.isOpened():\n",
        "            success, image = cap.read()\n",
        "            if not success:\n",
        "                break\n",
        "\n",
        "            # แปลงภาพเป็น RGB สำหรับ MediaPipe\n",
        "            image_rgb = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
        "\n",
        "            # ประมวลผลภาพด้วย MediaPipe\n",
        "            hand_results = hands.process(image_rgb)\n",
        "            pose_results = pose.process(image_rgb)\n",
        "            face_results = face_mesh.process(image_rgb) if show_face else None\n",
        "\n",
        "            # วาดข้อมูลบนภาพ\n",
        "            annotated_image = image.copy()\n",
        "\n",
        "            # แสดงเฟรมเคาท์เตอร์\n",
        "            cv2.putText(\n",
        "                annotated_image,\n",
        "                f\"Frame: {frame_count}\",\n",
        "                (10, 30),\n",
        "                cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                1,\n",
        "                (0, 255, 255),\n",
        "                2\n",
        "            )\n",
        "\n",
        "            # วาดจุดสำคัญและเส้นเชื่อมต่อของมือ\n",
        "            if hand_results.multi_hand_landmarks:\n",
        "                for i, hand_landmarks in enumerate(hand_results.multi_hand_landmarks):\n",
        "                    # วาดจุดและเส้นเชื่อมต่อ\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        annotated_image,\n",
        "                        hand_landmarks,\n",
        "                        mp_hands.HAND_CONNECTIONS,\n",
        "                        hand_drawing_spec,\n",
        "                        hand_connection_spec)\n",
        "\n",
        "                    # วาดหมายเลขกำกับจุดสำคัญ\n",
        "                    for id, lm in enumerate(hand_landmarks.landmark):\n",
        "                        h, w, c = annotated_image.shape\n",
        "                        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                        cv2.putText(\n",
        "                            annotated_image,\n",
        "                            str(id),\n",
        "                            (cx, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.5,\n",
        "                            (255, 255, 0),\n",
        "                            1\n",
        "                        )\n",
        "\n",
        "                    # ระบุว่าเป็นมือซ้ายหรือขวา\n",
        "                    if i < len(hand_results.multi_handedness):\n",
        "                        handedness = hand_results.multi_handedness[i]\n",
        "                        hand_type = handedness.classification[0].label\n",
        "                        h, w, c = annotated_image.shape\n",
        "                        wrist = hand_landmarks.landmark[0]\n",
        "                        cx, cy = int(wrist.x * w), int(wrist.y * h)\n",
        "                        cv2.putText(\n",
        "                            annotated_image,\n",
        "                            hand_type,\n",
        "                            (cx, cy - 20),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.7,\n",
        "                            (255, 0, 0),\n",
        "                            2\n",
        "                        )\n",
        "\n",
        "            # วาดจุดสำคัญและเส้นเชื่อมต่อของท่าทาง\n",
        "            if pose_results.pose_landmarks:\n",
        "                mp_drawing.draw_landmarks(\n",
        "                    annotated_image,\n",
        "                    pose_results.pose_landmarks,\n",
        "                    mp_pose.POSE_CONNECTIONS,\n",
        "                    mp_drawing_styles.get_default_pose_landmarks_style())\n",
        "\n",
        "                # วาดหมายเลขกำกับเฉพาะจุดสำคัญของแขนและลำตัวส่วนบน\n",
        "                for id, lm in enumerate(pose_results.pose_landmarks.landmark):\n",
        "                    if id in range(11, 23):  # แขนและลำตัวส่วนบน\n",
        "                        h, w, c = annotated_image.shape\n",
        "                        cx, cy = int(lm.x * w), int(lm.y * h)\n",
        "                        cv2.putText(\n",
        "                            annotated_image,\n",
        "                            str(id),\n",
        "                            (cx, cy),\n",
        "                            cv2.FONT_HERSHEY_SIMPLEX,\n",
        "                            0.5,\n",
        "                            (0, 0, 255),\n",
        "                            1\n",
        "                        )\n",
        "\n",
        "            # วาดใบหน้า (ถ้าเปิดใช้)\n",
        "            if show_face and face_results.multi_face_landmarks:\n",
        "                for face_landmarks in face_results.multi_face_landmarks:\n",
        "                    mp_drawing.draw_landmarks(\n",
        "                        image=annotated_image,\n",
        "                        landmark_list=face_landmarks,\n",
        "                        connections=mp_face_mesh.FACEMESH_TESSELATION,\n",
        "                        landmark_drawing_spec=None,\n",
        "                        connection_drawing_spec=mp_drawing_styles.get_default_face_mesh_tesselation_style())\n",
        "\n",
        "            # บันทึกเฟรม\n",
        "            out.write(annotated_image)\n",
        "            frame_count += 1\n",
        "            pbar.update(1)\n",
        "\n",
        "        pbar.close()\n",
        "\n",
        "    # ปิดการเชื่อมต่อ\n",
        "    cap.release()\n",
        "    out.release()\n",
        "\n",
        "    print(f\"บันทึกวิดีโอผลลัพธ์ไว้ที่: {output_video_path}\")\n",
        "    return output_video_path"
      ],
      "metadata": {
        "id": "8Mg7PjIR7nHw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### สร้างฟังก์ชันประมวลผลวิดีโอทั้งหมด"
      ],
      "metadata": {
        "id": "YgdSwQ1mFo5j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def process_all_videos_improved(main_folder, output_folder, max_frames=30, extract_face=True,\n",
        "                               skip_processed=True, batch_size=None):\n",
        "    \"\"\"\n",
        "    ประมวลผลวิดีโอทั้งหมดและบันทึกข้อมูลจุดสำคัญ\n",
        "\n",
        "    Args:\n",
        "        main_folder: โฟลเดอร์ที่เก็บวิดีโอภาษามือ\n",
        "        output_folder: โฟลเดอร์สำหรับบันทึกผลลัพธ์\n",
        "        max_frames: จำนวนเฟรมสูงสุดต่อวิดีโอ\n",
        "        extract_face: เปิดใช้การสกัดใบหน้าแบบละเอียดหรือไม่\n",
        "        skip_processed: ข้ามคำที่ประมวลผลแล้วหรือไม่\n",
        "        batch_size: จำนวนคำที่จะประมวลผลในแต่ละรอบ (None = ทั้งหมด)\n",
        "\n",
        "    Returns:\n",
        "        dict: ข้อมูลสรุป\n",
        "    \"\"\"\n",
        "    # สร้างโฟลเดอร์สำหรับเก็บผลลัพธ์ถ้ายังไม่มี\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "    vis_folder = '/content/drive/MyDrive/sign_language_3d_project/visualizations'\n",
        "    os.makedirs(vis_folder, exist_ok=True)\n",
        "\n",
        "    # โหลดข้อมูลสรุปที่มีอยู่เดิม (ถ้ามี)\n",
        "    summary_file = os.path.join(output_folder, \"summary.json\")\n",
        "    processed_words = {}\n",
        "    if os.path.exists(summary_file) and skip_processed:\n",
        "        try:\n",
        "            with open(summary_file, 'r', encoding='utf-8') as f:\n",
        "                processed_words = json.load(f)\n",
        "            print(f\"พบข้อมูลสรุปเดิม: มีคำที่ประมวลผลแล้ว {len(processed_words)} คำ\")\n",
        "        except Exception as e:\n",
        "            print(f\"เกิดข้อผิดพลาดในการโหลดข้อมูลสรุมเดิม: {str(e)}\")\n",
        "            processed_words = {}\n",
        "\n",
        "    # รายการคำทั้งหมด (เฉพาะโฟลเดอร์)\n",
        "    sign_words = [d for d in os.listdir(main_folder)\n",
        "                 if os.path.isdir(os.path.join(main_folder, d))]\n",
        "\n",
        "    total_words = len(sign_words)\n",
        "    print(f\"พบคำทั้งหมด: {total_words} คำ\")\n",
        "\n",
        "    # กำหนดขนาดแบทช์ถ้าไม่ได้ระบุ\n",
        "    if batch_size is None:\n",
        "        batch_size = total_words\n",
        "\n",
        "    all_data = processed_words.copy()  # เก็บข้อมูลทั้งหมด (รวมที่ประมวลผลไปแล้ว)\n",
        "\n",
        "    # คำนวณจำนวนแบทช์\n",
        "    num_batches = (total_words + batch_size - 1) // batch_size\n",
        "\n",
        "    # ประมวลผลทีละแบทช์\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, total_words)\n",
        "\n",
        "        print(f\"\\n=== ประมวลผลแบทช์ {batch_idx + 1}/{num_batches}: คำที่ {start_idx + 1} ถึง {end_idx} ===\")\n",
        "\n",
        "        # คำในแบทช์นี้\n",
        "        batch_words = sign_words[start_idx:end_idx]\n",
        "\n",
        "        # วนลูปผ่านทุกคำในแบทช์\n",
        "        for word in tqdm(batch_words, desc=f\"Processing words in batch {batch_idx + 1}\"):\n",
        "            # ข้ามคำที่ประมวลผลแล้ว\n",
        "            if word in processed_words and skip_processed:\n",
        "                print(f\"\\nข้ามคำ '{word}' เนื่องจากประมวลผลไปแล้ว\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nกำลังประมวลผลคำ: '{word}'\")\n",
        "\n",
        "            word_folder = os.path.join(main_folder, word)\n",
        "            videos = [f for f in os.listdir(word_folder)\n",
        "                     if f.lower().endswith(('.mp4', '.avi', '.mov', '.MP4', '.MOV'))]\n",
        "\n",
        "            word_data = []  # เก็บข้อมูลของคำนี้\n",
        "\n",
        "            # วนลูปผ่านทุกวิดีโอของคำนี้\n",
        "            for video_file in tqdm(videos, desc=f\"Videos for {word}\", leave=False):\n",
        "                video_path = os.path.join(word_folder, video_file)\n",
        "                print(f\"\\nกำลังประมวลผลวิดีโอ: {video_file}\")\n",
        "\n",
        "                try:\n",
        "                    # สกัดจุดสำคัญจากวิดีโอ\n",
        "                    landmarks = extract_landmarks_from_video(\n",
        "                        video_path,\n",
        "                        max_frames=max_frames,\n",
        "                        extract_face=extract_face\n",
        "                    )\n",
        "\n",
        "                    # เพิ่มข้อมูลเข้าไปในรายการของคำนี้\n",
        "                    video_data = {\n",
        "                        \"file_name\": video_file,\n",
        "                        \"landmarks\": landmarks\n",
        "                    }\n",
        "                    word_data.append(video_data)\n",
        "\n",
        "                    # สร้างวิดีโอแสดงผลการจับจุดสำคัญ\n",
        "                    word_vis_folder = os.path.join(vis_folder, word)\n",
        "                    os.makedirs(word_vis_folder, exist_ok=True)\n",
        "\n",
        "                    output_video_path = os.path.join(word_vis_folder, f\"{video_file}_viz.mp4\")\n",
        "                    visualize_hand_tracking_improved(\n",
        "                        video_path,\n",
        "                        output_video_path,\n",
        "                        show_face=extract_face\n",
        "                    )\n",
        "\n",
        "                except Exception as e:\n",
        "                    print(f\"เกิดข้อผิดพลาดกับวิดีโอ {video_file}: {str(e)}\")\n",
        "\n",
        "            # บันทึกข้อมูลของคำนี้\n",
        "            all_data[word] = len(word_data)\n",
        "\n",
        "            # บันทึกข้อมูลแยกตามคำ\n",
        "            word_output_file = os.path.join(output_folder, f\"{word}.json\")\n",
        "            with open(word_output_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(word_data, f)\n",
        "\n",
        "            # อัปเดตและบันทึกข้อมูลสรุปหลังจากประมวลผลแต่ละคำ (ป้องกันการหลุดการเชื่อมต่อ)\n",
        "            with open(summary_file, 'w', encoding='utf-8') as f:\n",
        "                json.dump(all_data, f)\n",
        "\n",
        "            print(f\"บันทึกข้อมูลสำหรับคำ '{word}' เรียบร้อย: {len(word_data)} วิดีโอ\")\n",
        "            print(f\"ความคืบหน้า: {len(all_data)}/{total_words} คำ ({len(all_data)/total_words*100:.2f}%)\")\n",
        "\n",
        "    print(f\"\\nประมวลผลเสร็จสิ้น! บันทึกข้อมูลไว้ที่ {output_folder}\")\n",
        "    print(f\"จำนวนคำที่ประมวลผล: {len(all_data)}\")\n",
        "\n",
        "    return all_data"
      ],
      "metadata": {
        "id": "3WhyM8yG6h16"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ทดสอบการประมวลผลกับวิดีโอตัวอย่าง"
      ],
      "metadata": {
        "id": "NetbCm0oFyD9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "lPdK9bFHNdGO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ทดสอบกับวิดีโอตัวอย่าง 3 คำ คำละ 2 วิดีโอ\n",
        "test_output_folder = '/content/drive/MyDrive/sign_language_3d_project/landmarks'\n",
        "all_data = process_all_videos(\n",
        "    main_folder=main_folder,\n",
        "    output_folder=test_output_folder,\n",
        "    num_words=3,              # เริ่มต้นด้วย 3 คำ\n",
        "    max_videos_per_word=2,    # แต่ละคำใช้ 2 วิดีโอ\n",
        "    max_frames=30,            # แต่ละวิดีโอเก็บ 30 เฟรม\n",
        "    extract_face=True         # เก็บข้อมูลใบหน้าด้วย\n",
        ")\n",
        "\n",
        "# แสดงภาพตัวอย่างวิดีโอที่ประมวลผลแล้ว\n",
        "from IPython.display import HTML\n",
        "from base64 import b64encode\n",
        "\n",
        "def display_video(video_path):\n",
        "    \"\"\"แสดงวิดีโอใน Colab\"\"\"\n",
        "    with open(video_path, \"rb\") as f:\n",
        "        video_file = f.read()\n",
        "    video_url = f\"data:video/mp4;base64,{b64encode(video_file).decode()}\"\n",
        "    return HTML(f\"\"\"<video width=640 controls><source src=\"{video_url}\"></video>\"\"\")\n",
        "\n",
        "# เลือกวิดีโอแรกของคำแรกมาแสดง\n",
        "first_word = list(all_data.keys())[0]\n",
        "first_video = all_data[first_word][0]['file_name']\n",
        "vis_video_path = f\"/content/drive/MyDrive/sign_language_3d_project/visualizations/{first_word}/{first_video}_viz.mp4\"\n",
        "display_video(vis_video_path)"
      ],
      "metadata": {
        "id": "tT5yiu4-GxNo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "JlgzG-DrNdGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "lZN58TSwNdGP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# เตรียมข้อมูลสำหรับโมเดล 3D"
      ],
      "metadata": {
        "id": "FbEjkjwIF7AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def prepare_data_for_3d_model(landmarks_data):\n",
        "    \"\"\"\n",
        "    แปลงข้อมูลให้พร้อมใช้กับโมเดล 3D\n",
        "\n",
        "    Args:\n",
        "        landmarks_data: ข้อมูลจุดสำคัญที่สกัดได้\n",
        "\n",
        "    Returns:\n",
        "        dict: ข้อมูลที่จัดรูปแบบสำหรับโมเดล 3D\n",
        "    \"\"\"\n",
        "    processed_data = []\n",
        "\n",
        "    for frame_data in landmarks_data:\n",
        "        frame_3d_data = {\n",
        "            'frame_idx': frame_data.get('frame_idx', 0),\n",
        "            'timestamp': frame_data.get('timestamp', 0),\n",
        "            'hands': [],\n",
        "            'pose': None,\n",
        "            'face': None\n",
        "        }\n",
        "\n",
        "        # แปลงข้อมูลมือ\n",
        "        for hand in frame_data['hands']:\n",
        "            hand_landmarks = hand['landmarks']\n",
        "            is_right = hand['is_right']\n",
        "\n",
        "            # จัดกลุ่มจุดตามส่วนของมือ\n",
        "            hand_3d = {\n",
        "                'is_right': is_right,\n",
        "                'wrist': hand_landmarks[0],\n",
        "                'thumb': hand_landmarks[1:5],\n",
        "                'index': hand_landmarks[5:9],\n",
        "                'middle': hand_landmarks[9:13],\n",
        "                'ring': hand_landmarks[13:17],\n",
        "                'pinky': hand_landmarks[17:21],\n",
        "                'palm': [hand_landmarks[0], hand_landmarks[5], hand_landmarks[9], hand_landmarks[13], hand_landmarks[17]]\n",
        "            }\n",
        "\n",
        "            frame_3d_data['hands'].append(hand_3d)\n",
        "\n",
        "        # แปลงข้อมูลท่าทาง\n",
        "        if frame_data['pose']:\n",
        "            pose = frame_data['pose']\n",
        "            pose_3d = {\n",
        "                'head': pose[0:11],\n",
        "                'torso': [pose[11], pose[12], pose[23], pose[24]],\n",
        "                'left_arm': [pose[11], pose[13], pose[15], pose[17], pose[19], pose[21]],\n",
        "                'right_arm': [pose[12], pose[14], pose[16], pose[18], pose[20], pose[22]],\n",
        "                'left_leg': [pose[23], pose[25], pose[27], pose[29], pose[31]],\n",
        "                'right_leg': [pose[24], pose[26], pose[28], pose[30], pose[32]]\n",
        "            }\n",
        "\n",
        "            frame_3d_data['pose'] = pose_3d\n",
        "\n",
        "        # แปลงข้อมูลใบหน้า (ถ้ามี)\n",
        "        if frame_data.get('face'):\n",
        "            # เลือกจุดสำคัญหลักของใบหน้า (ลดจำนวนจุดลง)\n",
        "            # เลือกเฉพาะจุดรอบตา จมูก ปาก และขอบหน้า\n",
        "            face = frame_data['face']\n",
        "            face_3d = {\n",
        "                'contour': [face[i] for i in range(0, 468, 20)],  # เลือกบางจุดเท่านั้น\n",
        "                'left_eye': [face[33], face[133], face[160], face[159], face[158], face[144], face[145], face[153]],\n",
        "                'right_eye': [face[263], face[362], face[385], face[386], face[387], face[373], face[374], face[380]],\n",
        "                'nose': [face[1], face[2], face[3], face[4], face[5], face[6], face[168], face[197], face[195]],\n",
        "                'mouth': [face[0], face[267], face[269], face[270], face[409], face[291], face[375], face[321], face[405], face[314], face[17], face[84], face[181], face[91], face[146]]\n",
        "            }\n",
        "\n",
        "            frame_3d_data['face'] = face_3d\n",
        "\n",
        "        processed_data.append(frame_3d_data)\n",
        "\n",
        "    return processed_data"
      ],
      "metadata": {
        "id": "5maRHLaD65OX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###  บันทึกข้อมูลที่แปลงแล้วสำหรับโมเดล 3D"
      ],
      "metadata": {
        "id": "-9OmDR1HGKnC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.enable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "dQn1g0eTPRDG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def export_3d_ready_data_improved(input_folder, output_folder, skip_processed=True, batch_size=None):\n",
        "    \"\"\"\n",
        "    แปลงข้อมูลและบันทึกในรูปแบบที่พร้อมใช้กับโมเดล 3D\n",
        "\n",
        "    Args:\n",
        "        input_folder: โฟลเดอร์ที่เก็บข้อมูลจุดสำคัญดิบ\n",
        "        output_folder: โฟลเดอร์สำหรับบันทึกข้อมูลที่แปลงแล้ว\n",
        "        skip_processed: ข้ามคำที่ประมวลผลแล้วหรือไม่\n",
        "        batch_size: จำนวนคำที่จะประมวลผลในแต่ละรอบ (None = ทั้งหมด)\n",
        "    \"\"\"\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    # โหลดข้อมูลสรุป\n",
        "    summary_file = os.path.join(input_folder, \"summary.json\")\n",
        "    with open(summary_file, 'r', encoding='utf-8') as f:\n",
        "        summary_data = json.load(f)\n",
        "\n",
        "    # โหลดข้อมูลสรุปที่แปลงแล้ว (ถ้ามี)\n",
        "    processed_summary_file = os.path.join(output_folder, \"summary_3d.json\")\n",
        "    processed_words = {}\n",
        "    if os.path.exists(processed_summary_file) and skip_processed:\n",
        "        try:\n",
        "            with open(processed_summary_file, 'r', encoding='utf-8') as f:\n",
        "                processed_words = json.load(f)\n",
        "            print(f\"พบข้อมูลสรุป 3D เดิม: มีคำที่แปลงแล้ว {len(processed_words)} คำ\")\n",
        "        except Exception as e:\n",
        "            print(f\"เกิดข้อผิดพลาดในการโหลดข้อมูลสรุม 3D เดิม: {str(e)}\")\n",
        "            processed_words = {}\n",
        "\n",
        "    # สร้างข้อมูลสรุปใหม่\n",
        "    new_summary = processed_words.copy()\n",
        "\n",
        "    # รายการคำทั้งหมด\n",
        "    all_words = list(summary_data.keys())\n",
        "    total_words = len(all_words)\n",
        "    print(f\"พบคำทั้งหมด: {total_words} คำ\")\n",
        "\n",
        "    # กำหนดขนาดแบทช์ถ้าไม่ได้ระบุ\n",
        "    if batch_size is None:\n",
        "        batch_size = total_words\n",
        "\n",
        "    # คำนวณจำนวนแบทช์\n",
        "    num_batches = (total_words + batch_size - 1) // batch_size\n",
        "\n",
        "    # ประมวลผลทีละแบทช์\n",
        "    for batch_idx in range(num_batches):\n",
        "        start_idx = batch_idx * batch_size\n",
        "        end_idx = min((batch_idx + 1) * batch_size, total_words)\n",
        "\n",
        "        print(f\"\\n=== แปลงข้อมูลแบทช์ {batch_idx + 1}/{num_batches}: คำที่ {start_idx + 1} ถึง {end_idx} ===\")\n",
        "\n",
        "        # คำในแบทช์นี้\n",
        "        batch_words = all_words[start_idx:end_idx]\n",
        "\n",
        "        # แปลงข้อมูลทุกคำในแบทช์\n",
        "        for word in tqdm(batch_words, desc=f\"Converting data for 3D model in batch {batch_idx + 1}\"):\n",
        "            # ข้ามคำที่แปลงแล้ว\n",
        "            if word in processed_words and skip_processed:\n",
        "                print(f\"\\nข้ามคำ '{word}' เนื่องจากแปลงแล้ว\")\n",
        "                continue\n",
        "\n",
        "            print(f\"\\nกำลังแปลงข้อมูลคำ: '{word}'\")\n",
        "\n",
        "            try:\n",
        "                # โหลดข้อมูลคำ\n",
        "                word_file = os.path.join(input_folder, f\"{word}.json\")\n",
        "                if not os.path.exists(word_file):\n",
        "                    print(f\"ไม่พบไฟล์ข้อมูลสำหรับคำ '{word}'\")\n",
        "                    continue\n",
        "\n",
        "                with open(word_file, 'r', encoding='utf-8') as f:\n",
        "                    word_data = json.load(f)\n",
        "\n",
        "                word_3d_data = []\n",
        "\n",
        "                # แปลงข้อมูลทุกวิดีโอของคำนี้\n",
        "                for video_data in tqdm(word_data, desc=f\"Videos for {word}\", leave=False):\n",
        "                    video_name = video_data['file_name']\n",
        "                    landmarks = video_data['landmarks']\n",
        "\n",
        "                    # แปลงข้อมูลให้พร้อมใช้กับโมเดล 3D\n",
        "                    processed_landmarks = prepare_data_for_3d_model(landmarks)\n",
        "\n",
        "                    # เพิ่มข้อมูลที่แปลงแล้ว\n",
        "                    video_3d_data = {\n",
        "                        \"file_name\": video_name,\n",
        "                        \"frames\": processed_landmarks\n",
        "                    }\n",
        "                    word_3d_data.append(video_3d_data)\n",
        "\n",
        "                # บันทึกข้อมูลที่แปลงแล้วของคำนี้\n",
        "                output_file = os.path.join(output_folder, f\"{word}_3d.json\")\n",
        "                with open(output_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(word_3d_data, f)\n",
        "\n",
        "                new_summary[word] = len(word_3d_data)\n",
        "\n",
        "                # อัปเดตและบันทึกข้อมูลสรุปหลังจากแปลงแต่ละคำ (ป้องกันการหลุดการเชื่อมต่อ)\n",
        "                with open(processed_summary_file, 'w', encoding='utf-8') as f:\n",
        "                    json.dump(new_summary, f)\n",
        "\n",
        "                print(f\"บันทึกข้อมูล 3D สำหรับคำ '{word}' เรียบร้อย: {len(word_3d_data)} วิดีโอ\")\n",
        "                print(f\"ความคืบหน้า: {len(new_summary)}/{total_words} คำ ({len(new_summary)/total_words*100:.2f}%)\")\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"เกิดข้อผิดพลาดในการแปลงข้อมูลคำ '{word}': {str(e)}\")\n",
        "\n",
        "    print(f\"\\nการแปลงข้อมูลเสร็จสิ้น! บันทึกข้อมูลไว้ที่ {output_folder}\")\n",
        "    print(f\"จำนวนคำที่แปลง: {len(new_summary)}\")\n",
        "\n",
        "    return new_summary"
      ],
      "metadata": {
        "id": "j0poBQuMGM-a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support for third party widgets will remain active for the duration of the session. To disable support:"
      ],
      "metadata": {
        "id": "KtPqK3WDPRDI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import output\n",
        "output.disable_custom_widget_manager()"
      ],
      "metadata": {
        "id": "Bh2AXDEXPRDJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ประมวลผลวิดีโอทั้งหมดในครั้งเดียว\n",
        "main_folder = '/content/drive/MyDrive/sign'\n",
        "output_folder = '/content/drive/MyDrive/sign_language_3d_project/landmarks'\n",
        "all_data = process_all_videos_improved(\n",
        "    main_folder=main_folder,\n",
        "    output_folder=output_folder,\n",
        "    max_frames=30,\n",
        "    extract_face=True,\n",
        "    skip_processed=True  # ข้ามคำที่เคยประมวลผลแล้ว\n",
        ")\n",
        "\n",
        "# แปลงข้อมูลทั้งหมดเป็นรูปแบบ 3D ในครั้งเดียว\n",
        "landmarks_folder = '/content/drive/MyDrive/sign_language_3d_project/landmarks'\n",
        "output_3d_folder = '/content/drive/MyDrive/sign_language_3d_project/3d_data'\n",
        "export_3d_ready_data_improved(\n",
        "    input_folder=landmarks_folder,\n",
        "    output_folder=output_3d_folder,\n",
        "    skip_processed=True  # ข้ามคำที่เคยแปลงแล้ว\n",
        ")"
      ],
      "metadata": {
        "id": "RanGJ_4uRW0B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ตรวจสอบข้อมูลที่แปลงแล้ว"
      ],
      "metadata": {
        "id": "OMCoMCEyGPxI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# โหลดและตรวจสอบข้อมูลที่แปลงแล้ว\n",
        "def verify_3d_data(folder_path):\n",
        "    \"\"\"ตรวจสอบความถูกต้องของข้อมูลที่แปลงแล้ว\"\"\"\n",
        "    # โหลดข้อมูลสรุป\n",
        "    with open(os.path.join(folder_path, \"summary_3d.json\"), 'r', encoding='utf-8') as f:\n",
        "        summary = json.load(f)\n",
        "\n",
        "    print(f\"จำนวนคำทั้งหมด: {len(summary)}\")\n",
        "\n",
        "    # เลือกคำแรกเพื่อตรวจสอบ\n",
        "    first_word = list(summary.keys())[0]\n",
        "    print(f\"\\nกำลังตรวจสอบคำ: '{first_word}'\")\n",
        "\n",
        "    # โหลดข้อมูลคำ\n",
        "    with open(os.path.join(folder_path, f\"{first_word}_3d.json\"), 'r', encoding='utf-8') as f:\n",
        "        word_data = json.load(f)\n",
        "\n",
        "    print(f\"จำนวนวิดีโอของคำนี้: {len(word_data)}\")\n",
        "\n",
        "    # เลือกวิดีโอแรกเพื่อตรวจสอบ\n",
        "    first_video = word_data[0]\n",
        "    print(f\"\\nชื่อวิดีโอ: {first_video['file_name']}\")\n",
        "    print(f\"จำนวนเฟรม: {len(first_video['frames'])}\")\n",
        "\n",
        "    # ตรวจสอบเฟรมแรก\n",
        "    first_frame = first_video['frames'][0]\n",
        "    print(\"\\nโครงสร้างข้อมูลเฟรมแรก:\")\n",
        "\n",
        "    # ตรวจสอบข้อมูลมือ\n",
        "    print(f\"จำนวนมือ: {len(first_frame['hands'])}\")\n",
        "    if first_frame['hands']:\n",
        "        hand = first_frame['hands'][0]\n",
        "        print(f\"ประเภทมือ: {'ขวา' if hand['is_right'] else 'ซ้าย'}\")\n",
        "        print(f\"จำนวนจุดสำคัญนิ้วหัวแม่มือ: {len(hand['thumb'])}\")\n",
        "\n",
        "    # ตรวจสอบข้อมูลท่าทาง\n",
        "    if first_frame['pose']:\n",
        "        print(\"\\nข้อมูลท่าทาง:\")\n",
        "        for part, points in first_frame['pose'].items():\n",
        "            print(f\"  {part}: {len(points)} จุด\")\n",
        "\n",
        "    # ตรวจสอบข้อมูลใบหน้า\n",
        "    if first_frame['face']:\n",
        "        print(\"\\nข้อมูลใบหน้า:\")\n",
        "        for part, points in first_frame['face'].items():\n",
        "            print(f\"  {part}: {len(points)} จุด\")\n",
        "\n",
        "    return first_video  # ส่งคืนข้อมูลวิดีโอแรกเพื่อใช้ในการทดสอบต่อไป\n",
        "\n",
        "# ทดสอบการตรวจสอบข้อมูล\n",
        "first_video_3d = verify_3d_data(output_3d_folder)"
      ],
      "metadata": {
        "id": "Bo1S6hBzGSnt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}